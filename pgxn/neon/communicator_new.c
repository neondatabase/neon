/*-------------------------------------------------------------------------
 *
 * communicator_new.c
 *	  Functions for communicating with remote pageservers.
 *
 * This is the "new" communicator. It consists of functions that
 * are called from the smgr implementation, in pagestore_smgr.c.
 *
 * Portions Copyright (c) 1996-2021, PostgreSQL Global Development Group
 * Portions Copyright (c) 1994, Regents of the University of California
 *
 *-------------------------------------------------------------------------
 */
#include "postgres.h"

#include <unistd.h>

#include "access/xlog.h"
#include "access/xlogdefs.h"
#if PG_VERSION_NUM >= 150000
#include "access/xlogrecovery.h"
#endif
#include "access/xlog_internal.h"
#include "access/xlogutils.h"
#include "executor/instrument.h"
#include "miscadmin.h"
#include "postmaster/bgworker.h"
#include "postmaster/interrupt.h"
#include "replication/walsender.h"
#include "storage/fd.h"
#include "storage/ipc.h"
#include "storage/latch.h"
#include "storage/pmsignal.h"
#include "storage/procarray.h"
#if PG_VERSION_NUM >= 170000
#include "storage/procnumber.h"
#endif
#include "storage/spin.h"
#include "tcop/tcopprot.h"

#include "communicator_new.h"
#include "neon.h"
#include "neon_perf_counters.h"
#include "pagestore_client.h"

/*
 * FIXME: these are in file_cache.h, but I don't want to #include that
 * here. This code shouldn't be using the C file cache for anything else than
 * the GUCs.
 */
extern int	lfc_max_size;
extern int	lfc_size_limit;
extern char *lfc_path;


/* the rust bindings, generated by cbindgen */
#include "communicator/communicator_bindings.h"

#define MaxProcs (MaxBackends + NUM_AUXILIARY_PROCS)

static CommunicatorInitStruct *cis;
static CommunicatorBackendStruct *my_bs;

static File cache_file = 0;

typedef struct CommunicatorShmemPerBackendData
{
	/*
	 * Latch used to notify backend of IO completion. We cannot use the
	 * standard process latch (MyProc->latch) because we cannot clear that
	 * latch as part of the IO handling, or we might cause the caller to miss
	 * some other events.
	 */
	Latch		io_completion_latch;

	/*
	 * Normally, when reading or writing pages from shared buffer cache, the
	 * worker process can operate directly on the shared buffer. But when
	 * working with a local buffer, we use this "bounce buffer" to pass the
	 * data to the worker process.
	 *
	 * TODO: That's slow, because it incurs an extra memory copy, and there's
	 * currently only one of these per backend, which means you can have only
	 * one such IO in progress at a time.
	 */
	PGIOAlignedBlock bounce_buffer;
} CommunicatorShmemPerBackendData;

typedef struct CommunicatorShmemData
{
	int			dummy;

	CommunicatorShmemPerBackendData backends[]; /* MaxProcs */

	/* rust-managed shmem area follows at next MAXALIGN boundary */
} CommunicatorShmemData;

static CommunicatorShmemData *communicator_shmem_ptr;

#define MyIOCompletionLatch (&communicator_shmem_ptr->backends[MyProcNumber].io_completion_latch)

static slock_t in_elog;

#define MAX_INFLIGHT_ASYNC_REQUESTS 5

/* request indexes of (prefetch) requests that have been started */
static int	inflight_requests[MAX_INFLIGHT_ASYNC_REQUESTS];
static int	num_inflight_requests = 0;

static int	start_request(NeonIORequest *request, struct NeonIOResult *immediate_result_p);
static void wait_request_completion(int request_idx, struct NeonIOResult *result_p);
static void perform_request(NeonIORequest *request, struct NeonIOResult *result_p);
static void process_inflight_requests(void);

static bool bounce_needed(void *buffer);
static void *bounce_buf(void);
static void *bounce_write_if_needed(void *buffer);

PGDLLEXPORT void communicator_new_bgworker_main(Datum main_arg);
static void communicator_new_backend_exit(int code, Datum arg);

/**** Initialization functions. These run in postmaster ****/

void
pg_init_communicator_new(void)
{
	BackgroundWorker bgw;

	/* Initialize the background worker process */
	memset(&bgw, 0, sizeof(bgw));
	bgw.bgw_flags = BGWORKER_SHMEM_ACCESS;
	bgw.bgw_start_time = BgWorkerStart_PostmasterStart;
	snprintf(bgw.bgw_library_name, BGW_MAXLEN, "neon");
	snprintf(bgw.bgw_function_name, BGW_MAXLEN, "communicator_new_bgworker_main");
	snprintf(bgw.bgw_name, BGW_MAXLEN, "Storage communicator process");
	snprintf(bgw.bgw_type, BGW_MAXLEN, "Storage communicator process");
	bgw.bgw_restart_time = 5;
	bgw.bgw_notify_pid = 0;
	bgw.bgw_main_arg = (Datum) 0;

	RegisterBackgroundWorker(&bgw);

	SpinLockInit(&in_elog);
}

static size_t
communicator_new_shmem_size(void)
{
	size_t		size = 0;

	size += MAXALIGN(
					 offsetof(CommunicatorShmemData, backends) +
					 MaxProcs * sizeof(CommunicatorShmemPerBackendData)
		);

	/* space needed by the rust code */
	size += rcommunicator_shmem_size(MaxProcs);

	return size;
}

void
communicator_new_shmem_request(void)
{
	RequestAddinShmemSpace(communicator_new_shmem_size());
}

void
communicator_new_shmem_startup(void)
{
	bool		found;
	int			pipefd[2];
	int			rc;
	size_t		communicator_size;
	size_t		shmem_size;
	void	   *shmem_ptr;
	uint64		initial_file_cache_size;
	uint64		max_file_cache_size;

	rc = pipe(pipefd);
	if (rc != 0)
		ereport(ERROR,
				(errcode_for_file_access(),
				 errmsg_internal("could not create pipe between neon communicator and backends : %m")));
	if (fcntl(pipefd[0], F_SETFL, O_NONBLOCK) == -1)
		elog(FATAL, "fcntl(F_SETFL) failed on read-end of communicator pipe: %m");
	if (fcntl(pipefd[1], F_SETFL, O_NONBLOCK) == -1)
		elog(FATAL, "fcntl(F_SETFL) failed on write-end of communicator pipe: %m");

	shmem_size = communicator_new_shmem_size();
	shmem_ptr = ShmemInitStruct("Communicator shmem state",
								shmem_size,
								&found);
	Assert(!found);

	/* Initialize the C-managed parts */
	communicator_shmem_ptr = (CommunicatorShmemData *) shmem_ptr;
	communicator_size = MAXALIGN(offsetof(CommunicatorShmemData, backends) + MaxProcs * sizeof(CommunicatorShmemPerBackendData));
	shmem_ptr = (char *) shmem_ptr + communicator_size;
	shmem_size -= communicator_size;

	for (int i = 0; i < MaxProcs; i++)
		InitSharedLatch(&communicator_shmem_ptr->backends[i].io_completion_latch);

	/* lfc_size_limit is in MBs */
	initial_file_cache_size = lfc_size_limit * (1024 * 1024 / BLCKSZ);
	max_file_cache_size = lfc_max_size * (1024 * 1024 / BLCKSZ);
	if (initial_file_cache_size < 100)
		initial_file_cache_size = 100;
	if (max_file_cache_size < 100)
		max_file_cache_size = 100;

	/* Initialize the rust-managed parts */
	cis = rcommunicator_shmem_init(pipefd[0], pipefd[1], MaxProcs, shmem_ptr, shmem_size,
								   initial_file_cache_size, max_file_cache_size);
}

/**** Worker process functions. These run in the communicator worker process ****/

/* Entry point for the communicator bgworker process */
void
communicator_new_bgworker_main(Datum main_arg)
{
	char	  **connstrs;
	shardno_t	num_shards;
	struct LoggingState *logging;
	char		errbuf[1000];
	int			elevel;
	uint64		file_cache_size;
	const struct CommunicatorWorkerProcessStruct *proc_handle;

	/*
	 * Pretend that this process is a WAL sender. That affects the shutdown
	 * sequence: WAL senders are shut down last, after the final checkpoint
	 * has been written. That's what we want for the communicator process too
	 */
	am_walsender = true;
	MarkPostmasterChildWalSender();

	/* lfc_size_limit is in MBs */
	file_cache_size = lfc_size_limit * (1024 * 1024 / BLCKSZ);
	if (file_cache_size < 100)
		file_cache_size = 100;

	/* Establish signal handlers. */
	pqsignal(SIGUSR1, procsignal_sigusr1_handler);
	/*
	 * Postmaster sends us SIGUSR2 when all regular backends and bgworkers
	 * have exited, and it's time for us to exit too
	 */
	pqsignal(SIGUSR2, die);
	pqsignal(SIGHUP, SignalHandlerForConfigReload);
	pqsignal(SIGTERM, die);

	BackgroundWorkerUnblockSignals();

	get_shard_map(&connstrs, &num_shards);

	logging = configure_logging();

	proc_handle = communicator_worker_process_launch(
									   cis,
									   neon_tenant,
									   neon_timeline,
									   neon_auth_token,
									   connstrs,
									   num_shards,
									   lfc_path,
									   file_cache_size);
	cis = NULL;

	elog(LOG, "communicator threads started");
	for (;;)
	{
		int32		rc;

		CHECK_FOR_INTERRUPTS();

		if (ConfigReloadPending)
		{
			ConfigReloadPending = false;
			ProcessConfigFile(PGC_SIGHUP);

			/* lfc_size_limit is in MBs */
			file_cache_size = lfc_size_limit * (1024 * 1024 / BLCKSZ);
			if (file_cache_size < 100)
				file_cache_size = 100;
			communicator_worker_config_reload(proc_handle, file_cache_size);
		}

		for (;;)
		{
			rc = pump_logging(logging, (uint8 *) errbuf, sizeof(errbuf), &elevel);
			if (rc == 0)
			{
				/* nothing to do */
				break;
			}
			else if (rc == 1)
			{
				/* Because we don't want to exit on error */
				if (elevel == ERROR)
					elevel = LOG;
				if (elevel == INFO)
					elevel = LOG;
				elog(elevel, "[COMMUNICATOR] %s", errbuf);
			}
			else if (rc == -1)
			{
				elog(ERROR, "logging channel was closed unexpectedly");
			}
		}

		(void) WaitLatch(MyLatch,
						 WL_LATCH_SET | WL_EXIT_ON_PM_DEATH,
						 0,
						 PG_WAIT_EXTENSION);
		ResetLatch(MyLatch);
	}
}

/*
 * Callbacks from the rust code, in the communicator process.
 *
 * NOTE: These must be thread safe! It's very limited which PostgreSQL functions you can use!!!
 *
 * NOTE: the signatures of these better match the Rust definitions!
 */

void
notify_proc_unsafe(int procno)
{
	SetLatch(&communicator_shmem_ptr->backends[procno].io_completion_latch);

}

void
callback_set_my_latch_unsafe(void)
{
	SetLatch(MyLatch);
}

/*
 * FIXME: The logic from neon_get_request_lsns() needs to go here, except for
 * the last-written LSN cache stuff, which is managed by the rust code now.
 */
uint64_t
callback_get_request_lsn_unsafe(void)
{
	/*
	 * NB: be very careful with what you do here! This is called from tokio
	 * threads, so anything tha tries to take LWLocks is unsafe, for example.
	 *
	 * RecoveryInProgress() is OK
	 */
	if (RecoveryInProgress())
	{
		XLogRecPtr	replay_lsn = GetXLogReplayRecPtr(NULL);

		return replay_lsn;
	}
	else
	{
		XLogRecPtr	flushlsn;

#if PG_VERSION_NUM >= 150000
		flushlsn = GetFlushRecPtr(NULL);
#else
		flushlsn = GetFlushRecPtr();
#endif

		return flushlsn;
	}
}

/**** Backend functions. These run in each backend ****/

/* Initialize per-backend private state */
void
communicator_new_init(void)
{
	Assert(cis != NULL);
	Assert(my_bs == NULL);

	if (MyBgworkerEntry && strcmp(MyBgworkerEntry->bgw_function_name, "communicator_new_bgworker_main") == 0)
		return;

	OwnLatch(MyIOCompletionLatch);

	my_bs = rcommunicator_backend_init(cis, MyProcNumber);
	cis = NULL;

	/*
	 * Arrange to clean up at backend exit.
	 */
	on_shmem_exit(communicator_new_backend_exit, 0);
}

static void
communicator_new_backend_exit(int code, Datum arg)
{
	DisownLatch(MyIOCompletionLatch);
}

/*
 * prefetch_register_bufferv() - register and prefetch buffers
 *
 * Register that we may want the contents of BufferTag in the near future.
 * This is used when issuing a speculative prefetch request, but also when
 * performing a synchronous request and need the buffer right now.
 *
 * When performing a prefetch rather than a synchronous request,
 * is_prefetch==true. Currently, it only affects how the request is accounted
 * in the perf counters.
 *
 * NOTE: this function may indirectly update MyPState->pfs_hash; which
 * invalidates any active pointers into the hash table.
 */
void
communicator_new_prefetch_register_bufferv(NRelFileInfo rinfo, ForkNumber forkNum,
										   BlockNumber blockno, BlockNumber nblocks)
{
	int			request_idx;
	NeonIORequest request = {
		.tag = NeonIORequest_PrefetchV,
		.prefetch_v = {
			.spc_oid = NInfoGetSpcOid(rinfo),
			.db_oid = NInfoGetDbOid(rinfo),
			.rel_number = NInfoGetRelNumber(rinfo),
			.fork_number = forkNum,
			.block_number = blockno,
			.nblocks = nblocks,
		}
	};
	struct NeonIOResult result;

	elog(DEBUG5, "prefetch called for rel %u/%u/%u.%u block %u (%u blocks)",
		 RelFileInfoFmt(rinfo), forkNum, blockno, nblocks);

	if (num_inflight_requests >= MAX_INFLIGHT_ASYNC_REQUESTS)
		process_inflight_requests();

	request_idx = bcomm_start_io_request(my_bs, &request, &result);
	if (request_idx == -1)
	{
		/* -1 means the request was satisfied immediately. */
		/* FIXME: check and log errors */
		return;
	}
	inflight_requests[num_inflight_requests] = request_idx;
	num_inflight_requests++;

	elog(LOG, "sent prefetch request with idx %d", request_idx);
}

static void
process_inflight_requests(void)
{
	struct NeonIOResult result;

	/* FIXME: log errors */
	for (int i = 0; i < num_inflight_requests; i++)
	{
		elog(DEBUG4, "processing prefetch request with idx %d", inflight_requests[i]);
		wait_request_completion(inflight_requests[i], &result);
	}
	num_inflight_requests = 0;
}

/*
 * Perform an IO request in a synchronous fashion.
 *
 * Returns a pointer to the result slot. It is valid until the next time a
 * request is submitted.
 */
static void
perform_request(NeonIORequest * request, struct NeonIOResult *result_p)
{
	int			request_idx;

	process_inflight_requests();

	request_idx = start_request(request, result_p);
	if (request_idx == -1)
	{
		/* it was completed immediately */
		return;
	}
	wait_request_completion(request_idx, result_p);
}

static int
start_request(NeonIORequest * request, struct NeonIOResult *immediate_result_p)
{
	int			request_idx;

	request_idx = bcomm_start_io_request(my_bs, request, immediate_result_p);
	if (request_idx == -1)
	{
		/* -1 means the request was satisfied immediately. */
		return -1;
	}
	elog(DEBUG5, "sent request with idx %d: tag %d", request_idx, request->tag);
	return request_idx;
}

static void
wait_request_completion(int request_idx, struct NeonIOResult *result_p)
{
	int32_t		poll_res;

	/* fixme: check 'request_idx' ? */

	for (;;)
	{
		ResetLatch(MyIOCompletionLatch);

		poll_res = bcomm_poll_request_completion(my_bs, request_idx, result_p);
		if (poll_res == -1)
		{
			CHECK_FOR_INTERRUPTS();

			/*
			 * TODO: wake up periodically for CHECK_FOR_INTERRUPTS(). Because
			 * we wait on MyIOCompletionLatch rather than MyLatch, we won't be
			 * woken up for the standard interrupts.
			 */
			(void) WaitLatch(MyIOCompletionLatch,
							 WL_EXIT_ON_PM_DEATH | WL_LATCH_SET,
							 0,
							 WAIT_EVENT_NEON_PS_STARTING);
			continue;			/* still busy */
		}
		else if (poll_res == 0)
		{
			return;
		}
		else
		{
			elog(ERROR, "unexpected return code from bcomm_poll_request_completion()");
		}
	}
}

/*
 *	Does the physical file exist?
 */
bool
communicator_new_rel_exists(NRelFileInfo rinfo, ForkNumber forkNum)
{
	NeonIORequest request = {
		.tag = NeonIORequest_RelExists,
		.rel_exists = {
			.spc_oid = NInfoGetSpcOid(rinfo),
			.db_oid = NInfoGetDbOid(rinfo),
			.rel_number = NInfoGetRelNumber(rinfo),
			.fork_number = forkNum,
		}
	};
	NeonIOResult result;

	perform_request(&request, &result);
	switch (result.tag)
	{
		case NeonIOResult_RelExists:
			return result.rel_exists;
		case NeonIOResult_Error:
			ereport(ERROR,
					(errcode_for_file_access(),
					 errmsg("could not check existence of rel %u/%u/%u.%u: %s",
							RelFileInfoFmt(rinfo), forkNum, pg_strerror(result.error))));
			break;
		default:
			elog(ERROR, "unexpected result for RelExists operation: %d", result.tag);
			break;
	}
}

/*
 * Read N consecutive pages from a relation
 */
void
communicator_new_read_at_lsnv(NRelFileInfo rinfo, ForkNumber forkNum, BlockNumber blockno,
							  void **buffers, BlockNumber nblocks)
{
	NeonIOResult result;
	CCachedGetPageVResult cached_result;
	void	   *bounce_buf_used = NULL;
	int			request_idx;
	NeonIORequest request = {
		.tag = NeonIORequest_GetPageV,
		.get_page_v = {
			.spc_oid = NInfoGetSpcOid(rinfo),
			.db_oid = NInfoGetDbOid(rinfo),
			.rel_number = NInfoGetRelNumber(rinfo),
			.fork_number = forkNum,
			.block_number = blockno,
			.nblocks = nblocks,
		}
	};

	elog(DEBUG5, "getpagev called for rel %u/%u/%u.%u block %u (%u blocks)",
		 RelFileInfoFmt(rinfo), forkNum, blockno, nblocks);

	/* Fill in the destination buffers in the request */
	if (nblocks == 1)
	{
		if (bounce_needed(buffers[0]))
		{
			bounce_buf_used = bounce_buf();
			request.get_page_v.dest[0].ptr = bounce_buf_used;
		}
		else
			request.get_page_v.dest[0].ptr = buffers[0];
	}
	else
	{
		for (int i = 0; i < nblocks; i++)
		{
			if (bounce_needed(buffers[i]))
			{
				/* Split the vector-request into single page requests */
				for (int j = 0; j < nblocks; j++)
				{
					communicator_new_read_at_lsnv(rinfo, forkNum, blockno + j,
												  &buffers[j], 1);
				}
				return;
			}
			request.get_page_v.dest[i].ptr = buffers[i];
		}
	}

	process_inflight_requests();

retry:
	request_idx = bcomm_start_get_page_v_request(my_bs, &request, &cached_result);
	if (request_idx == -1)
	{
		bool		completed;

		/*
		 * LFC hit, but we are responsible for completing the I/O on the local
		 * file
		 */
		if (cache_file == 0)
			cache_file = PathNameOpenFile(lfc_path, O_RDONLY | PG_BINARY);

		for (int i = 0; i < nblocks; i++)
		{
			uint64_t	cached_block = cached_result.cache_block_numbers[i];
			char	   *buffer = buffers[i];
			ssize_t		bytes_total = 0;

			while (bytes_total < BLCKSZ)
			{
				ssize_t		nbytes;

				nbytes = FileRead(cache_file, buffer + bytes_total, BLCKSZ - bytes_total, cached_block * BLCKSZ + bytes_total, WAIT_EVENT_NEON_LFC_READ);
				if (nbytes == -1)
					ereport(ERROR,
							(errcode_for_file_access(),
							 errmsg("could not read block %lu in local cache file: %m",
									(unsigned long)cached_block)));
				bytes_total += nbytes;
			}
		}
		completed = bcomm_finish_cache_read(my_bs);
		if (!completed)
		{
			elog(DEBUG1, "read from local cache file was superseded by concurrent update");
			goto retry;
		}
		return;
	}

	wait_request_completion(request_idx, &result);
	switch (result.tag)
	{
		case NeonIOResult_GetPageV:
			if (bounce_buf_used)
				memcpy(buffers[0], bounce_buf_used, BLCKSZ);
			return;
		case NeonIOResult_Error:
			ereport(ERROR,
					(errcode_for_file_access(),
					 errmsg("could not read block %u in rel %u/%u/%u.%u: %s",
							blockno, RelFileInfoFmt(rinfo), forkNum, pg_strerror(result.error))));
			break;
		default:
			elog(ERROR, "unexpected result for GetPage operation: %d", result.tag);
			break;
	}
}

/*
 *	neon_nblocks() -- Get the number of blocks stored in a relation.
 */
BlockNumber
communicator_new_rel_nblocks(NRelFileInfo rinfo, ForkNumber forkNum)
{
	NeonIORequest request = {
		.tag = NeonIORequest_RelSize,
		.rel_size = {
			.spc_oid = NInfoGetSpcOid(rinfo),
			.db_oid = NInfoGetDbOid(rinfo),
			.rel_number = NInfoGetRelNumber(rinfo),
			.fork_number = forkNum,
		}
	};
	NeonIOResult result;

	perform_request(&request, &result);
	switch (result.tag)
	{
		case NeonIOResult_RelSize:
			return result.rel_size;
		case NeonIOResult_Error:
			ereport(ERROR,
					(errcode_for_file_access(),
					 errmsg("could not read size of rel %u/%u/%u.%u: %s",
							RelFileInfoFmt(rinfo), forkNum, pg_strerror(result.error))));
			break;
		default:
			elog(ERROR, "unexpected result for RelSize operation: %d", result.tag);
			break;
	}
}

/*
 *	neon_db_size() -- Get the size of the database in bytes.
 */
int64
communicator_new_dbsize(Oid dbNode)
{
	NeonIORequest request = {
		.tag = NeonIORequest_DbSize,
		.db_size = {
			.db_oid = dbNode,
		}
	};
	NeonIOResult result;

	perform_request(&request, &result);
	switch (result.tag)
	{
		case NeonIOResult_DbSize:
			return (int64) result.db_size;
		case NeonIOResult_Error:
			ereport(ERROR,
					(errcode_for_file_access(),
					 errmsg("could not read database size of database %u: %s",
							dbNode, pg_strerror(result.error))));
			break;
		default:
			elog(ERROR, "unexpected result for DbSize operation: %d", result.tag);
			break;
	}
}

int
communicator_new_read_slru_segment(SlruKind kind, int64 segno, void *buffer)
{
	/* TODO */
	elog(ERROR, "not implemented");
}

/* Write requests */
void
communicator_new_write_page(NRelFileInfo rinfo, ForkNumber forkNum, BlockNumber blockno,
							const void *buffer, XLogRecPtr lsn)
{
	void	   *src = bounce_write_if_needed((void *) buffer);
	NeonIORequest request = {
		.tag = NeonIORequest_WritePage,
		.write_page = {
			.spc_oid = NInfoGetSpcOid(rinfo),
			.db_oid = NInfoGetDbOid(rinfo),
			.rel_number = NInfoGetRelNumber(rinfo),
			.fork_number = forkNum,
			.block_number = blockno,
			.lsn = lsn,
			.src.ptr = src,
		}
	};
	NeonIOResult result;

	perform_request(&request, &result);
	switch (result.tag)
	{
		case NeonIOResult_WriteOK:
			return;
		case NeonIOResult_Error:
			ereport(ERROR,
					(errcode_for_file_access(),
					 errmsg("could not write block %u in rel %u/%u/%u.%u: %s",
							blockno, RelFileInfoFmt(rinfo), forkNum, pg_strerror(result.error))));
			break;
		default:
			elog(ERROR, "unexpected result for WritePage operation: %d", result.tag);
			break;
	}
}

void
communicator_new_rel_extend(NRelFileInfo rinfo, ForkNumber forkNum, BlockNumber blockno,
							const void *buffer, XLogRecPtr lsn)
{
	void	   *src = bounce_write_if_needed((void *) buffer);
	NeonIORequest request = {
		.tag = NeonIORequest_RelExtend,
		.rel_extend = {
			.spc_oid = NInfoGetSpcOid(rinfo),
			.db_oid = NInfoGetDbOid(rinfo),
			.rel_number = NInfoGetRelNumber(rinfo),
			.fork_number = forkNum,
			.block_number = blockno,
			.lsn = lsn,
			.src_ptr = (uintptr_t) src,
			.src_size = BLCKSZ,
		}
	};
	NeonIOResult result;

	perform_request(&request, &result);
	switch (result.tag)
	{
		case NeonIOResult_WriteOK:
			return;
		case NeonIOResult_Error:
			ereport(ERROR,
					(errcode_for_file_access(),
					 errmsg("could not extend to block %u in rel %u/%u/%u.%u: %s",
							blockno, RelFileInfoFmt(rinfo), forkNum, pg_strerror(result.error))));
			break;
		default:
			elog(ERROR, "unexpected result for Extend operation: %d", result.tag);
			break;
	}
}

void
communicator_new_rel_zeroextend(NRelFileInfo rinfo, ForkNumber forkNum, BlockNumber blockno,
								BlockNumber nblocks, XLogRecPtr lsn)
{
	NeonIORequest request = {
		.tag = NeonIORequest_RelZeroExtend,
		.rel_zero_extend = {
			.spc_oid = NInfoGetSpcOid(rinfo),
			.db_oid = NInfoGetDbOid(rinfo),
			.rel_number = NInfoGetRelNumber(rinfo),
			.fork_number = forkNum,
			.block_number = blockno,
			.nblocks = nblocks,
			.lsn = lsn,
		}
	};
	NeonIOResult result;

	perform_request(&request, &result);
	switch (result.tag)
	{
		case NeonIOResult_WriteOK:
			return;
		case NeonIOResult_Error:
			ereport(ERROR,
					(errcode_for_file_access(),
					 errmsg("could not zeroextend to block %u in rel %u/%u/%u.%u: %s",
							blockno, RelFileInfoFmt(rinfo), forkNum, pg_strerror(result.error))));
			break;
		default:
			elog(ERROR, "unexpected result for ZeroExtend operation: %d", result.tag);
			break;
	}
}

void
communicator_new_rel_create(NRelFileInfo rinfo, ForkNumber forkNum)
{
	NeonIORequest request = {
		.tag = NeonIORequest_RelCreate,
		.rel_create = {
			.spc_oid = NInfoGetSpcOid(rinfo),
			.db_oid = NInfoGetDbOid(rinfo),
			.rel_number = NInfoGetRelNumber(rinfo),
			.fork_number = forkNum,
		}
	};
	NeonIOResult result;

	perform_request(&request, &result);
	switch (result.tag)
	{
		case NeonIOResult_WriteOK:
			return;
		case NeonIOResult_Error:
			ereport(ERROR,
					(errcode_for_file_access(),
					 errmsg("could not create rel %u/%u/%u.%u: %s",
							RelFileInfoFmt(rinfo), forkNum, pg_strerror(result.error))));
			break;
		default:
			elog(ERROR, "unexpected result for Create operation: %d", result.tag);
			break;
	}
}

void
communicator_new_rel_truncate(NRelFileInfo rinfo, ForkNumber forkNum, BlockNumber nblocks)
{
	NeonIORequest request = {
		.tag = NeonIORequest_RelTruncate,
		.rel_truncate = {
			.spc_oid = NInfoGetSpcOid(rinfo),
			.db_oid = NInfoGetDbOid(rinfo),
			.rel_number = NInfoGetRelNumber(rinfo),
			.fork_number = forkNum,
			.nblocks = nblocks,
		}
	};
	NeonIOResult result;

	perform_request(&request, &result);
	switch (result.tag)
	{
		case NeonIOResult_WriteOK:
			return;
		case NeonIOResult_Error:
			ereport(ERROR,
					(errcode_for_file_access(),
					 errmsg("could not truncate rel %u/%u/%u.%u to %u blocks: %s",
							RelFileInfoFmt(rinfo), forkNum, nblocks, pg_strerror(result.error))));
			break;
		default:
			elog(ERROR, "unexpected result for Truncate operation: %d", result.tag);
			break;
	}
}

void
communicator_new_rel_unlink(NRelFileInfo rinfo, ForkNumber forkNum)
{
	NeonIORequest request = {
		.tag = NeonIORequest_RelUnlink,
		.rel_unlink = {
			.spc_oid = NInfoGetSpcOid(rinfo),
			.db_oid = NInfoGetDbOid(rinfo),
			.rel_number = NInfoGetRelNumber(rinfo),
			.fork_number = forkNum,
		}
	};
	NeonIOResult result;

	perform_request(&request, &result);
	switch (result.tag)
	{
		case NeonIOResult_WriteOK:
			return;
		case NeonIOResult_Error:
			ereport(ERROR,
					(errcode_for_file_access(),
					 errmsg("could not unlink rel %u/%u/%u.%u: %s",
							RelFileInfoFmt(rinfo), forkNum, pg_strerror(result.error))));
			break;
		default:
			elog(ERROR, "unexpected result for Unlink operation: %d", result.tag);
			break;
	}
}

/*
 * The worker process can read / write shared buffers directly. But if smgrread() or
 * smgrwrite() is called with a private temporary buffer, we need to copy it to the
 * "bounce buffer", to make it available fro the worker process.
 */
static bool
bounce_needed(void *buffer)
{
	if ((uintptr_t) buffer >= (uintptr_t) BufferBlocks &&
		(uintptr_t) buffer < (uintptr_t) BufferBlocks + NBuffers * BLCKSZ)
	{
		return false;
	}
	return true;
}

static void *
bounce_buf(void)
{
	return &communicator_shmem_ptr->backends[MyProcNumber].bounce_buffer;
}

static void *
bounce_write_if_needed(void *buffer)
{
	void	   *p;

	if (!bounce_needed(buffer))
		return buffer;

	p = bounce_buf();
	memcpy(p, buffer, BLCKSZ);
	return p;
}
