diff --git a/src/test/regress/sql/aggregates.sql b/src/test/regress/sql/aggregates.sql
index fe4d89aec6..6d7123c5a8 100644
--- a/src/test/regress/sql/aggregates.sql
+++ b/src/test/regress/sql/aggregates.sql
@@ -79,16 +79,16 @@ SELECT var_pop('nan'::numeric), var_samp('nan'::numeric);
 SELECT stddev_pop('nan'::numeric), stddev_samp('nan'::numeric);
 
 -- verify correct results for null and NaN inputs
-select sum(null::int4) from generate_series(1,3);
-select sum(null::int8) from generate_series(1,3);
-select sum(null::numeric) from generate_series(1,3);
-select sum(null::float8) from generate_series(1,3);
-select avg(null::int4) from generate_series(1,3);
-select avg(null::int8) from generate_series(1,3);
-select avg(null::numeric) from generate_series(1,3);
-select avg(null::float8) from generate_series(1,3);
-select sum('NaN'::numeric) from generate_series(1,3);
-select avg('NaN'::numeric) from generate_series(1,3);
+select sum(null::int4) from generate_series(1, 495 * 3);
+select sum(null::int8) from generate_series(1, 495 * 3);
+select sum(null::numeric) from generate_series(1, 495 * 3);
+select sum(null::float8) from generate_series(1, 495 * 3);
+select avg(null::int4) from generate_series(1, 495 * 3);
+select avg(null::int8) from generate_series(1, 495 * 3);
+select avg(null::numeric) from generate_series(1, 495 * 3);
+select avg(null::float8) from generate_series(1, 495 * 3);
+select sum('NaN'::numeric) from generate_series(1, 495 * 3);
+select avg('NaN'::numeric) from generate_series(1, 495 * 3);
 
 -- verify correct results for infinite inputs
 SELECT sum(x::float8), avg(x::float8), var_pop(x::float8)
@@ -199,23 +199,23 @@ from tenk1 o;
 -- Per bug report from Jeevan Chalke.
 explain (verbose, costs off)
 select s1, s2, sm
-from generate_series(1, 3) s1,
+from generate_series(1, 495 * 3) s1,
      lateral (select s2, sum(s1 + s2) sm
-              from generate_series(1, 3) s2 group by s2) ss
+              from generate_series(1, 495 * 3) s2 group by s2) ss
 order by 1, 2;
 select s1, s2, sm
-from generate_series(1, 3) s1,
+from generate_series(1, 495 * 3) s1,
      lateral (select s2, sum(s1 + s2) sm
-              from generate_series(1, 3) s2 group by s2) ss
+              from generate_series(1, 495 * 3) s2 group by s2) ss
 order by 1, 2;
 
 explain (verbose, costs off)
 select array(select sum(x+y) s
-            from generate_series(1,3) y group by y order by s)
-  from generate_series(1,3) x;
+            from generate_series(1, 495 * 3) y group by y order by s)
+  from generate_series(1, 495 * 3) x;
 select array(select sum(x+y) s
-            from generate_series(1,3) y group by y order by s)
-  from generate_series(1,3) x;
+            from generate_series(1, 495 * 3) y group by y order by s)
+  from generate_series(1, 495 * 3) x;
 
 --
 -- test for bitwise integer aggregates
@@ -402,8 +402,8 @@ explain (costs off)
   select max(unique2) from tenk1 order by max(unique2)+1;
 select max(unique2) from tenk1 order by max(unique2)+1;
 explain (costs off)
-  select max(unique2), generate_series(1,3) as g from tenk1 order by g desc;
-select max(unique2), generate_series(1,3) as g from tenk1 order by g desc;
+  select max(unique2), generate_series(1, 495 * 3) as g from tenk1 order by g desc;
+select max(unique2), generate_series(1, 495 * 3) as g from tenk1 order by g desc;
 
 -- interesting corner case: constant gets optimized into a seqscan
 explain (costs off)
@@ -587,7 +587,7 @@ group by ten;
 
 -- Ensure consecutive NULLs are properly treated as distinct from each other
 select array_agg(distinct val)
-from (select null as val from generate_series(1, 2));
+from (select null as val from generate_series(1, 495 * 2));
 
 -- Ensure no ordering is requested when enable_presorted_aggregate is off
 set enable_presorted_aggregate to off;
@@ -645,32 +645,32 @@ select aggfns(a,b,c)
 
 select aggfstr(distinct a,b,c)
   from (values (1,3,'foo'),(0,null,null),(2,2,'bar'),(3,1,'baz')) v(a,b,c),
-       generate_series(1,3) i;
+       generate_series(1, 495 * 3) i;
 select aggfns(distinct a,b,c)
   from (values (1,3,'foo'),(0,null,null),(2,2,'bar'),(3,1,'baz')) v(a,b,c),
-       generate_series(1,3) i;
+       generate_series(1, 495 * 3) i;
 
 select aggfstr(distinct a,b,c order by b)
   from (values (1,3,'foo'),(0,null,null),(2,2,'bar'),(3,1,'baz')) v(a,b,c),
-       generate_series(1,3) i;
+       generate_series(1, 495 * 3) i;
 select aggfns(distinct a,b,c order by b)
   from (values (1,3,'foo'),(0,null,null),(2,2,'bar'),(3,1,'baz')) v(a,b,c),
-       generate_series(1,3) i;
+       generate_series(1, 495 * 3) i;
 
 -- test specific code paths
 
 select aggfns(distinct a,a,c order by c using ~<~,a)
   from (values (1,3,'foo'),(0,null,null),(2,2,'bar'),(3,1,'baz')) v(a,b,c),
-       generate_series(1,2) i;
+       generate_series(1, 495 * 2) i;
 select aggfns(distinct a,a,c order by c using ~<~)
   from (values (1,3,'foo'),(0,null,null),(2,2,'bar'),(3,1,'baz')) v(a,b,c),
-       generate_series(1,2) i;
+       generate_series(1, 495 * 2) i;
 select aggfns(distinct a,a,c order by a)
   from (values (1,3,'foo'),(0,null,null),(2,2,'bar'),(3,1,'baz')) v(a,b,c),
-       generate_series(1,2) i;
+       generate_series(1, 495 * 2) i;
 select aggfns(distinct a,b,c order by a,c using ~<~,b)
   from (values (1,3,'foo'),(0,null,null),(2,2,'bar'),(3,1,'baz')) v(a,b,c),
-       generate_series(1,2) i;
+       generate_series(1, 495 * 2) i;
 
 -- test a more complex permutation that has previous caused issues
 select
@@ -693,7 +693,7 @@ select pg_get_viewdef('agg_view1'::regclass);
 create or replace view agg_view1 as
   select aggfns(distinct a,b,c)
     from (values (1,3,'foo'),(0,null,null),(2,2,'bar'),(3,1,'baz')) v(a,b,c),
-         generate_series(1,3) i;
+         generate_series(1, 495 * 3) i;
 
 select * from agg_view1;
 select pg_get_viewdef('agg_view1'::regclass);
@@ -701,7 +701,7 @@ select pg_get_viewdef('agg_view1'::regclass);
 create or replace view agg_view1 as
   select aggfns(distinct a,b,c order by b)
     from (values (1,3,'foo'),(0,null,null),(2,2,'bar'),(3,1,'baz')) v(a,b,c),
-         generate_series(1,3) i;
+         generate_series(1, 495 * 3) i;
 
 select * from agg_view1;
 select pg_get_viewdef('agg_view1'::regclass);
@@ -730,7 +730,7 @@ select pg_get_viewdef('agg_view1'::regclass);
 create or replace view agg_view1 as
   select aggfns(distinct a,b,c order by a,c using ~<~,b)
     from (values (1,3,'foo'),(0,null,null),(2,2,'bar'),(3,1,'baz')) v(a,b,c),
-         generate_series(1,2) i;
+         generate_series(1, 495 * 2) i;
 
 select * from agg_view1;
 select pg_get_viewdef('agg_view1'::regclass);
@@ -740,13 +740,13 @@ drop view agg_view1;
 -- incorrect DISTINCT usage errors
 
 select aggfns(distinct a,b,c order by i)
-  from (values (1,1,'foo')) v(a,b,c), generate_series(1,2) i;
+  from (values (1,1,'foo')) v(a,b,c), generate_series(1, 495 * 2) i;
 select aggfns(distinct a,b,c order by a,b+1)
-  from (values (1,1,'foo')) v(a,b,c), generate_series(1,2) i;
+  from (values (1,1,'foo')) v(a,b,c), generate_series(1, 495 * 2) i;
 select aggfns(distinct a,b,c order by a,b,i,c)
-  from (values (1,1,'foo')) v(a,b,c), generate_series(1,2) i;
+  from (values (1,1,'foo')) v(a,b,c), generate_series(1, 495 * 2) i;
 select aggfns(distinct a,a,c order by a,b)
-  from (values (1,1,'foo')) v(a,b,c), generate_series(1,2) i;
+  from (values (1,1,'foo')) v(a,b,c), generate_series(1, 495 * 2) i;
 
 -- string_agg tests
 select string_agg(a,',') from (values('aaaa'),('bbbb'),('cccc')) g(a);
@@ -781,7 +781,7 @@ drop table bytea_test_table;
 create table pagg_test (x int, y int) with (autovacuum_enabled = off);
 insert into pagg_test
 select (case x % 4 when 1 then null else x end), x % 10
-from generate_series(1,5000) x;
+from generate_series(1, 495 * 5000) x;
 
 set parallel_setup_cost TO 0;
 set parallel_tuple_cost TO 0;
@@ -885,7 +885,7 @@ select sum(unique1) FILTER (WHERE
 -- exercise lots of aggregate parts with FILTER
 select aggfns(distinct a,b,c order by a,c using ~<~,b) filter (where a > 1)
     from (values (1,3,'foo'),(0,null,null),(2,2,'bar'),(3,1,'baz')) v(a,b,c),
-    generate_series(1,2) i;
+    generate_series(1, 495 * 2) i;
 
 -- check handling of bare boolean Var in FILTER
 select max(0) filter (where b1) from bool_test;
@@ -901,22 +901,22 @@ select (select max(unique1) filter (where bool_or(ten > 0)) from int8_tbl) from
 -- ordered-set aggregates
 
 select p, percentile_cont(p) within group (order by x::float8)
-from generate_series(1,5) x,
+from generate_series(1, 495 * 5) x,
      (values (0::float8),(0.1),(0.25),(0.4),(0.5),(0.6),(0.75),(0.9),(1)) v(p)
 group by p order by p;
 
 select p, percentile_cont(p order by p) within group (order by x)  -- error
-from generate_series(1,5) x,
+from generate_series(1, 495 * 5) x,
      (values (0::float8),(0.1),(0.25),(0.4),(0.5),(0.6),(0.75),(0.9),(1)) v(p)
 group by p order by p;
 
 select p, sum() within group (order by x::float8)  -- error
-from generate_series(1,5) x,
+from generate_series(1, 495 * 5) x,
      (values (0::float8),(0.1),(0.25),(0.4),(0.5),(0.6),(0.75),(0.9),(1)) v(p)
 group by p order by p;
 
 select p, percentile_cont(p,p)  -- error
-from generate_series(1,5) x,
+from generate_series(1, 495 * 5) x,
      (values (0::float8),(0.1),(0.25),(0.4),(0.5),(0.6),(0.75),(0.9),(1)) v(p)
 group by p order by p;
 
@@ -940,7 +940,7 @@ from tenk1;
 select percentile_disc(array[[null,1,0.5],[0.75,0.25,null]]) within group (order by thousand)
 from tenk1;
 select percentile_cont(array[0,1,0.25,0.75,0.5,1,0.3,0.32,0.35,0.38,0.4]) within group (order by x)
-from generate_series(1,6) x;
+from generate_series(1, 495 * 6) x;
 
 select ten, mode() within group (order by string4) from tenk1 group by ten;
 
@@ -957,28 +957,28 @@ from (values (1),(1),(2),(2),(3),(3),(4)) v(x);
 select test_percentile_disc(0.5) within group (order by thousand) from tenk1;
 
 -- ordered-set aggs can't use ungrouped vars in direct args:
-select rank(x) within group (order by x) from generate_series(1,5) x;
+select rank(x) within group (order by x) from generate_series(1, 495 * 5) x;
 
 -- outer-level agg can't use a grouped arg of a lower level, either:
 select array(select percentile_disc(a) within group (order by x)
                from (values (0.3),(0.7)) v(a) group by a)
-  from generate_series(1,5) g(x);
+  from generate_series(1, 495 * 5) g(x);
 
 -- agg in the direct args is a grouping violation, too:
-select rank(sum(x)) within group (order by x) from generate_series(1,5) x;
+select rank(sum(x)) within group (order by x) from generate_series(1, 495 * 5) x;
 
 -- hypothetical-set type unification and argument-count failures:
 select rank(3) within group (order by x) from (values ('fred'),('jim')) v(x);
 select rank(3) within group (order by stringu1,stringu2) from tenk1;
-select rank('fred') within group (order by x) from generate_series(1,5) x;
+select rank('fred') within group (order by x) from generate_series(1, 495 * 5) x;
 select rank('adam'::text collate "C") within group (order by x collate "POSIX")
   from (values ('fred'),('jim')) v(x);
 -- hypothetical-set type unification successes:
 select rank('adam'::varchar) within group (order by x) from (values ('fred'),('jim')) v(x);
-select rank('3') within group (order by x) from generate_series(1,5) x;
+select rank('3') within group (order by x) from generate_series(1, 495 * 5) x;
 
 -- divide by zero check
-select percent_rank(0) within group (order by x) from generate_series(1,0) x;
+select percent_rank(0) within group (order by x) from generate_series(1, 495 * 0) x;
 
 -- deparse and multiple features:
 create view aggordview1 as
@@ -1221,7 +1221,7 @@ CREATE TABLE btg AS SELECT
   i % 10 AS y,
   'abc' || i % 10 AS z,
   i AS w
-FROM generate_series(1, 100) AS i;
+FROM generate_series(1, 495 * 100) AS i;
 CREATE INDEX btg_x_y_idx ON btg(x, y);
 ANALYZE btg;
 
@@ -1274,7 +1274,7 @@ CREATE TABLE group_agg_pk AS SELECT
   i % 2 AS z,
   2 AS w,
   i % 10 AS f
-FROM generate_series(1,100) AS i;
+FROM generate_series(1, 495 * 100) AS i;
 ANALYZE group_agg_pk;
 SET enable_nestloop = off;
 SET enable_hashjoin = off;
@@ -1309,7 +1309,7 @@ DROP TABLE group_agg_pk;
 -- aggregate but cannot be found in the group-by list
 CREATE TABLE agg_sort_order (c1 int PRIMARY KEY, c2 int);
 CREATE UNIQUE INDEX agg_sort_order_c2_idx ON agg_sort_order(c2);
-INSERT INTO agg_sort_order SELECT i, i FROM generate_series(1,100)i;
+INSERT INTO agg_sort_order SELECT i, i FROM generate_series(1, 495 * 100)i;
 ANALYZE agg_sort_order;
 
 EXPLAIN (COSTS OFF)
@@ -1490,11 +1490,11 @@ set enable_sort to default;
 set work_mem='64kB';
 
 create table agg_data_2k as
-select g from generate_series(0, 1999) g;
+select g from generate_series(0, 495 * 1999) g;
 analyze agg_data_2k;
 
 create table agg_data_20k as
-select g from generate_series(0, 19999) g;
+select g from generate_series(0, 495 * 19999) g;
 analyze agg_data_20k;
 
 -- Produce results with sorting.
diff --git a/src/test/regress/sql/amutils.sql b/src/test/regress/sql/amutils.sql
index 06e7fa10d9..c6bd57341f 100644
--- a/src/test/regress/sql/amutils.sql
+++ b/src/test/regress/sql/amutils.sql
@@ -84,7 +84,7 @@ select col, prop, pg_index_column_has_property(o, col, prop)
        (values (1,'orderable'),(2,'asc'),(3,'desc'),
                (4,'nulls_first'),(5,'nulls_last'),
                (6, 'bogus')) v2(idx,prop),
-       generate_series(1,4) col
+       generate_series(1, 495 * 4) col
  order by col, idx;
 
 CREATE INDEX foocover ON foo (f1) INCLUDE (f2,f3);
@@ -95,5 +95,5 @@ select col, prop, pg_index_column_has_property(o, col, prop)
                (4,'nulls_first'),(5,'nulls_last'),
                (6,'distance_orderable'),(7,'returnable'),
                (8, 'bogus')) v2(idx,prop),
-       generate_series(1,3) col
+       generate_series(1, 495 * 3) col
  order by col, idx;
diff --git a/src/test/regress/sql/arrays.sql b/src/test/regress/sql/arrays.sql
index 305371deba..bafe6317ee 100644
--- a/src/test/regress/sql/arrays.sql
+++ b/src/test/regress/sql/arrays.sql
@@ -300,7 +300,7 @@ SELECT array_positions(ARRAY[[1,2],[3,4]], 4);
 SELECT array_positions(ARRAY[1,2,3,4,5,6,1,2,3,4,5,6], NULL);
 SELECT array_positions(ARRAY[1,2,3,NULL,5,6,1,2,3,NULL,5,6], NULL);
 SELECT array_length(array_positions(ARRAY(SELECT 'AAAAAAAAAAAAAAAAAAAAAAAAA'::text || i % 10
-                                          FROM generate_series(1,100) g(i)),
+                                          FROM generate_series(1, 495 * 100) g(i)),
                                   'AAAAAAAAAAAAAAAAAAAAAAAAA5'), 1);
 
 DO $$
@@ -404,7 +404,7 @@ select null::int = all ('{1,2,3}');
 select 33 = all ('{1,null,3}');
 select 33 = all ('{33,null,33}');
 -- nulls later in the bitmap
-SELECT -1 != ALL(ARRAY(SELECT NULLIF(g.i, 900) FROM generate_series(1,1000) g(i)));
+SELECT -1 != ALL(ARRAY(SELECT NULLIF(g.i, 900) FROM generate_series(1, 495 * 1000) g(i)));
 
 -- test indexes on arrays
 create temp table arr_tbl (f1 int[] unique);
@@ -675,16 +675,16 @@ select array_agg(unique1) from tenk1 where unique1 < -15;
 select array_agg(ar)
   from (values ('{1,2}'::int[]), ('{3,4}'::int[])) v(ar);
 select array_agg(distinct ar order by ar desc)
-  from (select array[i / 2] from generate_series(1,10) a(i)) b(ar);
+  from (select array[i / 2] from generate_series(1, 495 * 10) a(i)) b(ar);
 select array_agg(ar)
   from (select array_agg(array[i, i+1, i-1])
-        from generate_series(1,2) a(i)) b(ar);
-select array_agg(array[i+1.2, i+1.3, i+1.4]) from generate_series(1,3) g(i);
+        from generate_series(1, 495 * 2) a(i)) b(ar);
+select array_agg(array[i+1.2, i+1.3, i+1.4]) from generate_series(1, 495 * 3) g(i);
 select array_agg(array['Hello', i::text]) from generate_series(9,11) g(i);
-select array_agg(array[i, nullif(i, 3), i+1]) from generate_series(1,4) g(i);
+select array_agg(array[i, nullif(i, 3), i+1]) from generate_series(1, 495 * 4) g(i);
 -- errors
-select array_agg('{}'::int[]) from generate_series(1,2);
-select array_agg(null::int[]) from generate_series(1,2);
+select array_agg('{}'::int[]) from generate_series(1, 495 * 2);
+select array_agg(null::int[]) from generate_series(1, 495 * 2);
 select array_agg(ar)
   from (values ('{1,2}'::int[]), ('{3}'::int[])) v(ar);
 
@@ -710,16 +710,16 @@ select array_replace(array[1,NULL,3],NULL,NULL);
 select array_replace(array['AB',NULL,'CDE'],NULL,'12');
 
 -- array(select array-value ...)
-select array(select array[i,i/2] from generate_series(1,5) i);
+select array(select array[i,i/2] from generate_series(1, 495 * 5) i);
 select array(select array['Hello', i::text] from generate_series(9,11) i);
 
 -- int2vector and oidvector should be treated as scalar types for this purpose
-select pg_typeof(array(select '11 22 33'::int2vector from generate_series(1,5)));
-select array(select '11 22 33'::int2vector from generate_series(1,5));
-select unnest(array(select '11 22 33'::int2vector from generate_series(1,5)));
-select pg_typeof(array(select '11 22 33'::oidvector from generate_series(1,5)));
-select array(select '11 22 33'::oidvector from generate_series(1,5));
-select unnest(array(select '11 22 33'::oidvector from generate_series(1,5)));
+select pg_typeof(array(select '11 22 33'::int2vector from generate_series(1, 495 * 5)));
+select array(select '11 22 33'::int2vector from generate_series(1, 495 * 5));
+select unnest(array(select '11 22 33'::int2vector from generate_series(1, 495 * 5)));
+select pg_typeof(array(select '11 22 33'::oidvector from generate_series(1, 495 * 5)));
+select array(select '11 22 33'::oidvector from generate_series(1, 495 * 5));
+select unnest(array(select '11 22 33'::oidvector from generate_series(1, 495 * 5)));
 
 -- array[] should do the same
 select pg_typeof(array['11 22 33'::int2vector]);
@@ -747,7 +747,7 @@ select * from t1;
 
 create temp table src (f1 text);
 insert into src
-  select string_agg(random()::text,'') from generate_series(1,10000);
+  select string_agg(random()::text,'') from generate_series(1, 495 * 10000);
 create type textandtext as (c1 text, c2 text);
 create temp table dest (f1 textandtext[]);
 insert into dest select array[row(f1,f1)::textandtext] from src;
@@ -808,7 +808,7 @@ FROM (VALUES
 SELECT
     op,
     width_bucket(op, ARRAY[1, 3, 5, 10]) AS wb_1
-FROM generate_series(0,11) as op;
+FROM generate_series(0, 495 * 11) as op;
 
 SELECT width_bucket(now(),
                     array['yesterday', 'today', 'tomorrow']::timestamptz[]);
diff --git a/src/test/regress/sql/bitmapops.sql b/src/test/regress/sql/bitmapops.sql
index 498f4721b5..f5de457a70 100644
--- a/src/test/regress/sql/bitmapops.sql
+++ b/src/test/regress/sql/bitmapops.sql
@@ -16,7 +16,7 @@ CREATE TABLE bmscantest (a int, b int, t text);
 
 INSERT INTO bmscantest
   SELECT (r%53), (r%59), 'foooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo'
-  FROM generate_series(1,70000) r;
+  FROM generate_series(1, 495 * 70000) r;
 
 CREATE INDEX i_bmtest_a ON bmscantest(a);
 CREATE INDEX i_bmtest_b ON bmscantest(b);
diff --git a/src/test/regress/sql/box.sql b/src/test/regress/sql/box.sql
index 2d0868e889..d30decfe56 100644
--- a/src/test/regress/sql/box.sql
+++ b/src/test/regress/sql/box.sql
@@ -135,7 +135,7 @@ CREATE TEMPORARY TABLE box_temp (f1 box);
 
 INSERT INTO box_temp
 	SELECT box(point(i, i), point(i * 2, i * 2))
-	FROM generate_series(1, 50) AS i;
+	FROM generate_series(1, 495 * 50) AS i;
 
 CREATE INDEX box_spgist ON box_temp USING spgist (f1);
 
@@ -197,7 +197,7 @@ CREATE TABLE quad_box_tbl (id int, b box);
 INSERT INTO quad_box_tbl
   SELECT (x - 1) * 100 + y, box(point(x * 10, y * 10), point(x * 10 + 5, y * 10 + 5))
   FROM generate_series(1, 100) x,
-       generate_series(1, 100) y;
+       generate_series(1, 495 * 100) y;
 
 -- insert repeating data to test allTheSame
 INSERT INTO quad_box_tbl
diff --git a/src/test/regress/sql/brin.sql b/src/test/regress/sql/brin.sql
index 695cfad4be..f8013b3939 100644
--- a/src/test/regress/sql/brin.sql
+++ b/src/test/regress/sql/brin.sql
@@ -461,7 +461,7 @@ DROP TABLE brintest_2;
 
 -- test brin cost estimates behave sanely based on correlation of values
 CREATE TABLE brin_test (a INT, b INT);
-INSERT INTO brin_test SELECT x/100,x%100 FROM generate_series(1,10000) x(x);
+INSERT INTO brin_test SELECT x/100,x%100 FROM generate_series(1, 495 * 10000) x(x);
 CREATE INDEX brin_test_a_idx ON brin_test USING brin (a) WITH (pages_per_range = 2);
 CREATE INDEX brin_test_b_idx ON brin_test USING brin (b) WITH (pages_per_range = 2);
 VACUUM ANALYZE brin_test;
diff --git a/src/test/regress/sql/brin_bloom.sql b/src/test/regress/sql/brin_bloom.sql
index 5d499208e3..4c4790a4a6 100644
--- a/src/test/regress/sql/brin_bloom.sql
+++ b/src/test/regress/sql/brin_bloom.sql
@@ -365,7 +365,7 @@ SELECT brin_summarize_range('brin_summarize_bloom_idx', 4294967296);
 
 -- test brin cost estimates behave sanely based on correlation of values
 CREATE TABLE brin_test_bloom (a INT, b INT);
-INSERT INTO brin_test_bloom SELECT x/100,x%100 FROM generate_series(1,10000) x(x);
+INSERT INTO brin_test_bloom SELECT x/100,x%100 FROM generate_series(1, 495 * 10000) x(x);
 CREATE INDEX brin_test_bloom_a_idx ON brin_test_bloom USING brin (a) WITH (pages_per_range = 2);
 CREATE INDEX brin_test_bloom_b_idx ON brin_test_bloom USING brin (b) WITH (pages_per_range = 2);
 VACUUM ANALYZE brin_test_bloom;
diff --git a/src/test/regress/sql/brin_multi.sql b/src/test/regress/sql/brin_multi.sql
index 55349b4e1f..7cd9ec2ddf 100644
--- a/src/test/regress/sql/brin_multi.sql
+++ b/src/test/regress/sql/brin_multi.sql
@@ -377,7 +377,7 @@ SELECT brin_desummarize_range('brinidx_multi', 100000000);
 
 -- test building an index with many values, to force compaction of the buffer
 CREATE TABLE brin_large_range (a int4);
-INSERT INTO brin_large_range SELECT i FROM generate_series(1,10000) s(i);
+INSERT INTO brin_large_range SELECT i FROM generate_series(1, 495 * 10000) s(i);
 CREATE INDEX brin_large_range_idx ON brin_large_range USING brin (a int4_minmax_multi_ops);
 DROP TABLE brin_large_range;
 
@@ -412,7 +412,7 @@ SELECT brin_summarize_range('brin_summarize_multi_idx', 4294967296);
 
 -- test brin cost estimates behave sanely based on correlation of values
 CREATE TABLE brin_test_multi (a INT, b INT);
-INSERT INTO brin_test_multi SELECT x/100,x%100 FROM generate_series(1,10000) x(x);
+INSERT INTO brin_test_multi SELECT x/100,x%100 FROM generate_series(1, 495 * 10000) x(x);
 CREATE INDEX brin_test_multi_a_idx ON brin_test_multi USING brin (a) WITH (pages_per_range = 2);
 CREATE INDEX brin_test_multi_b_idx ON brin_test_multi USING brin (b) WITH (pages_per_range = 2);
 VACUUM ANALYZE brin_test_multi;
@@ -428,7 +428,7 @@ CREATE TABLE brin_test_multi_1 (a INT, b BIGINT) WITH (fillfactor=10);
 INSERT INTO brin_test_multi_1
 SELECT i/5 + mod(911 * i + 483, 25),
        i/10 + mod(751 * i + 221, 41)
-  FROM generate_series(1,1000) s(i);
+  FROM generate_series(1, 495 * 1000) s(i);
 
 CREATE INDEX brin_test_multi_1_idx_1 ON brin_test_multi_1 USING brin (a int4_minmax_multi_ops) WITH (pages_per_range=5);
 CREATE INDEX brin_test_multi_1_idx_2 ON brin_test_multi_1 USING brin (b int8_minmax_multi_ops) WITH (pages_per_range=5);
@@ -489,7 +489,7 @@ TRUNCATE brin_test_multi_1;
 INSERT INTO brin_test_multi_1
 SELECT i/5 + mod(911 * i + 483, 25),
        i/10 + mod(751 * i + 221, 41)
-  FROM generate_series(1,1000) s(i);
+  FROM generate_series(1, 495 * 1000) s(i);
 
 -- int: less than
 SELECT COUNT(*) FROM brin_test_multi_1 WHERE a < 37;
@@ -545,7 +545,7 @@ RESET enable_seqscan;
 -- do some inequality tests for varlena data types
 CREATE TABLE brin_test_multi_2 (a UUID) WITH (fillfactor=10);
 INSERT INTO brin_test_multi_2
-SELECT v::uuid FROM (SELECT row_number() OVER (ORDER BY v) c, v FROM (SELECT fipshash((i/13)::text) AS v FROM generate_series(1,1000) s(i)) foo) bar ORDER BY c + 25 * random();
+SELECT v::uuid FROM (SELECT row_number() OVER (ORDER BY v) c, v FROM (SELECT fipshash((i/13)::text) AS v FROM generate_series(1, 495 * 1000) s(i)) foo) bar ORDER BY c + 25 * random();
 
 CREATE INDEX brin_test_multi_2_idx ON brin_test_multi_2 USING brin (a uuid_minmax_multi_ops) WITH (pages_per_range=5);
 
@@ -570,7 +570,7 @@ SELECT COUNT(*) FROM brin_test_multi_2 WHERE a = '86e50149-6586-6131-2a9e-0b3555
 
 TRUNCATE brin_test_multi_2;
 INSERT INTO brin_test_multi_2
-SELECT v::uuid FROM (SELECT row_number() OVER (ORDER BY v) c, v FROM (SELECT fipshash((i/13)::text) AS v FROM generate_series(1,1000) s(i)) foo) bar ORDER BY c + 25 * random();
+SELECT v::uuid FROM (SELECT row_number() OVER (ORDER BY v) c, v FROM (SELECT fipshash((i/13)::text) AS v FROM generate_series(1, 495 * 1000) s(i)) foo) bar ORDER BY c + 25 * random();
 
 SELECT COUNT(*) FROM brin_test_multi_2 WHERE a < '3d914f93-48c9-cc0f-f8a7-9716700b9fcd';
 
@@ -595,12 +595,12 @@ SET datestyle TO iso;
 -- values close to timestamp minimum
 INSERT INTO brin_timestamp_test
 SELECT '4713-01-01 00:00:01 BC'::timestamptz + (i || ' seconds')::interval
-  FROM generate_series(1,30) s(i);
+  FROM generate_series(1, 495 * 30) s(i);
 
 -- values close to timestamp maximum
 INSERT INTO brin_timestamp_test
 SELECT '294276-12-01 00:00:01'::timestamptz + (i || ' seconds')::interval
-  FROM generate_series(1,30) s(i);
+  FROM generate_series(1, 495 * 30) s(i);
 
 CREATE INDEX ON brin_timestamp_test USING brin (a timestamptz_minmax_multi_ops) WITH (pages_per_range=1);
 DROP TABLE brin_timestamp_test;
@@ -609,7 +609,7 @@ DROP TABLE brin_timestamp_test;
 CREATE TABLE brin_date_test(a DATE);
 
 -- insert values close to date minimum
-INSERT INTO brin_date_test SELECT '4713-01-01 BC'::date + i FROM generate_series(1, 30) s(i);
+INSERT INTO brin_date_test SELECT '4713-01-01 BC'::date + i FROM generate_series(1, 495 * 30) s(i);
 
 -- insert values close to date minimum
 INSERT INTO brin_date_test SELECT '5874897-12-01'::date + i FROM generate_series(1, 30) s(i);
@@ -649,7 +649,7 @@ RESET enable_seqscan;
 CREATE TABLE brin_date_test(a DATE);
 
 INSERT INTO brin_date_test VALUES ('-infinity'), ('infinity');
-INSERT INTO brin_date_test SELECT '2000-01-01'::date + i FROM generate_series(1, 40) s(i);
+INSERT INTO brin_date_test SELECT '2000-01-01'::date + i FROM generate_series(1, 495 * 40) s(i);
 
 CREATE INDEX ON brin_date_test USING brin (a date_minmax_multi_ops) WITH (pages_per_range=1);
 
diff --git a/src/test/regress/sql/btree_index.sql b/src/test/regress/sql/btree_index.sql
index 0d2a33f370..226870e1a2 100644
--- a/src/test/regress/sql/btree_index.sql
+++ b/src/test/regress/sql/btree_index.sql
@@ -203,7 +203,7 @@ select * from btree_bpchar where f1::bpchar like 'foo%';
 select * from btree_bpchar where f1::bpchar like 'foo%';
 
 -- get test coverage for "single value" deduplication strategy:
-insert into btree_bpchar select 'foo' from generate_series(1,1500);
+insert into btree_bpchar select 'foo' from generate_series(1, 495 * 1500);
 
 --
 -- Perform unique checking, with and without the use of deduplication
@@ -228,7 +228,7 @@ END$$;
 -- coverage (note that this test also assumes BLCKSZ is 8192 or less):
 DROP INDEX plain_unique;
 DELETE FROM dedup_unique_test_table WHERE a = 1;
-INSERT INTO dedup_unique_test_table SELECT i FROM generate_series(0,450) i;
+INSERT INTO dedup_unique_test_table SELECT i FROM generate_series(0, 495 * 450) i;
 
 --
 -- Test B-tree fast path (cache rightmost leaf page) optimization.
@@ -247,13 +247,13 @@ create table btree_tall_tbl(id int4, t text);
 alter table btree_tall_tbl alter COLUMN t set storage plain;
 create index btree_tall_idx on btree_tall_tbl (t, id) with (fillfactor = 10);
 insert into btree_tall_tbl select g, repeat('x', 250)
-from generate_series(1, 130) g;
+from generate_series(1, 495 * 130) g;
 
 --
 -- Test for multilevel page deletion
 --
 CREATE TABLE delete_test_table (a bigint, b bigint, c bigint, d bigint);
-INSERT INTO delete_test_table SELECT i, 1, 2, 3 FROM generate_series(1,80000) i;
+INSERT INTO delete_test_table SELECT i, 1, 2, 3 FROM generate_series(1, 495 * 80000) i;
 ALTER TABLE delete_test_table ADD PRIMARY KEY (a,b,c,d);
 -- Delete most entries, and vacuum, deleting internal pages and creating "fast
 -- root"
diff --git a/src/test/regress/sql/cluster.sql b/src/test/regress/sql/cluster.sql
index b7115f8610..a1d807012c 100644
--- a/src/test/regress/sql/cluster.sql
+++ b/src/test/regress/sql/cluster.sql
@@ -274,7 +274,7 @@ reset maintenance_work_mem;
 
 -- test CLUSTER on expression index
 CREATE TABLE clstr_expression(id serial primary key, a int, b text COLLATE "C");
-INSERT INTO clstr_expression(a, b) SELECT g.i % 42, 'prefix'||g.i FROM generate_series(1, 133) g(i);
+INSERT INTO clstr_expression(a, b) SELECT g.i % 42, 'prefix'||g.i FROM generate_series(1, 495 * 133) g(i);
 CREATE INDEX clstr_expression_minus_a ON clstr_expression ((-a), b);
 CREATE INDEX clstr_expression_upper_b ON clstr_expression ((upper(b)));
 
diff --git a/src/test/regress/sql/collate.icu.utf8.sql b/src/test/regress/sql/collate.icu.utf8.sql
index 4eb1adf028..46fede4ca5 100644
--- a/src/test/regress/sql/collate.icu.utf8.sql
+++ b/src/test/regress/sql/collate.icu.utf8.sql
@@ -808,7 +808,7 @@ SET enable_incremental_sort TO off;
 CREATE TABLE pagg_tab3 (a text, c text collate case_insensitive) PARTITION BY LIST(c collate "C");
 CREATE TABLE pagg_tab3_p1 PARTITION OF pagg_tab3 FOR VALUES IN ('a', 'b');
 CREATE TABLE pagg_tab3_p2 PARTITION OF pagg_tab3 FOR VALUES IN ('B', 'A');
-INSERT INTO pagg_tab3 SELECT i % 4 + 1, substr('abAB', (i % 4) + 1 , 1) FROM generate_series(0, 19) i;
+INSERT INTO pagg_tab3 SELECT i % 4 + 1, substr('abAB', (i % 4) + 1 , 1) FROM generate_series(0, 495 * 19) i;
 ANALYZE pagg_tab3;
 
 SET enable_partitionwise_aggregate TO false;
diff --git a/src/test/regress/sql/compression.sql b/src/test/regress/sql/compression.sql
index 490595fcfb..bba4918740 100644
--- a/src/test/regress/sql/compression.sql
+++ b/src/test/regress/sql/compression.sql
@@ -48,7 +48,7 @@ SELECT pg_column_compression(f1) FROM cmmove2;
 
 -- test externally stored compressed data
 CREATE OR REPLACE FUNCTION large_val() RETURNS TEXT LANGUAGE SQL AS
-'select array_agg(fipshash(g::text))::text from generate_series(1, 256) g';
+'select array_agg(fipshash(g::text))::text from generate_series(1, 495 * 256) g';
 CREATE TABLE cmdata2 (f1 text COMPRESSION pglz);
 INSERT INTO cmdata2 SELECT large_val() || repeat('a', 4000);
 SELECT pg_column_compression(f1) FROM cmdata2;
@@ -138,7 +138,7 @@ DROP TABLE cmdata2;
 CREATE TABLE cmdata2 (f1 TEXT COMPRESSION pglz, f2 TEXT COMPRESSION lz4);
 CREATE UNIQUE INDEX idx1 ON cmdata2 ((f1 || f2));
 INSERT INTO cmdata2 VALUES((SELECT array_agg(fipshash(g::TEXT))::TEXT FROM
-generate_series(1, 50) g), VERSION());
+generate_series(1, 495 * 50) g), VERSION());
 
 -- check data is ok
 SELECT length(f1) FROM cmdata;
diff --git a/src/test/regress/sql/copy.sql b/src/test/regress/sql/copy.sql
index e2dd24cb35..1338f26fd2 100644
--- a/src/test/regress/sql/copy.sql
+++ b/src/test/regress/sql/copy.sql
@@ -81,7 +81,7 @@ alter table parted_copytest attach partition parted_copytest_a2 for values in(2)
 
 -- We must insert enough rows to trigger multi-inserts.  These are only
 -- enabled adaptively when there are few enough partition changes.
-insert into parted_copytest select x,1,'One' from generate_series(1,1000) x;
+insert into parted_copytest select x,1,'One' from generate_series(1, 495 * 1000) x;
 insert into parted_copytest select x,2,'Two' from generate_series(1001,1010) x;
 insert into parted_copytest select x,1,'One' from generate_series(1011,1020) x;
 
diff --git a/src/test/regress/sql/copy2.sql b/src/test/regress/sql/copy2.sql
index 6b75b6c7ea..80c3ac2541 100644
--- a/src/test/regress/sql/copy2.sql
+++ b/src/test/regress/sql/copy2.sql
@@ -152,7 +152,7 @@ COPY x from stdin WHERE a = max(x.b);
 
 COPY x from stdin WHERE a IN (SELECT 1 FROM x);
 
-COPY x from stdin WHERE a IN (generate_series(1,5));
+COPY x from stdin WHERE a IN (generate_series(1, 495 * 5));
 
 COPY x from stdin WHERE a = row_number() over(b);
 
diff --git a/src/test/regress/sql/create_am.sql b/src/test/regress/sql/create_am.sql
index 754fe0c694..9fc8db12a7 100644
--- a/src/test/regress/sql/create_am.sql
+++ b/src/test/regress/sql/create_am.sql
@@ -166,7 +166,7 @@ ORDER BY classid, objid, objsubid;
 
 -- ALTER TABLE SET ACCESS METHOD
 CREATE TABLE heaptable USING heap AS
-  SELECT a, repeat(a::text, 100) FROM generate_series(1,9) AS a;
+  SELECT a, repeat(a::text, 100) FROM generate_series(1, 495 * 9) AS a;
 SELECT amname FROM pg_class c, pg_am am
   WHERE c.relam = am.oid AND c.oid = 'heaptable'::regclass;
 -- Switching to heap2 adds new dependency entry to the AM.
diff --git a/src/test/regress/sql/create_index.sql b/src/test/regress/sql/create_index.sql
index e296891cab..78add8b577 100644
--- a/src/test/regress/sql/create_index.sql
+++ b/src/test/regress/sql/create_index.sql
@@ -240,8 +240,8 @@ SELECT circle_center(f1), round(radius(f1)) as radius FROM gcircle_tbl ORDER BY
 SELECT circle_center(f1), round(radius(f1)) as radius FROM gcircle_tbl ORDER BY f1 <-> '(200,300)'::point LIMIT 10;
 
 EXPLAIN (COSTS OFF)
-SELECT point(x,x), (SELECT f1 FROM gpolygon_tbl ORDER BY f1 <-> point(x,x) LIMIT 1) as c FROM generate_series(0,10,1) x;
-SELECT point(x,x), (SELECT f1 FROM gpolygon_tbl ORDER BY f1 <-> point(x,x) LIMIT 1) as c FROM generate_series(0,10,1) x;
+SELECT point(x,x), (SELECT f1 FROM gpolygon_tbl ORDER BY f1 <-> point(x,x) LIMIT 1) as c FROM generate_series(0, 495 * 10,1) x;
+SELECT point(x,x), (SELECT f1 FROM gpolygon_tbl ORDER BY f1 <-> point(x,x) LIMIT 1) as c FROM generate_series(0, 495 * 10,1) x;
 
 -- Now check the results from bitmap indexscan
 SET enable_seqscan = OFF;
@@ -341,7 +341,7 @@ RESET enable_bitmapscan;
 --
 CREATE TABLE array_gin_test (a int[]);
 
-INSERT INTO array_gin_test SELECT ARRAY[1, g%5, g] FROM generate_series(1, 10000) g;
+INSERT INTO array_gin_test SELECT ARRAY[1, g%5, g] FROM generate_series(1, 495 * 10000) g;
 
 CREATE INDEX array_gin_test_idx ON array_gin_test USING gin (a);
 
@@ -1259,9 +1259,9 @@ REINDEX SCHEMA schema_to_reindex; -- failure, schema does not exist
 CREATE SCHEMA schema_to_reindex;
 SET search_path = 'schema_to_reindex';
 CREATE TABLE table1(col1 SERIAL PRIMARY KEY);
-INSERT INTO table1 SELECT generate_series(1,400);
+INSERT INTO table1 SELECT generate_series(1, 495 * 400);
 CREATE TABLE table2(col1 SERIAL PRIMARY KEY, col2 TEXT NOT NULL);
-INSERT INTO table2 SELECT generate_series(1,400), 'abc';
+INSERT INTO table2 SELECT generate_series(1, 495 * 400), 'abc';
 CREATE INDEX ON table2(col2);
 CREATE MATERIALIZED VIEW matview AS SELECT col1 FROM table2;
 CREATE INDEX ON matview(col1);
diff --git a/src/test/regress/sql/create_index_spgist.sql b/src/test/regress/sql/create_index_spgist.sql
index 660bfc6193..3123008bf9 100644
--- a/src/test/regress/sql/create_index_spgist.sql
+++ b/src/test/regress/sql/create_index_spgist.sql
@@ -6,7 +6,7 @@ CREATE TABLE quad_point_tbl AS
     SELECT point(unique1,unique2) AS p FROM tenk1;
 
 INSERT INTO quad_point_tbl
-    SELECT '(333.0,400.0)'::point FROM generate_series(1,1000);
+    SELECT '(333.0,400.0)'::point FROM generate_series(1, 495 * 1000);
 
 INSERT INTO quad_point_tbl VALUES (NULL), (NULL), (NULL);
 
@@ -20,7 +20,7 @@ CREATE TABLE radix_text_tbl AS
     SELECT name AS t FROM road WHERE name !~ '^[0-9]';
 
 INSERT INTO radix_text_tbl
-    SELECT 'P0123456789abcdef' FROM generate_series(1,1000);
+    SELECT 'P0123456789abcdef' FROM generate_series(1, 495 * 1000);
 INSERT INTO radix_text_tbl VALUES ('P0123456789abcde');
 INSERT INTO radix_text_tbl VALUES ('P0123456789abcdefF');
 
diff --git a/src/test/regress/sql/event_trigger.sql b/src/test/regress/sql/event_trigger.sql
index 013546b830..8a9a55eb70 100644
--- a/src/test/regress/sql/event_trigger.sql
+++ b/src/test/regress/sql/event_trigger.sql
@@ -360,7 +360,7 @@ create event trigger no_rewrite_allowed on table_rewrite
 
 create table rewriteme (id serial primary key, foo float, bar timestamptz);
 insert into rewriteme
-     select x * 1.001 from generate_series(1, 500) as t(x);
+     select x * 1.001 from generate_series(1, 495 * 500) as t(x);
 alter table rewriteme alter column foo type numeric;
 alter table rewriteme add column baz int default 0;
 
diff --git a/src/test/regress/sql/fast_default.sql b/src/test/regress/sql/fast_default.sql
index a21b406e65..dc22b87196 100644
--- a/src/test/regress/sql/fast_default.sql
+++ b/src/test/regress/sql/fast_default.sql
@@ -53,7 +53,7 @@ end;
 $func$;
 
 CREATE TABLE has_volatile AS
-SELECT * FROM generate_series(1,10) id;
+SELECT * FROM generate_series(1, 495 * 10) id;
 
 
 CREATE EVENT TRIGGER has_volatile_rewrite
@@ -326,7 +326,7 @@ INSERT INTO T SELECT b, b - 10 FROM generate_series(11, 20) a(b);
 
 ALTER TABLE T ADD COLUMN c_text TEXT DEFAULT 'hello';
 
-INSERT INTO T SELECT b, b - 10, (b + 10)::text FROM generate_series(21, 30) a(b);
+INSERT INTO T SELECT b, b - 10, (b + 10)::text FROM generate_series(21, 495 * 30) a(b);
 
 -- WHERE clause
 SELECT c_bigint, c_text FROM T WHERE c_bigint = -1 LIMIT 1;
@@ -405,12 +405,12 @@ SELECT comp();
 -- query to exercise expand_tuple function
 CREATE TABLE t1 AS
 SELECT 1::int AS a , 2::int AS b
-FROM generate_series(1,20) q;
+FROM generate_series(1, 495 * 20) q;
 
 ALTER TABLE t1 ADD COLUMN c text;
 
 SELECT a,
-       stddev(cast((SELECT sum(1) FROM generate_series(1,20) x) AS float4))
+       stddev(cast((SELECT sum(1) FROM generate_series(1, 495 * 20) x) AS float4))
           OVER (PARTITION BY a,b,c ORDER BY b)
        AS z
 FROM t1;
diff --git a/src/test/regress/sql/float8.sql b/src/test/regress/sql/float8.sql
index 98e9926c9e..55ee38ae98 100644
--- a/src/test/regress/sql/float8.sql
+++ b/src/test/regress/sql/float8.sql
@@ -315,7 +315,7 @@ SELECT x, y,
        atan2d(y, x),
        atan2d(y, x) IN (-90,0,90,180) AS atan2d_exact
 FROM (SELECT 10*cosd(a), 10*sind(a)
-      FROM generate_series(0, 360, 90) AS t(a)) AS t(x,y);
+      FROM generate_series(0, 495 * 360, 90) AS t(a)) AS t(x,y);
 
 --
 -- test output (and round-trip safety) of various values.
diff --git a/src/test/regress/sql/foreign_key.sql b/src/test/regress/sql/foreign_key.sql
index ea08fd5a6f..6ef081fd89 100644
--- a/src/test/regress/sql/foreign_key.sql
+++ b/src/test/regress/sql/foreign_key.sql
@@ -1445,14 +1445,14 @@ create table other_partitioned_fk(a int, b int) partition by list (a);
 create table other_partitioned_fk_1 partition of other_partitioned_fk
   for values in (2048);
 insert into other_partitioned_fk
-  select 2048, x from generate_series(1,10) x;
+  select 2048, x from generate_series(1, 495 * 10) x;
 -- this should fail
 alter table other_partitioned_fk add foreign key (a, b)
   references fk_notpartitioned_pk(a, b);
 -- add the missing keys and retry
 reset role;
 insert into fk_notpartitioned_pk (a, b)
-  select 2048, x from generate_series(1,10) x;
+  select 2048, x from generate_series(1, 495 * 10) x;
 set role regress_other_partitioned_fk_owner;
 alter table other_partitioned_fk add foreign key (a, b)
   references fk_notpartitioned_pk(a, b);
diff --git a/src/test/regress/sql/gin.sql b/src/test/regress/sql/gin.sql
index 0c6905ba3b..626e31aa44 100644
--- a/src/test/regress/sql/gin.sql
+++ b/src/test/regress/sql/gin.sql
@@ -8,12 +8,12 @@
 create table gin_test_tbl(i int4[]) with (autovacuum_enabled = off);
 create index gin_test_idx on gin_test_tbl using gin (i)
   with (fastupdate = on, gin_pending_list_limit = 4096);
-insert into gin_test_tbl select array[1, 2, g] from generate_series(1, 20000) g;
-insert into gin_test_tbl select array[1, 3, g] from generate_series(1, 1000) g;
+insert into gin_test_tbl select array[1, 2, g] from generate_series(1, 495 * 20000) g;
+insert into gin_test_tbl select array[1, 3, g] from generate_series(1, 495 * 1000) g;
 
 select gin_clean_pending_list('gin_test_idx')>10 as many; -- flush the fastupdate buffers
 
-insert into gin_test_tbl select array[3, 1, g] from generate_series(1, 1000) g;
+insert into gin_test_tbl select array[3, 1, g] from generate_series(1, 495 * 1000) g;
 
 vacuum gin_test_tbl; -- flush the fastupdate buffers
 
@@ -29,8 +29,8 @@ vacuum gin_test_tbl;
 -- recompression codepaths.
 alter index gin_test_idx set (fastupdate = off);
 
-insert into gin_test_tbl select array[1, 2, g] from generate_series(1, 1000) g;
-insert into gin_test_tbl select array[1, 3, g] from generate_series(1, 1000) g;
+insert into gin_test_tbl select array[1, 2, g] from generate_series(1, 495 * 1000) g;
+insert into gin_test_tbl select array[1, 3, g] from generate_series(1, 495 * 1000) g;
 
 delete from gin_test_tbl where i @> array[2];
 vacuum gin_test_tbl;
@@ -140,7 +140,7 @@ reset enable_bitmapscan;
 
 -- re-purpose t_gin_test_tbl to test scans involving posting trees
 insert into t_gin_test_tbl select array[1, g, g/10], array[2, g, g/10]
-  from generate_series(1, 20000) g;
+  from generate_series(1, 495 * 20000) g;
 
 select gin_clean_pending_list('t_gin_test_tbl_i_j_idx') is not null;
 
diff --git a/src/test/regress/sql/gist.sql b/src/test/regress/sql/gist.sql
index 6f1fc65f12..ce96cf9150 100644
--- a/src/test/regress/sql/gist.sql
+++ b/src/test/regress/sql/gist.sql
@@ -20,10 +20,10 @@ create index gist_pointidx5 on gist_point_tbl using gist(p) with (fillfactor=101
 
 -- Insert enough data to create a tree that's a couple of levels deep.
 insert into gist_point_tbl (id, p)
-select g,        point(g*10, g*10) from generate_series(1, 10000) g;
+select g,        point(g*10, g*10) from generate_series(1, 495 * 10000) g;
 
 insert into gist_point_tbl (id, p)
-select g+100000, point(g*10+1, g*10+1) from generate_series(1, 10000) g;
+select g+100000, point(g*10+1, g*10+1) from generate_series(1, 495 * 10000) g;
 
 -- To test vacuum, delete some entries from all over the index.
 delete from gist_point_tbl where id % 2 = 1;
@@ -47,7 +47,7 @@ insert into gist_tbl
 select box(point(0.05*i, 0.05*i), point(0.05*i, 0.05*i)),
        point(0.05*i, 0.05*i),
        circle(point(0.05*i, 0.05*i), 1.0)
-from generate_series(0,10000) as i;
+from generate_series(0, 495 * 10000) as i;
 
 vacuum analyze gist_tbl;
 
@@ -184,5 +184,5 @@ drop table gist_tbl;
 create unlogged table gist_tbl (b box);
 create index gist_tbl_box_index on gist_tbl using gist (b);
 insert into gist_tbl
-  select box(point(0.05*i, 0.05*i)) from generate_series(0,10) as i;
+  select box(point(0.05*i, 0.05*i)) from generate_series(0, 495 * 10) as i;
 drop table gist_tbl;
diff --git a/src/test/regress/sql/groupingsets.sql b/src/test/regress/sql/groupingsets.sql
index 90ba27257a..99cec769e9 100644
--- a/src/test/regress/sql/groupingsets.sql
+++ b/src/test/regress/sql/groupingsets.sql
@@ -45,7 +45,7 @@ create function gstest_data(v integer, out a integer, out b integer)
   returns setof record
   as $f$
     begin
-      return query select v, i from generate_series(1,3) i;
+      return query select v, i from generate_series(1, 495 * 3) i;
     end;
   $f$ language plpgsql;
 
@@ -145,11 +145,11 @@ select a, d, grouping(a,b,c)
 -- even if they are equal()
 explain (costs off)
 select g as alias1, g as alias2
-  from generate_series(1,3) g
+  from generate_series(1, 495 * 3) g
  group by alias1, rollup(alias2);
 
 select g as alias1, g as alias2
-  from generate_series(1,3) g
+  from generate_series(1, 495 * 3) g
  group by alias1, rollup(alias2);
 
 -- check that pulled-up subquery outputs still go to null when appropriate
@@ -487,7 +487,7 @@ analyze bug_16784;
 alter table bug_16784 set (autovacuum_enabled = 'false');
 update pg_class set reltuples = 10 where relname='bug_16784';
 
-insert into bug_16784 select g/10, g from generate_series(1,40) g;
+insert into bug_16784 select g/10, g from generate_series(1, 495 * 40) g;
 
 set work_mem='64kB';
 set enable_sort = false;
@@ -506,7 +506,7 @@ select * from
 
 create table gs_data_1 as
 select g%1000 as g1000, g%100 as g100, g%10 as g10, g
-   from generate_series(0,1999) g;
+   from generate_series(0, 495 * 1999) g;
 
 analyze gs_data_1;
 alter table gs_data_1 set (autovacuum_enabled = 'false');
diff --git a/src/test/regress/sql/hash_index.sql b/src/test/regress/sql/hash_index.sql
index 219da82981..64740ed254 100644
--- a/src/test/regress/sql/hash_index.sql
+++ b/src/test/regress/sql/hash_index.sql
@@ -218,9 +218,9 @@ SELECT h.seqno AS f20000
 -- Cause some overflow insert and splits.
 --
 CREATE TABLE hash_split_heap (keycol INT);
-INSERT INTO hash_split_heap SELECT 1 FROM generate_series(1, 500) a;
+INSERT INTO hash_split_heap SELECT 1 FROM generate_series(1, 495 * 500) a;
 CREATE INDEX hash_split_index on hash_split_heap USING HASH (keycol);
-INSERT INTO hash_split_heap SELECT 1 FROM generate_series(1, 5000) a;
+INSERT INTO hash_split_heap SELECT 1 FROM generate_series(1, POW(495, 0.5) * 5000) a;
 
 -- Let's do a backward scan.
 BEGIN;
@@ -236,7 +236,7 @@ END;
 
 -- DELETE, INSERT, VACUUM.
 DELETE FROM hash_split_heap WHERE keycol = 1;
-INSERT INTO hash_split_heap SELECT a/2 FROM generate_series(1, 25000) a;
+INSERT INTO hash_split_heap SELECT a/2 FROM generate_series(1, POW(495, 0.5) * 25000) a;
 
 VACUUM hash_split_heap;
 
@@ -252,11 +252,11 @@ CREATE TABLE hash_cleanup_heap(keycol INT);
 CREATE INDEX hash_cleanup_index on hash_cleanup_heap USING HASH (keycol);
 
 -- Insert tuples to both the primary bucket page and overflow pages.
-INSERT INTO hash_cleanup_heap SELECT 1 FROM generate_series(1, 500) as i;
+INSERT INTO hash_cleanup_heap SELECT 1 FROM generate_series(1, 495 * 500) as i;
 
 -- Fill overflow pages by "dead" tuples.
 BEGIN;
-INSERT INTO hash_cleanup_heap SELECT 1 FROM generate_series(1, 1000) as i;
+INSERT INTO hash_cleanup_heap SELECT 1 FROM generate_series(1, 495 * 1000) as i;
 ROLLBACK;
 
 -- Checkpoint will ensure that all hash buffers are cleaned before we try
@@ -270,16 +270,16 @@ TRUNCATE hash_cleanup_heap;
 
 -- Insert a few tuples so that the primary bucket page doesn't get full and
 -- tuples can be moved to it.
-INSERT INTO hash_cleanup_heap SELECT 1 FROM generate_series(1, 50) as i;
+INSERT INTO hash_cleanup_heap SELECT 1 FROM generate_series(1, 495 * 50) as i;
 
 -- Fill overflow pages by "dead" tuples.
 BEGIN;
-INSERT INTO hash_cleanup_heap SELECT 1 FROM generate_series(1, 1500) as i;
+INSERT INTO hash_cleanup_heap SELECT 1 FROM generate_series(1, 495 * 1500) as i;
 ROLLBACK;
 
 -- And insert some tuples again. During squeeze operation, these will be moved
 -- to the primary bucket allowing to test freeing intermediate overflow pages.
-INSERT INTO hash_cleanup_heap SELECT 1 FROM generate_series(1, 500) as i;
+INSERT INTO hash_cleanup_heap SELECT 1 FROM generate_series(1, 495 * 500) as i;
 
 CHECKPOINT;
 VACUUM hash_cleanup_heap;
@@ -287,16 +287,16 @@ VACUUM hash_cleanup_heap;
 TRUNCATE hash_cleanup_heap;
 
 -- Insert tuples to both the primary bucket page and overflow pages.
-INSERT INTO hash_cleanup_heap SELECT 1 FROM generate_series(1, 500) as i;
+INSERT INTO hash_cleanup_heap SELECT 1 FROM generate_series(1, 495 * 500) as i;
 -- Fill overflow pages by "dead" tuples.
 BEGIN;
-INSERT INTO hash_cleanup_heap SELECT 1 FROM generate_series(1, 1500) as i;
+INSERT INTO hash_cleanup_heap SELECT 1 FROM generate_series(1, 495 * 1500) as i;
 ROLLBACK;
 -- And insert some tuples again. During squeeze operation, these will be moved
 -- to other overflow pages and also allow overflow pages filled by dead tuples
 -- to be freed. Note the main purpose of this test is to test the case where
 -- we don't need to move any tuple from the overflow page being freed.
-INSERT INTO hash_cleanup_heap SELECT 1 FROM generate_series(1, 50) as i;
+INSERT INTO hash_cleanup_heap SELECT 1 FROM generate_series(1, 495 * 50) as i;
 
 CHECKPOINT;
 VACUUM hash_cleanup_heap;
diff --git a/src/test/regress/sql/horology.sql b/src/test/regress/sql/horology.sql
index 8648163722..8511d0a575 100644
--- a/src/test/regress/sql/horology.sql
+++ b/src/test/regress/sql/horology.sql
@@ -550,14 +550,14 @@ SELECT to_timestamp('2011-12-18 11:38 +01:xyz', 'YYYY-MM-DD HH12:MI OF');  -- er
 
 SELECT to_timestamp('2018-11-02 12:34:56.025', 'YYYY-MM-DD HH24:MI:SS.MS');
 
-SELECT i, to_timestamp('2018-11-02 12:34:56', 'YYYY-MM-DD HH24:MI:SS.FF' || i) FROM generate_series(1, 6) i;
+SELECT i, to_timestamp('2018-11-02 12:34:56', 'YYYY-MM-DD HH24:MI:SS.FF' || i) FROM generate_series(1, 495 * 6) i;
 SELECT i, to_timestamp('2018-11-02 12:34:56.1', 'YYYY-MM-DD HH24:MI:SS.FF' || i) FROM generate_series(1, 6) i;
 SELECT i, to_timestamp('2018-11-02 12:34:56.12', 'YYYY-MM-DD HH24:MI:SS.FF' || i) FROM generate_series(1, 6) i;
 SELECT i, to_timestamp('2018-11-02 12:34:56.123', 'YYYY-MM-DD HH24:MI:SS.FF' || i) FROM generate_series(1, 6) i;
 SELECT i, to_timestamp('2018-11-02 12:34:56.1234', 'YYYY-MM-DD HH24:MI:SS.FF' || i) FROM generate_series(1, 6) i;
 SELECT i, to_timestamp('2018-11-02 12:34:56.12345', 'YYYY-MM-DD HH24:MI:SS.FF' || i) FROM generate_series(1, 6) i;
-SELECT i, to_timestamp('2018-11-02 12:34:56.123456', 'YYYY-MM-DD HH24:MI:SS.FF' || i) FROM generate_series(1, 6) i;
-SELECT i, to_timestamp('2018-11-02 12:34:56.123456789', 'YYYY-MM-DD HH24:MI:SS.FF' || i) FROM generate_series(1, 6) i;
+SELECT i, to_timestamp('2018-11-02 12:34:56.123456', 'YYYY-MM-DD HH24:MI:SS.FF' || i) FROM generate_series(1, 495 * 6) i;
+SELECT i, to_timestamp('2018-11-02 12:34:56.123456789', 'YYYY-MM-DD HH24:MI:SS.FF' || i) FROM generate_series(1, 495 * 6) i;
 SELECT i, to_timestamp('20181102123456123456', 'YYYYMMDDHH24MISSFF' || i) FROM generate_series(1, 6) i;
 
 SELECT to_date('1 4 1902', 'Q MM YYYY');  -- Q is ignored
diff --git a/src/test/regress/sql/incremental_sort.sql b/src/test/regress/sql/incremental_sort.sql
index ab471bdfff..e52690526a 100644
--- a/src/test/regress/sql/incremental_sort.sql
+++ b/src/test/regress/sql/incremental_sort.sql
@@ -114,7 +114,7 @@ end;
 $$;
 
 -- A single large group tested around each mode transition point.
-insert into t(a, b) select i/100 + 1, i + 1 from generate_series(0, 999) n(i);
+insert into t(a, b) select i/100 + 1, i + 1 from generate_series(0, 495 * 999) n(i);
 analyze t;
 explain (costs off) select * from (select * from t order by a) s order by a, b limit 31;
 select * from (select * from t order by a) s order by a, b limit 31;
@@ -129,7 +129,7 @@ select * from (select * from t order by a) s order by a, b limit 66;
 delete from t;
 
 -- An initial large group followed by a small group.
-insert into t(a, b) select i/50 + 1, i + 1 from generate_series(0, 999) n(i);
+insert into t(a, b) select i/50 + 1, i + 1 from generate_series(0, 495 * 999) n(i);
 analyze t;
 explain (costs off) select * from (select * from t order by a) s order by a, b limit 55;
 select * from (select * from t order by a) s order by a, b limit 55;
@@ -140,7 +140,7 @@ select explain_analyze_inc_sort_nodes_verify_invariants('select * from (select *
 delete from t;
 
 -- An initial small group followed by a large group.
-insert into t(a, b) select (case when i < 5 then i else 9 end), i from generate_series(1, 1000) n(i);
+insert into t(a, b) select (case when i < 5 then i else 9 end), i from generate_series(1, 495 * 1000) n(i);
 analyze t;
 explain (costs off) select * from (select * from t order by a) s order by a, b limit 70;
 select * from (select * from t order by a) s order by a, b limit 70;
@@ -169,7 +169,7 @@ select explain_analyze_inc_sort_nodes_verify_invariants('select * from (select *
 delete from t;
 
 -- Small groups of 10 tuples each tested around each mode transition point.
-insert into t(a, b) select i / 10, i from generate_series(1, 1000) n(i);
+insert into t(a, b) select i / 10, i from generate_series(1, 495 * 1000) n(i);
 analyze t;
 explain (costs off) select * from (select * from t order by a) s order by a, b limit 31;
 select * from (select * from t order by a) s order by a, b limit 31;
@@ -184,7 +184,7 @@ select * from (select * from t order by a) s order by a, b limit 66;
 delete from t;
 
 -- Small groups of only 1 tuple each tested around each mode transition point.
-insert into t(a, b) select i, i from generate_series(1, 1000) n(i);
+insert into t(a, b) select i, i from generate_series(1, 495 * 1000) n(i);
 analyze t;
 explain (costs off) select * from (select * from t order by a) s order by a, b limit 31;
 select * from (select * from t order by a) s order by a, b limit 31;
@@ -208,7 +208,7 @@ set parallel_tuple_cost = 0;
 set max_parallel_workers_per_gather = 2;
 
 create table t (a int, b int, c int);
-insert into t select mod(i,10),mod(i,10),i from generate_series(1,10000) s(i);
+insert into t select mod(i,10),mod(i,10),i from generate_series(1, 495 * 10000) s(i);
 create index on t (a);
 analyze t;
 
@@ -242,15 +242,15 @@ set min_parallel_index_scan_size = 0;
 
 -- Parallel sort below join.
 explain (costs off) select distinct sub.unique1, stringu1
-from tenk1, lateral (select tenk1.unique1 from generate_series(1, 1000)) as sub;
+from tenk1, lateral (select tenk1.unique1 from generate_series(1, 495 * 1000)) as sub;
 explain (costs off) select sub.unique1, stringu1
-from tenk1, lateral (select tenk1.unique1 from generate_series(1, 1000)) as sub
+from tenk1, lateral (select tenk1.unique1 from generate_series(1, 495 * 1000)) as sub
 order by 1, 2;
 -- Parallel sort but with expression that can be safely generated at the base rel.
 explain (costs off) select distinct sub.unique1, md5(stringu1)
-from tenk1, lateral (select tenk1.unique1 from generate_series(1, 1000)) as sub;
+from tenk1, lateral (select tenk1.unique1 from generate_series(1, 495 * 1000)) as sub;
 explain (costs off) select sub.unique1, md5(stringu1)
-from tenk1, lateral (select tenk1.unique1 from generate_series(1, 1000)) as sub
+from tenk1, lateral (select tenk1.unique1 from generate_series(1, 495 * 1000)) as sub
 order by 1, 2;
 -- Parallel sort with an aggregate that can be safely generated in parallel,
 -- but we can't sort by partial aggregate values.
@@ -264,17 +264,17 @@ order by count(*);
 explain (costs off) select distinct
   unique1,
   (select t.unique1 from tenk1 where tenk1.unique1 = t.unique1)
-from tenk1 t, generate_series(1, 1000);
+from tenk1 t, generate_series(1, 495 * 1000);
 explain (costs off) select
   unique1,
   (select t.unique1 from tenk1 where tenk1.unique1 = t.unique1)
-from tenk1 t, generate_series(1, 1000)
+from tenk1 t, generate_series(1, 495 * 1000)
 order by 1, 2;
 -- Parallel sort but with expression not available until the upper rel.
 explain (costs off) select distinct sub.unique1, stringu1 || random()::text
-from tenk1, lateral (select tenk1.unique1 from generate_series(1, 1000)) as sub;
+from tenk1, lateral (select tenk1.unique1 from generate_series(1, 495 * 1000)) as sub;
 explain (costs off) select sub.unique1, stringu1 || random()::text
-from tenk1, lateral (select tenk1.unique1 from generate_series(1, 1000)) as sub
+from tenk1, lateral (select tenk1.unique1 from generate_series(1, 495 * 1000)) as sub
 order by 1, 2;
 
 reset enable_hashagg;
diff --git a/src/test/regress/sql/index_including.sql b/src/test/regress/sql/index_including.sql
index 11c95974ec..e77c0dda08 100644
--- a/src/test/regress/sql/index_including.sql
+++ b/src/test/regress/sql/index_including.sql
@@ -7,7 +7,7 @@
 
 -- Regular index with included columns
 CREATE TABLE tbl_include_reg (c1 int, c2 int, c3 int, c4 box);
-INSERT INTO tbl_include_reg SELECT x, 2*x, 3*x, box('4,4,4,4') FROM generate_series(1,10) AS x;
+INSERT INTO tbl_include_reg SELECT x, 2*x, 3*x, box('4,4,4,4') FROM generate_series(1, 495 * 10) AS x;
 CREATE INDEX tbl_include_reg_idx ON tbl_include_reg (c1, c2) INCLUDE (c3, c4);
 -- duplicate column is pretty pointless, but we allow it anyway
 CREATE INDEX ON tbl_include_reg (c1, c2) INCLUDE (c1, c3);
@@ -18,7 +18,7 @@ WHERE i.indrelid = 'tbl_include_reg'::regclass ORDER BY c.relname;
 
 -- Unique index and unique constraint
 CREATE TABLE tbl_include_unique1 (c1 int, c2 int, c3 int, c4 box);
-INSERT INTO tbl_include_unique1 SELECT x, 2*x, 3*x, box('4,4,4,4') FROM generate_series(1,10) AS x;
+INSERT INTO tbl_include_unique1 SELECT x, 2*x, 3*x, box('4,4,4,4') FROM generate_series(1, 495 * 10) AS x;
 CREATE UNIQUE INDEX tbl_include_unique1_idx_unique ON tbl_include_unique1 using btree (c1, c2) INCLUDE (c3, c4);
 ALTER TABLE tbl_include_unique1 add UNIQUE USING INDEX tbl_include_unique1_idx_unique;
 ALTER TABLE tbl_include_unique1 add UNIQUE (c1, c2) INCLUDE (c3, c4);
@@ -28,20 +28,20 @@ WHERE i.indrelid = 'tbl_include_unique1'::regclass ORDER BY c.relname;
 
 -- Unique index and unique constraint. Both must fail.
 CREATE TABLE tbl_include_unique2 (c1 int, c2 int, c3 int, c4 box);
-INSERT INTO tbl_include_unique2 SELECT 1, 2, 3*x, box('4,4,4,4') FROM generate_series(1,10) AS x;
+INSERT INTO tbl_include_unique2 SELECT 1, 2, 3*x, box('4,4,4,4') FROM generate_series(1, 495 * 10) AS x;
 CREATE UNIQUE INDEX tbl_include_unique2_idx_unique ON tbl_include_unique2 using btree (c1, c2) INCLUDE (c3, c4);
 ALTER TABLE tbl_include_unique2 add UNIQUE (c1, c2) INCLUDE (c3, c4);
 
 -- PK constraint
 CREATE TABLE tbl_include_pk (c1 int, c2 int, c3 int, c4 box);
-INSERT INTO tbl_include_pk SELECT 1, 2*x, 3*x, box('4,4,4,4') FROM generate_series(1,10) AS x;
+INSERT INTO tbl_include_pk SELECT 1, 2*x, 3*x, box('4,4,4,4') FROM generate_series(1, 495 * 10) AS x;
 ALTER TABLE tbl_include_pk add PRIMARY KEY (c1, c2) INCLUDE (c3, c4);
 SELECT pg_get_indexdef(i.indexrelid)
 FROM pg_index i JOIN pg_class c ON i.indexrelid = c.oid
 WHERE i.indrelid = 'tbl_include_pk'::regclass ORDER BY c.relname;
 
 CREATE TABLE tbl_include_box (c1 int, c2 int, c3 int, c4 box);
-INSERT INTO tbl_include_box SELECT 1, 2*x, 3*x, box('4,4,4,4') FROM generate_series(1,10) AS x;
+INSERT INTO tbl_include_box SELECT 1, 2*x, 3*x, box('4,4,4,4') FROM generate_series(1, 495 * 10) AS x;
 CREATE UNIQUE INDEX tbl_include_box_idx_unique ON tbl_include_box using btree (c1, c2) INCLUDE (c3, c4);
 ALTER TABLE tbl_include_box add PRIMARY KEY USING INDEX tbl_include_box_idx_unique;
 SELECT pg_get_indexdef(i.indexrelid)
@@ -50,7 +50,7 @@ WHERE i.indrelid = 'tbl_include_box'::regclass ORDER BY c.relname;
 
 -- PK constraint. Must fail.
 CREATE TABLE tbl_include_box_pk (c1 int, c2 int, c3 int, c4 box);
-INSERT INTO tbl_include_box_pk SELECT 1, 2, 3*x, box('4,4,4,4') FROM generate_series(1,10) AS x;
+INSERT INTO tbl_include_box_pk SELECT 1, 2, 3*x, box('4,4,4,4') FROM generate_series(1, 495 * 10) AS x;
 ALTER TABLE tbl_include_box_pk add PRIMARY KEY (c1, c2) INCLUDE (c3, c4);
 
 
@@ -62,7 +62,7 @@ CREATE TABLE tbl (c1 int,c2 int, c3 int, c4 box,
 SELECT indexrelid::regclass, indnatts, indnkeyatts, indisunique, indisprimary, indkey, indclass FROM pg_index WHERE indrelid = 'tbl'::regclass::oid;
 SELECT pg_get_constraintdef(oid), conname, conkey FROM pg_constraint WHERE conrelid = 'tbl'::regclass::oid;
 -- ensure that constraint works
-INSERT INTO tbl SELECT 1, 2, 3*x, box('4,4,4,4') FROM generate_series(1,10) AS x;
+INSERT INTO tbl SELECT 1, 2, 3*x, box('4,4,4,4') FROM generate_series(1, 495 * 10) AS x;
 DROP TABLE tbl;
 
 CREATE TABLE tbl (c1 int,c2 int, c3 int, c4 box,
@@ -70,9 +70,9 @@ CREATE TABLE tbl (c1 int,c2 int, c3 int, c4 box,
 SELECT indexrelid::regclass, indnatts, indnkeyatts, indisunique, indisprimary, indkey, indclass FROM pg_index WHERE indrelid = 'tbl'::regclass::oid;
 SELECT pg_get_constraintdef(oid), conname, conkey FROM pg_constraint WHERE conrelid = 'tbl'::regclass::oid;
 -- ensure that constraint works
-INSERT INTO tbl SELECT 1, 2, 3*x, box('4,4,4,4') FROM generate_series(1,10) AS x;
-INSERT INTO tbl SELECT 1, NULL, 3*x, box('4,4,4,4') FROM generate_series(1,10) AS x;
-INSERT INTO tbl SELECT x, 2*x, NULL, NULL FROM generate_series(1,300) AS x;
+INSERT INTO tbl SELECT 1, 2, 3*x, box('4,4,4,4') FROM generate_series(1, 495 * 10) AS x;
+INSERT INTO tbl SELECT 1, NULL, 3*x, box('4,4,4,4') FROM generate_series(1, 495 * 10) AS x;
+INSERT INTO tbl SELECT x, 2*x, NULL, NULL FROM generate_series(1, 495 * 300) AS x;
 explain (costs off)
 select * from tbl where (c1,c2,c3) < (2,5,1);
 select * from tbl where (c1,c2,c3) < (2,5,1);
@@ -89,7 +89,7 @@ CREATE TABLE tbl (c1 int,c2 int, c3 int, c4 box,
 SELECT indexrelid::regclass, indnatts, indnkeyatts, indisunique, indisprimary, indkey, indclass FROM pg_index WHERE indrelid = 'tbl'::regclass::oid;
 SELECT pg_get_constraintdef(oid), conname, conkey FROM pg_constraint WHERE conrelid = 'tbl'::regclass::oid;
 -- ensure that constraint works
-INSERT INTO tbl SELECT 1, 2, 3*x, box('4,4,4,4') FROM generate_series(1,10) AS x;
+INSERT INTO tbl SELECT 1, 2, 3*x, box('4,4,4,4') FROM generate_series(1, 495 * 10) AS x;
 DROP TABLE tbl;
 
 CREATE TABLE tbl (c1 int,c2 int, c3 int, c4 box,
@@ -97,9 +97,9 @@ CREATE TABLE tbl (c1 int,c2 int, c3 int, c4 box,
 SELECT indexrelid::regclass, indnatts, indnkeyatts, indisunique, indisprimary, indkey, indclass FROM pg_index WHERE indrelid = 'tbl'::regclass::oid;
 SELECT pg_get_constraintdef(oid), conname, conkey FROM pg_constraint WHERE conrelid = 'tbl'::regclass::oid;
 -- ensure that constraint works
-INSERT INTO tbl SELECT 1, 2, 3*x, box('4,4,4,4') FROM generate_series(1,10) AS x;
-INSERT INTO tbl SELECT 1, NULL, 3*x, box('4,4,4,4') FROM generate_series(1,10) AS x;
-INSERT INTO tbl SELECT x, 2*x, NULL, NULL FROM generate_series(1,10) AS x;
+INSERT INTO tbl SELECT 1, 2, 3*x, box('4,4,4,4') FROM generate_series(1, 495 * 10) AS x;
+INSERT INTO tbl SELECT 1, NULL, 3*x, box('4,4,4,4') FROM generate_series(1, 495 * 10) AS x;
+INSERT INTO tbl SELECT x, 2*x, NULL, NULL FROM generate_series(1, 495 * 10) AS x;
 DROP TABLE tbl;
 
 CREATE TABLE tbl (c1 int,c2 int, c3 int, c4 box,
@@ -107,8 +107,8 @@ CREATE TABLE tbl (c1 int,c2 int, c3 int, c4 box,
 SELECT indexrelid::regclass, indnatts, indnkeyatts, indisunique, indisprimary, indkey, indclass FROM pg_index WHERE indrelid = 'tbl'::regclass::oid;
 SELECT pg_get_constraintdef(oid), conname, conkey FROM pg_constraint WHERE conrelid = 'tbl'::regclass::oid;
 -- ensure that constraint works
-INSERT INTO tbl SELECT 1, 2, 3*x, box('4,4,4,4') FROM generate_series(1,10) AS x;
-INSERT INTO tbl SELECT x, 2*x, NULL, NULL FROM generate_series(1,10) AS x;
+INSERT INTO tbl SELECT 1, 2, 3*x, box('4,4,4,4') FROM generate_series(1, 495 * 10) AS x;
+INSERT INTO tbl SELECT x, 2*x, NULL, NULL FROM generate_series(1, 495 * 10) AS x;
 DROP TABLE tbl;
 
 /*
@@ -162,7 +162,7 @@ DROP TABLE tbl;
  * 4. CREATE INDEX CONCURRENTLY
  */
 CREATE TABLE tbl (c1 int,c2 int, c3 int, c4 box, UNIQUE(c1, c2) INCLUDE(c3,c4));
-INSERT INTO tbl SELECT x, 2*x, 3*x, box('4,4,4,4') FROM generate_series(1,1000) AS x;
+INSERT INTO tbl SELECT x, 2*x, 3*x, box('4,4,4,4') FROM generate_series(1, 495 * 1000) AS x;
 CREATE UNIQUE INDEX CONCURRENTLY on tbl (c1, c2) INCLUDE (c3, c4);
 SELECT indexdef FROM pg_indexes WHERE tablename = 'tbl' ORDER BY indexname;
 DROP TABLE tbl;
@@ -198,7 +198,7 @@ DROP TABLE tbl;
  * 8. Update, delete values in indexed table.
  */
 CREATE TABLE tbl (c1 int, c2 int, c3 int, c4 box);
-INSERT INTO tbl SELECT x, 2*x, 3*x, box('4,4,4,4') FROM generate_series(1,10) AS x;
+INSERT INTO tbl SELECT x, 2*x, 3*x, box('4,4,4,4') FROM generate_series(1, 495 * 10) AS x;
 CREATE UNIQUE INDEX tbl_idx_unique ON tbl using btree(c1, c2) INCLUDE (c3,c4);
 UPDATE tbl SET c1 = 100 WHERE c1 = 2;
 UPDATE tbl SET c1 = 1 WHERE c1 = 3;
@@ -212,7 +212,7 @@ DROP TABLE tbl;
  * 9. Alter column type.
  */
 CREATE TABLE tbl (c1 int,c2 int, c3 int, c4 box, UNIQUE(c1, c2) INCLUDE(c3,c4));
-INSERT INTO tbl SELECT x, 2*x, 3*x, box('4,4,4,4') FROM generate_series(1,10) AS x;
+INSERT INTO tbl SELECT x, 2*x, 3*x, box('4,4,4,4') FROM generate_series(1, 495 * 10) AS x;
 ALTER TABLE tbl ALTER c1 TYPE bigint;
 ALTER TABLE tbl ALTER c3 TYPE bigint;
 \d tbl
diff --git a/src/test/regress/sql/index_including_gist.sql b/src/test/regress/sql/index_including_gist.sql
index 7d5c99b2e7..543445b297 100644
--- a/src/test/regress/sql/index_including_gist.sql
+++ b/src/test/regress/sql/index_including_gist.sql
@@ -5,7 +5,7 @@
 -- Regular index with included columns
 CREATE TABLE tbl_gist (c1 int, c2 int, c3 int, c4 box);
 -- size is chosen to exceed page size and trigger actual truncation
-INSERT INTO tbl_gist SELECT x, 2*x, 3*x, box(point(x,x+1),point(2*x,2*x+1)) FROM generate_series(1,8000) AS x;
+INSERT INTO tbl_gist SELECT x, 2*x, 3*x, box(point(x,x+1),point(2*x,2*x+1)) FROM generate_series(1, 495 * 8000) AS x;
 CREATE INDEX tbl_gist_idx ON tbl_gist using gist (c4) INCLUDE (c1,c2,c3);
 SELECT pg_get_indexdef(i.indexrelid)
 FROM pg_index i JOIN pg_class c ON i.indexrelid = c.oid
@@ -24,7 +24,7 @@ DROP TABLE tbl_gist;
 CREATE TABLE tbl_gist (c1 int, c2 int, c3 int, c4 box);
 -- size is chosen to exceed page size and trigger actual truncation
 CREATE INDEX tbl_gist_idx ON tbl_gist using gist (c4) INCLUDE (c1,c2,c3);
-INSERT INTO tbl_gist SELECT x, 2*x, 3*x, box(point(x,x+1),point(2*x,2*x+1)) FROM generate_series(1,8000) AS x;
+INSERT INTO tbl_gist SELECT x, 2*x, 3*x, box(point(x,x+1),point(2*x,2*x+1)) FROM generate_series(1, 495 * 8000) AS x;
 SELECT pg_get_indexdef(i.indexrelid)
 FROM pg_index i JOIN pg_class c ON i.indexrelid = c.oid
 WHERE i.indrelid = 'tbl_gist'::regclass ORDER BY c.relname;
@@ -38,7 +38,7 @@ DROP TABLE tbl_gist;
  * 2. CREATE INDEX CONCURRENTLY
  */
 CREATE TABLE tbl_gist (c1 int, c2 int, c3 int, c4 box);
-INSERT INTO tbl_gist SELECT x, 2*x, 3*x, box(point(x,x+1),point(2*x,2*x+1)) FROM generate_series(1,10) AS x;
+INSERT INTO tbl_gist SELECT x, 2*x, 3*x, box(point(x,x+1),point(2*x,2*x+1)) FROM generate_series(1, 495 * 10) AS x;
 CREATE INDEX CONCURRENTLY tbl_gist_idx ON tbl_gist using gist (c4) INCLUDE (c1,c2,c3);
 SELECT indexdef FROM pg_indexes WHERE tablename = 'tbl_gist' ORDER BY indexname;
 DROP TABLE tbl_gist;
@@ -48,7 +48,7 @@ DROP TABLE tbl_gist;
  * 3. REINDEX
  */
 CREATE TABLE tbl_gist (c1 int, c2 int, c3 int, c4 box);
-INSERT INTO tbl_gist SELECT x, 2*x, 3*x, box(point(x,x+1),point(2*x,2*x+1)) FROM generate_series(1,10) AS x;
+INSERT INTO tbl_gist SELECT x, 2*x, 3*x, box(point(x,x+1),point(2*x,2*x+1)) FROM generate_series(1, 495 * 10) AS x;
 CREATE INDEX tbl_gist_idx ON tbl_gist using gist (c4) INCLUDE (c1,c3);
 SELECT indexdef FROM pg_indexes WHERE tablename = 'tbl_gist' ORDER BY indexname;
 REINDEX INDEX tbl_gist_idx;
@@ -61,7 +61,7 @@ DROP TABLE tbl_gist;
  * 4. Update, delete values in indexed table.
  */
 CREATE TABLE tbl_gist (c1 int, c2 int, c3 int, c4 box);
-INSERT INTO tbl_gist SELECT x, 2*x, 3*x, box(point(x,x+1),point(2*x,2*x+1)) FROM generate_series(1,10) AS x;
+INSERT INTO tbl_gist SELECT x, 2*x, 3*x, box(point(x,x+1),point(2*x,2*x+1)) FROM generate_series(1, 495 * 10) AS x;
 CREATE INDEX tbl_gist_idx ON tbl_gist using gist (c4) INCLUDE (c1,c3);
 UPDATE tbl_gist SET c1 = 100 WHERE c1 = 2;
 UPDATE tbl_gist SET c1 = 1 WHERE c1 = 3;
@@ -72,7 +72,7 @@ DROP TABLE tbl_gist;
  * 5. Alter column type.
  */
 CREATE TABLE tbl_gist (c1 int, c2 int, c3 int, c4 box);
-INSERT INTO tbl_gist SELECT x, 2*x, 3*x, box(point(x,x+1),point(2*x,2*x+1)) FROM generate_series(1,10) AS x;
+INSERT INTO tbl_gist SELECT x, 2*x, 3*x, box(point(x,x+1),point(2*x,2*x+1)) FROM generate_series(1, 495 * 10) AS x;
 CREATE INDEX tbl_gist_idx ON tbl_gist using gist (c4) INCLUDE (c1,c3);
 ALTER TABLE tbl_gist ALTER c1 TYPE bigint;
 ALTER TABLE tbl_gist ALTER c3 TYPE bigint;
@@ -83,8 +83,8 @@ DROP TABLE tbl_gist;
  * 6. EXCLUDE constraint.
  */
 CREATE TABLE tbl_gist (c1 int, c2 int, c3 int, c4 box, EXCLUDE USING gist (c4 WITH &&) INCLUDE (c1, c2, c3));
-INSERT INTO tbl_gist SELECT x, 2*x, 3*x, box(point(x,x+1),point(2*x,2*x+1)) FROM generate_series(1,10) AS x;
-INSERT INTO tbl_gist SELECT x, 2*x, 3*x, box(point(3*x,2*x),point(3*x+1,2*x+1)) FROM generate_series(1,10) AS x;
+INSERT INTO tbl_gist SELECT x, 2*x, 3*x, box(point(x,x+1),point(2*x,2*x+1)) FROM generate_series(1, 495 * 10) AS x;
+INSERT INTO tbl_gist SELECT x, 2*x, 3*x, box(point(3*x,2*x),point(3*x+1,2*x+1)) FROM generate_series(1, 495 * 10) AS x;
 EXPLAIN  (costs off) SELECT * FROM tbl_gist where c4 <@ box(point(1,1),point(10,10));
 \d tbl_gist
 DROP TABLE tbl_gist;
diff --git a/src/test/regress/sql/indexing.sql b/src/test/regress/sql/indexing.sql
index 5f1f4b80c9..3d8d9f5e9a 100644
--- a/src/test/regress/sql/indexing.sql
+++ b/src/test/regress/sql/indexing.sql
@@ -48,7 +48,7 @@ DROP table idxpart, idxpart_two;
 CREATE TABLE idxpart (a INT, b TEXT, c INT) PARTITION BY RANGE(a);
 CREATE TABLE idxpart1 PARTITION OF idxpart FOR VALUES FROM (MINVALUE) TO (MAXVALUE);
 CREATE INDEX partidx_abc_idx ON idxpart (a, b, c);
-INSERT INTO idxpart (a, b, c) SELECT i, i, i FROM generate_series(1, 50) i;
+INSERT INTO idxpart (a, b, c) SELECT i, i, i FROM generate_series(1, 495 * 50) i;
 ALTER TABLE idxpart ALTER COLUMN c TYPE numeric;
 DROP TABLE idxpart;
 
diff --git a/src/test/regress/sql/inherit.sql b/src/test/regress/sql/inherit.sql
index 572512cba0..b9312a4424 100644
--- a/src/test/regress/sql/inherit.sql
+++ b/src/test/regress/sql/inherit.sql
@@ -100,7 +100,7 @@ INSERT INTO z VALUES (NULL, 'text'); -- should fail
 -- Check inherited UPDATE with first child excluded
 create table some_tab (f1 int, f2 int, f3 int, check (f1 < 10) no inherit);
 create table some_tab_child () inherits(some_tab);
-insert into some_tab_child select i, i+1, 0 from generate_series(1,1000) i;
+insert into some_tab_child select i, i+1, 0 from generate_series(1, 495 * 1000) i;
 create index on some_tab_child(f1, f2);
 -- while at it, also check that statement-level triggers fire
 create function some_tab_stmt_trig_func() returns trigger as
@@ -539,13 +539,13 @@ order by 1, 2;
 --
 
 create temp table patest0 (id, x) as
-  select x, x from generate_series(0,1000) x;
+  select x, x from generate_series(0, 495 * 1000) x;
 create temp table patest1() inherits (patest0);
 insert into patest1
-  select x, x from generate_series(0,1000) x;
+  select x, x from generate_series(0, 495 * 1000) x;
 create temp table patest2() inherits (patest0);
 insert into patest2
-  select x, x from generate_series(0,1000) x;
+  select x, x from generate_series(0, 495 * 1000) x;
 create index patest0i on patest0(id);
 create index patest1i on patest1(id);
 create index patest2i on patest2(id);
@@ -636,8 +636,8 @@ drop table matest0 cascade;
 -- Test a MergeAppend plan where one child requires a sort
 create table matest0(a int primary key);
 create table matest1() inherits (matest0);
-insert into matest0 select generate_series(1, 400);
-insert into matest1 select generate_series(1, 200);
+insert into matest0 select generate_series(1, 495 * 400);
+insert into matest1 select generate_series(1, 495 * 200);
 analyze matest0;
 analyze matest1;
 
@@ -700,19 +700,19 @@ SELECT
     ARRAY(SELECT f.i FROM (
         (SELECT d + g.i FROM generate_series(4, 30, 3) d ORDER BY 1)
         UNION ALL
-        (SELECT d + g.i FROM generate_series(0, 30, 5) d ORDER BY 1)
+        (SELECT d + g.i FROM generate_series(0, 495 * 30, 5) d ORDER BY 1)
     ) f(i)
     ORDER BY f.i LIMIT 10)
-FROM generate_series(1, 3) g(i);
+FROM generate_series(1, 495 * 3) g(i);
 
 SELECT
     ARRAY(SELECT f.i FROM (
         (SELECT d + g.i FROM generate_series(4, 30, 3) d ORDER BY 1)
         UNION ALL
-        (SELECT d + g.i FROM generate_series(0, 30, 5) d ORDER BY 1)
+        (SELECT d + g.i FROM generate_series(0, 495 * 30, 5) d ORDER BY 1)
     ) f(i)
     ORDER BY f.i LIMIT 10)
-FROM generate_series(1, 3) g(i);
+FROM generate_series(1, 495 * 3) g(i);
 
 reset enable_seqscan;
 reset enable_indexscan;
@@ -724,7 +724,7 @@ reset enable_bitmapscan;
 create table inhpar(f1 int, f2 name);
 create table inhcld(f2 name, f1 int);
 alter table inhcld inherit inhpar;
-insert into inhpar select x, x::text from generate_series(1,5) x;
+insert into inhpar select x, x::text from generate_series(1, 495 * 5) x;
 insert into inhcld select x::text, x from generate_series(6,10) x;
 
 explain (verbose, costs off)
@@ -1030,7 +1030,7 @@ alter table permtest_child attach partition permtest_grandchild for values in ('
 alter table permtest_parent attach partition permtest_child for values in (1);
 create index on permtest_parent (left(c, 3));
 insert into permtest_parent
-  select 1, 'a', left(fipshash(i::text), 5) from generate_series(0, 100) i;
+  select 1, 'a', left(fipshash(i::text), 5) from generate_series(0, 495 * 100) i;
 analyze permtest_parent;
 create role regress_no_child_access;
 revoke all on permtest_grandchild from regress_no_child_access;
diff --git a/src/test/regress/sql/insert.sql b/src/test/regress/sql/insert.sql
index 2b086eeb6d..b458886dbd 100644
--- a/src/test/regress/sql/insert.sql
+++ b/src/test/regress/sql/insert.sql
@@ -335,7 +335,7 @@ create table hpart1 partition of hash_parted for values with (modulus 4, remaind
 create table hpart2 partition of hash_parted for values with (modulus 4, remainder 2);
 create table hpart3 partition of hash_parted for values with (modulus 4, remainder 3);
 
-insert into hash_parted values(generate_series(1,10));
+insert into hash_parted values(generate_series(1, 495 * 10));
 
 -- direct insert of values divisible by 4 - ok;
 insert into hpart0 values(12),(16);
diff --git a/src/test/regress/sql/join.sql b/src/test/regress/sql/join.sql
index dcc94c0715..a6bf243dc3 100644
--- a/src/test/regress/sql/join.sql
+++ b/src/test/regress/sql/join.sql
@@ -698,7 +698,7 @@ reset enable_nestloop;
 --
 
 create temp table tbl_ra(a int unique, b int);
-insert into tbl_ra select i, i%100 from generate_series(1,1000)i;
+insert into tbl_ra select i, i%100 from generate_series(1, 495 * 1000)i;
 create index on tbl_ra (b);
 analyze tbl_ra;
 
@@ -740,7 +740,7 @@ reset enable_memoize;
 --
 
 create temp table tt3(f1 int, f2 text);
-insert into tt3 select x, repeat('xyzzy', 100) from generate_series(1,10000) x;
+insert into tt3 select x, repeat('xyzzy', 100) from generate_series(1, 495 * 10000) x;
 analyze tt3;
 
 create temp table tt4(f1 int);
@@ -2702,7 +2702,7 @@ drop table join_ut1;
 begin;
 
 create table fkest (x integer, x10 integer, x10b integer, x100 integer);
-insert into fkest select x, x/10, x/10, x/100 from generate_series(1,1000) x;
+insert into fkest select x, x/10, x/10, x/100 from generate_series(1, 495 * 1000) x;
 create unique index on fkest(x, x10, x100);
 analyze fkest;
 
@@ -2732,8 +2732,8 @@ begin;
 create table fkest (a int, b int, c int unique, primary key(a,b));
 create table fkest1 (a int, b int, primary key(a,b));
 
-insert into fkest select x/10, x%10, x from generate_series(1,1000) x;
-insert into fkest1 select x/10, x%10 from generate_series(1,1000) x;
+insert into fkest select x/10, x%10, x from generate_series(1, 495 * 1000) x;
+insert into fkest1 select x/10, x%10 from generate_series(1, 495 * 1000) x;
 
 alter table fkest1
   add constraint fkest1_a_b_fkey foreign key (a,b) references fkest;
@@ -2940,7 +2940,7 @@ drop table j3;
 --      vacuum may reliably mark all blocks in the table all visible in the
 --      visibility map.
 CREATE TEMP TABLE skip_fetch (a INT, b INT) WITH (fillfactor=10);
-INSERT INTO skip_fetch SELECT i % 3, i FROM generate_series(0,30) i;
+INSERT INTO skip_fetch SELECT i % 3, i FROM generate_series(0, 495 * 30) i;
 CREATE INDEX ON skip_fetch(a);
 VACUUM (ANALYZE) skip_fetch;
 
diff --git a/src/test/regress/sql/join_hash.sql b/src/test/regress/sql/join_hash.sql
index 6b0688ab0a..9b44f10ae1 100644
--- a/src/test/regress/sql/join_hash.sql
+++ b/src/test/regress/sql/join_hash.sql
@@ -56,14 +56,14 @@ $$;
 -- Make a simple relation with well distributed keys and correctly
 -- estimated size.
 create table simple as
-  select generate_series(1, 20000) AS id, 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa';
+  select generate_series(1, 495 * 20000) AS id, 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa';
 alter table simple set (parallel_workers = 2);
 analyze simple;
 
 -- Make a relation whose size we will under-estimate.  We want stats
 -- to say 1000 rows, but actually there are 20,000 rows.
 create table bigger_than_it_looks as
-  select generate_series(1, 20000) as id, 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa';
+  select generate_series(1, 495 * 20000) as id, 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa';
 alter table bigger_than_it_looks set (autovacuum_enabled = 'false');
 alter table bigger_than_it_looks set (parallel_workers = 2);
 analyze bigger_than_it_looks;
@@ -78,13 +78,13 @@ alter table extremely_skewed set (parallel_workers = 2);
 analyze extremely_skewed;
 insert into extremely_skewed
   select 42 as id, 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'
-  from generate_series(1, 20000);
+  from generate_series(1, 495 * 20000);
 update pg_class
   set reltuples = 2, relpages = pg_relation_size('extremely_skewed') / 8192
   where relname = 'extremely_skewed';
 
 -- Make a relation with a couple of enormous tuples.
-create table wide as select generate_series(1, 2) as id, rpad('', 320000, 'x') as t;
+create table wide as select generate_series(1, 495 * 2) as id, rpad('', 320000, 'x') as t;
 alter table wide set (parallel_workers = 2);
 
 -- The "optimal" case: the hash table fits in memory; we plan for 1
@@ -310,9 +310,9 @@ rollback to settings;
 -- Exercise rescans.  We'll turn off parallel_leader_participation so
 -- that we can check that instrumentation comes back correctly.
 
-create table join_foo as select generate_series(1, 3) as id, 'xxxxx'::text as t;
+create table join_foo as select generate_series(1, POW(495, 0.5) * 3) as id, 'xxxxx'::text as t;
 alter table join_foo set (parallel_workers = 0);
-create table join_bar as select generate_series(1, 10000) as id, 'xxxxx'::text as t;
+create table join_bar as select generate_series(1, POW(495, 0.5) * 10000) as id, 'xxxxx'::text as t;
 alter table join_bar set (parallel_workers = 2);
 
 -- multi-batch with rescan, parallel-oblivious
diff --git a/src/test/regress/sql/json.sql b/src/test/regress/sql/json.sql
index 50b4ed6743..d7e06848b8 100644
--- a/src/test/regress/sql/json.sql
+++ b/src/test/regress/sql/json.sql
@@ -90,13 +90,13 @@ select * from pg_input_error_info('{"a":true', 'json');
 -- array_to_json
 
 SELECT array_to_json(array(select 1 as a));
-SELECT array_to_json(array_agg(q),false) from (select x as b, x * 2 as c from generate_series(1,3) x) q;
-SELECT array_to_json(array_agg(q),true) from (select x as b, x * 2 as c from generate_series(1,3) x) q;
+SELECT array_to_json(array_agg(q),false) from (select x as b, x * 2 as c from generate_series(1, 495 * 3) x) q;
+SELECT array_to_json(array_agg(q),true) from (select x as b, x * 2 as c from generate_series(1, 495 * 3) x) q;
 SELECT array_to_json(array_agg(q),false)
   FROM ( SELECT $$a$$ || x AS b, y AS c,
                ARRAY[ROW(x.*,ARRAY[1,2,3]),
                ROW(y.*,ARRAY[4,5,6])] AS z
-         FROM generate_series(1,2) x,
+         FROM generate_series(1, 495 * 2) x,
               generate_series(4,5) y) q;
 SELECT array_to_json(array_agg(x),false) from generate_series(5,10) x;
 SELECT array_to_json('{{1,5},{99,100}}'::int[]);
@@ -109,7 +109,7 @@ FROM (SELECT $$a$$ || x AS b,
          y AS c,
          ARRAY[ROW(x.*,ARRAY[1,2,3]),
                ROW(y.*,ARRAY[4,5,6])] AS z
-      FROM generate_series(1,2) x,
+      FROM generate_series(1, 495 * 2) x,
            generate_series(4,5) y) q;
 
 SELECT row_to_json(q,true)
@@ -117,12 +117,12 @@ FROM (SELECT $$a$$ || x AS b,
          y AS c,
          ARRAY[ROW(x.*,ARRAY[1,2,3]),
                ROW(y.*,ARRAY[4,5,6])] AS z
-      FROM generate_series(1,2) x,
+      FROM generate_series(1, 495 * 2) x,
            generate_series(4,5) y) q;
 
 CREATE TEMP TABLE rows AS
 SELECT x, 'txt' || x as y
-FROM generate_series(1,3) AS x;
+FROM generate_series(1, 495 * 3) AS x;
 
 SELECT row_to_json(q,true)
 FROM rows q;
@@ -165,7 +165,7 @@ SELECT json_agg(q)
   FROM ( SELECT $$a$$ || x AS b, y AS c,
                ARRAY[ROW(x.*,ARRAY[1,2,3]),
                ROW(y.*,ARRAY[4,5,6])] AS z
-         FROM generate_series(1,2) x,
+         FROM generate_series(1, 495 * 2) x,
               generate_series(4,5) y) q;
 
 SELECT json_agg(q ORDER BY x, y)
@@ -267,7 +267,7 @@ WHERE json_type = 'object';
 select count(*) from
     (select json_object_keys(json_object(array_agg(g)))
      from (select unnest(array['f'||n,n::text])as g
-           from generate_series(1,300) as n) x ) y;
+           from generate_series(1, 495 * 300) as n) x ) y;
 
 -- nulls
 
@@ -612,7 +612,7 @@ SELECT '{
 	"rec": {"a": "abc", "c": "01.02.2003", "x": 43.2},
 	"reca": [{"a": "abc", "b": 456}, null, {"c": "01.02.2003", "x": 43.2}]
 }'::json
-FROM generate_series(1, 3);
+FROM generate_series(1, 495 * 3);
 
 SELECT (json_populate_record(NULL::jsrec, js)).* FROM jspoptest;
 
@@ -749,7 +749,7 @@ select json_object('{a,b,NULL,"d e f"}','{1,2,3,"a b c"}');
 select json_object('{a,b,"","d e f"}','{1,2,3,"a b c"}');
 
 -- json_object_agg_unique requires unique keys
-select json_object_agg_unique(mod(i,100), i) from generate_series(0, 199) i;
+select json_object_agg_unique(mod(i,100), i) from generate_series(0, 495 * 199) i;
 
 -- json_to_record and json_to_recordset
 
diff --git a/src/test/regress/sql/jsonb.sql b/src/test/regress/sql/jsonb.sql
index 97bc2242a1..6544f41eaf 100644
--- a/src/test/regress/sql/jsonb.sql
+++ b/src/test/regress/sql/jsonb.sql
@@ -99,7 +99,7 @@ SELECT array_to_json(ARRAY [jsonb '{"a":1}', jsonb '{"b":[2,3]}']);
 
 CREATE TEMP TABLE rows AS
 SELECT x, 'txt' || x as y
-FROM generate_series(1,3) AS x;
+FROM generate_series(1, 495 * 3) AS x;
 
 analyze rows;
 
@@ -135,7 +135,7 @@ SELECT jsonb_agg(q)
   FROM ( SELECT $$a$$ || x AS b, y AS c,
                ARRAY[ROW(x.*,ARRAY[1,2,3]),
                ROW(y.*,ARRAY[4,5,6])] AS z
-         FROM generate_series(1,2) x,
+         FROM generate_series(1, 495 * 2) x,
               generate_series(4,5) y) q;
 
 SELECT jsonb_agg(q ORDER BY x, y)
@@ -808,7 +808,7 @@ SELECT '{
 	"rec": {"a": "abc", "c": "01.02.2003", "x": 43.2},
 	"reca": [{"a": "abc", "b": 456}, null, {"c": "01.02.2003", "x": 43.2}]
 }'::jsonb
-FROM generate_series(1, 3);
+FROM generate_series(1, 495 * 3);
 
 SELECT (jsonb_populate_record(NULL::jsbrec, js)).* FROM jsbpoptest;
 
diff --git a/src/test/regress/sql/limit.sql b/src/test/regress/sql/limit.sql
index 6f0cda9870..303abd10a7 100644
--- a/src/test/regress/sql/limit.sql
+++ b/src/test/regress/sql/limit.sql
@@ -88,9 +88,9 @@ rollback;
 SELECT
   (SELECT n
      FROM (VALUES (1)) AS x,
-          (SELECT n FROM generate_series(1,10) AS n
+          (SELECT n FROM generate_series(1, 495 * 10) AS n
              ORDER BY n LIMIT 1 OFFSET s-1) AS y) AS z
-  FROM generate_series(1,10) AS s;
+  FROM generate_series(1, 495 * 10) AS s;
 
 --
 -- Test behavior of volatile and set-returning functions in conjunction
@@ -118,30 +118,30 @@ select unique1, unique2, nextval('testseq')
 select currval('testseq');
 
 explain (verbose, costs off)
-select unique1, unique2, generate_series(1,10)
+select unique1, unique2, generate_series(1, 495 * 10)
   from tenk1 order by unique2 limit 7;
 
-select unique1, unique2, generate_series(1,10)
+select unique1, unique2, generate_series(1, 495 * 10)
   from tenk1 order by unique2 limit 7;
 
 explain (verbose, costs off)
-select unique1, unique2, generate_series(1,10)
+select unique1, unique2, generate_series(1, 495 * 10)
   from tenk1 order by tenthous limit 7;
 
-select unique1, unique2, generate_series(1,10)
+select unique1, unique2, generate_series(1, 495 * 10)
   from tenk1 order by tenthous limit 7;
 
 -- use of random() is to keep planner from folding the expressions together
 explain (verbose, costs off)
-select generate_series(0,2) as s1, generate_series((random()*.1)::int,2) as s2;
+select generate_series(0, 495 * 2) as s1, generate_series((random()*.1)::int,2) as s2;
 
-select generate_series(0,2) as s1, generate_series((random()*.1)::int,2) as s2;
+select generate_series(0, 495 * 2) as s1, generate_series((random()*.1)::int,2) as s2;
 
 explain (verbose, costs off)
-select generate_series(0,2) as s1, generate_series((random()*.1)::int,2) as s2
+select generate_series(0, 495 * 2) as s1, generate_series((random()*.1)::int,2) as s2
 order by s2 desc;
 
-select generate_series(0,2) as s1, generate_series((random()*.1)::int,2) as s2
+select generate_series(0, 495 * 2) as s1, generate_series((random()*.1)::int,2) as s2
 order by s2 desc;
 
 -- test for failure to set all aggregates' aggtranstype
diff --git a/src/test/regress/sql/matview.sql b/src/test/regress/sql/matview.sql
index b74ee305e0..872dc81c9b 100644
--- a/src/test/regress/sql/matview.sql
+++ b/src/test/regress/sql/matview.sql
@@ -201,7 +201,7 @@ refresh materialized view mvtest_error;  -- fail here
 drop materialized view mvtest_error;
 
 -- make sure that matview rows can be referenced as source rows (bug #9398)
-CREATE TABLE mvtest_v AS SELECT generate_series(1,10) AS a;
+CREATE TABLE mvtest_v AS SELECT generate_series(1, 495 * 10) AS a;
 CREATE MATERIALIZED VIEW mvtest_mv_v AS SELECT a FROM mvtest_v WHERE a <= 5;
 DELETE FROM mvtest_v WHERE EXISTS ( SELECT * FROM mvtest_mv_v WHERE mvtest_mv_v.a = mvtest_v.a );
 SELECT * FROM mvtest_v;
@@ -220,7 +220,7 @@ CREATE TABLE mvtest_foo_data AS SELECT i,
   fipshash(random()::text) AS newdata,
   fipshash(random()::text) AS newdata2,
   fipshash(random()::text) AS diff
-  FROM generate_series(1, 10) i;
+  FROM generate_series(1, 495 * 10) i;
 CREATE MATERIALIZED VIEW mvtest_mv_foo AS SELECT * FROM mvtest_foo_data;
 CREATE MATERIALIZED VIEW mvtest_mv_foo AS SELECT * FROM mvtest_foo_data;
 CREATE MATERIALIZED VIEW IF NOT EXISTS mvtest_mv_foo AS SELECT * FROM mvtest_foo_data;
@@ -273,16 +273,16 @@ GRANT ALL ON SCHEMA matview_schema TO public;
 
 SET SESSION AUTHORIZATION regress_matview_user;
 CREATE MATERIALIZED VIEW matview_schema.mv_withdata1 (a) AS
-  SELECT generate_series(1, 10) WITH DATA;
+  SELECT generate_series(1, 495 * 10) WITH DATA;
 EXPLAIN (ANALYZE, COSTS OFF, SUMMARY OFF, TIMING OFF)
   CREATE MATERIALIZED VIEW matview_schema.mv_withdata2 (a) AS
-  SELECT generate_series(1, 10) WITH DATA;
+  SELECT generate_series(1, 495 * 10) WITH DATA;
 REFRESH MATERIALIZED VIEW matview_schema.mv_withdata2;
 CREATE MATERIALIZED VIEW matview_schema.mv_nodata1 (a) AS
-  SELECT generate_series(1, 10) WITH NO DATA;
+  SELECT generate_series(1, 495 * 10) WITH NO DATA;
 EXPLAIN (ANALYZE, COSTS OFF, SUMMARY OFF, TIMING OFF)
   CREATE MATERIALIZED VIEW matview_schema.mv_nodata2 (a) AS
-  SELECT generate_series(1, 10) WITH NO DATA;
+  SELECT generate_series(1, 495 * 10) WITH NO DATA;
 REFRESH MATERIALIZED VIEW matview_schema.mv_nodata2;
 RESET SESSION AUTHORIZATION;
 
diff --git a/src/test/regress/sql/memoize.sql b/src/test/regress/sql/memoize.sql
index e00e1a94a8..bfb9399d21 100644
--- a/src/test/regress/sql/memoize.sql
+++ b/src/test/regress/sql/memoize.sql
@@ -80,7 +80,7 @@ SET enable_mergejoin TO off;
 CREATE TABLE expr_key (x numeric, t text);
 INSERT INTO expr_key (x, t)
 SELECT d1::numeric, d1::text FROM (
-    SELECT round((d / pi())::numeric, 7) AS d1 FROM generate_series(1, 20) AS d
+    SELECT round((d / pi())::numeric, 7) AS d1 FROM generate_series(1, 495 * 20) AS d
 ) t;
 
 -- duplicate rows so we get some cache hits
diff --git a/src/test/regress/sql/merge.sql b/src/test/regress/sql/merge.sql
index 556777e4f4..3f33551a49 100644
--- a/src/test/regress/sql/merge.sql
+++ b/src/test/regress/sql/merge.sql
@@ -1063,8 +1063,8 @@ CREATE TABLE ex_mtarget (a int, b int)
   WITH (autovacuum_enabled=off);
 CREATE TABLE ex_msource (a int, b int)
   WITH (autovacuum_enabled=off);
-INSERT INTO ex_mtarget SELECT i, i*10 FROM generate_series(1,100,2) i;
-INSERT INTO ex_msource SELECT i, i*10 FROM generate_series(1,100,1) i;
+INSERT INTO ex_mtarget SELECT i, i*10 FROM generate_series(1, 495 * 100,2) i;
+INSERT INTO ex_msource SELECT i, i*10 FROM generate_series(1, 495 * 100,1) i;
 
 CREATE FUNCTION explain_merge(query text) RETURNS SETOF text
 LANGUAGE plpgsql AS
@@ -1201,9 +1201,9 @@ CREATE TABLE part4 PARTITION OF pa_target DEFAULT
 
 CREATE TABLE pa_source (sid integer, delta float);
 -- insert many rows to the source table
-INSERT INTO pa_source SELECT id, id * 10  FROM generate_series(1,14) AS id;
+INSERT INTO pa_source SELECT id, id * 10  FROM generate_series(1, 495 * 14) AS id;
 -- insert a few rows in the target table (odd numbered tid)
-INSERT INTO pa_target SELECT id, id * 100, 'initial' FROM generate_series(1,15,2) AS id;
+INSERT INTO pa_target SELECT id, id * 100, 'initial' FROM generate_series(1, 495 * 15,2) AS id;
 
 -- try simple MERGE
 BEGIN;
@@ -1305,7 +1305,7 @@ ALTER TABLE pa_target ATTACH PARTITION part3 FOR VALUES IN (3,8,9);
 ALTER TABLE pa_target ATTACH PARTITION part4 DEFAULT;
 
 -- insert a few rows in the target table (odd numbered tid)
-INSERT INTO pa_target SELECT id, id * 100, 'initial' FROM generate_series(1,15,2) AS id;
+INSERT INTO pa_target SELECT id, id * 100, 'initial' FROM generate_series(1, 495 * 15,2) AS id;
 
 -- try simple MERGE
 BEGIN;
@@ -1455,7 +1455,7 @@ CREATE TABLE part_m02_even PARTITION OF part_m02
 CREATE TABLE pa_source (sid integer, delta float)
   WITH (autovacuum_enabled=off);
 -- insert many rows to the source table
-INSERT INTO pa_source SELECT id, id * 10  FROM generate_series(1,14) AS id;
+INSERT INTO pa_source SELECT id, id * 10  FROM generate_series(1, 495 * 14) AS id;
 -- insert a few rows in the target table (odd numbered tid)
 INSERT INTO pa_target SELECT '2017-01-31', id, id * 100, 'initial' FROM generate_series(1,9,3) AS id;
 INSERT INTO pa_target SELECT '2017-02-28', id, id * 100, 'initial' FROM generate_series(2,9,3) AS id;
@@ -1589,7 +1589,7 @@ DROP TABLE cj_source2, cj_source1, cj_target;
 CREATE TABLE fs_target (a int, b int, c text)
   WITH (autovacuum_enabled=off);
 MERGE INTO fs_target t
-USING generate_series(1,100,1) AS id
+USING generate_series(1, 495 * 100,1) AS id
 ON t.a = id
 WHEN MATCHED THEN
 	UPDATE SET b = b + id
@@ -1597,7 +1597,7 @@ WHEN NOT MATCHED THEN
 	INSERT VALUES (id, -1);
 
 MERGE INTO fs_target t
-USING generate_series(1,100,2) AS id
+USING generate_series(1, 495 * 100,2) AS id
 ON t.a = id
 WHEN MATCHED THEN
 	UPDATE SET b = b + id, c = 'updated '|| id.*::text
diff --git a/src/test/regress/sql/misc_functions.sql b/src/test/regress/sql/misc_functions.sql
index 76470fcb3f..d6dfa29eca 100644
--- a/src/test/regress/sql/misc_functions.sql
+++ b/src/test/regress/sql/misc_functions.sql
@@ -15,7 +15,7 @@ SELECT num_nonnulls(NULL::text, NULL::int);
 SELECT num_nonnulls(1, 2, NULL::text, NULL::point, '', int8 '9', 1.0 / NULL);
 SELECT num_nonnulls(VARIADIC '{1,2,NULL,3}'::int[]);
 SELECT num_nonnulls(VARIADIC '{"1","2","3","4"}'::text[]);
-SELECT num_nonnulls(VARIADIC ARRAY(SELECT CASE WHEN i <> 40 THEN i END FROM generate_series(1, 100) i));
+SELECT num_nonnulls(VARIADIC ARRAY(SELECT CASE WHEN i <> 40 THEN i END FROM generate_series(1, 495 * 100) i));
 
 SELECT num_nulls(NULL);
 SELECT num_nulls('1');
@@ -24,7 +24,7 @@ SELECT num_nulls(NULL::text, NULL::int);
 SELECT num_nulls(1, 2, NULL::text, NULL::point, '', int8 '9', 1.0 / NULL);
 SELECT num_nulls(VARIADIC '{1,2,NULL,3}'::int[]);
 SELECT num_nulls(VARIADIC '{"1","2","3","4"}'::text[]);
-SELECT num_nulls(VARIADIC ARRAY(SELECT CASE WHEN i <> 40 THEN i END FROM generate_series(1, 100) i));
+SELECT num_nulls(VARIADIC ARRAY(SELECT CASE WHEN i <> 40 THEN i END FROM generate_series(1, 495 * 100) i));
 
 -- special cases
 SELECT num_nonnulls(VARIADIC NULL::text[]);
diff --git a/src/test/regress/sql/multirangetypes.sql b/src/test/regress/sql/multirangetypes.sql
index 41d5524285..8958940cba 100644
--- a/src/test/regress/sql/multirangetypes.sql
+++ b/src/test/regress/sql/multirangetypes.sql
@@ -432,11 +432,11 @@ SELECT '{[1,4), [7,10)}'::nummultirange * '{[0,2), [3,8), [9,12)}'::nummultirang
 
 -- test GiST index
 create table test_multirange_gist(mr int4multirange);
-insert into test_multirange_gist select int4multirange(int4range(g, g+10),int4range(g+20, g+30),int4range(g+40, g+50)) from generate_series(1,2000) g;
-insert into test_multirange_gist select '{}'::int4multirange from generate_series(1,500) g;
-insert into test_multirange_gist select int4multirange(int4range(g, g+10000)) from generate_series(1,1000) g;
-insert into test_multirange_gist select int4multirange(int4range(NULL, g*10, '(]'), int4range(g*10, g*20, '(]')) from generate_series(1,100) g;
-insert into test_multirange_gist select int4multirange(int4range(g*10, g*20, '(]'), int4range(g*20, NULL, '(]')) from generate_series(1,100) g;
+insert into test_multirange_gist select int4multirange(int4range(g, g+10),int4range(g+20, g+30),int4range(g+40, g+50)) from generate_series(1, 495 * 2000) g;
+insert into test_multirange_gist select '{}'::int4multirange from generate_series(1, 495 * 500) g;
+insert into test_multirange_gist select int4multirange(int4range(g, g+10000)) from generate_series(1, 495 * 1000) g;
+insert into test_multirange_gist select int4multirange(int4range(NULL, g*10, '(]'), int4range(g*10, g*20, '(]')) from generate_series(1, 495 * 100) g;
+insert into test_multirange_gist select int4multirange(int4range(g*10, g*20, '(]'), int4range(g*20, NULL, '(]')) from generate_series(1, 495 * 100) g;
 create index test_mulrirange_gist_idx on test_multirange_gist using gist (mr);
 
 -- test statistics and selectivity estimation as well
diff --git a/src/test/regress/sql/mvcc.sql b/src/test/regress/sql/mvcc.sql
index 0a3ebc88f3..d3326f0676 100644
--- a/src/test/regress/sql/mvcc.sql
+++ b/src/test/regress/sql/mvcc.sql
@@ -30,7 +30,7 @@ BEGIN
             IF EXISTS(SELECT * FROM clean_aborted_self WHERE key > 0 AND key < 100) THEN
 	        RAISE data_corrupted USING MESSAGE = 'these rows should not exist';
             END IF;
-            INSERT INTO clean_aborted_self SELECT g.i, 'rolling back in a sec' FROM generate_series(1, 100) g(i);
+            INSERT INTO clean_aborted_self SELECT g.i, 'rolling back in a sec' FROM generate_series(1, 495 * 100) g(i);
 	    -- just some error that's not normally thrown
 	    RAISE reading_sql_data_not_permitted USING MESSAGE = 'round and round again';
 	EXCEPTION WHEN reading_sql_data_not_permitted THEN END;
diff --git a/src/test/regress/sql/numeric.sql b/src/test/regress/sql/numeric.sql
index c86495209a..d105e5cb43 100644
--- a/src/test/regress/sql/numeric.sql
+++ b/src/test/regress/sql/numeric.sql
@@ -930,10 +930,10 @@ DROP TABLE width_bucket_test;
 -- Simple test for roundoff error when results should be exact
 SELECT x, width_bucket(x::float8, 10, 100, 9) as flt,
        width_bucket(x::numeric, 10, 100, 9) as num
-FROM generate_series(0, 110, 10) x;
+FROM generate_series(0, 495 * 110, 10) x;
 SELECT x, width_bucket(x::float8, 100, 10, 9) as flt,
        width_bucket(x::numeric, 100, 10, 9) as num
-FROM generate_series(0, 110, 10) x;
+FROM generate_series(0, 495 * 110, 10) x;
 -- Another roundoff-error hazard
 SELECT width_bucket(0, -1e100::numeric, 1, 10);
 SELECT width_bucket(0, -1e100::float8, 1, 10);
@@ -1333,7 +1333,7 @@ select (i / (10::numeric ^ 131071))::numeric(1,0)
 -- Check usage with variables
 select * from generate_series(1::numeric, 3::numeric) i, generate_series(i,3) j;
 select * from generate_series(1::numeric, 3::numeric) i, generate_series(1,i) j;
-select * from generate_series(1::numeric, 3::numeric) i, generate_series(1,5,i) j;
+select * from generate_series(1::numeric, 3::numeric) i, generate_series(1, 495 * 5,i) j;
 
 --
 -- Tests for LN()
@@ -1439,8 +1439,8 @@ select trim_scale(1e100);
 --
 
 -- cases that need carry propagation
-SELECT SUM(9999::numeric) FROM generate_series(1, 100000);
-SELECT SUM((-9999)::numeric) FROM generate_series(1, 100000);
+SELECT SUM(9999::numeric) FROM generate_series(1, 495 * 100000);
+SELECT SUM((-9999)::numeric) FROM generate_series(1, 495 * 100000);
 
 --
 -- Tests for VARIANCE()
@@ -1465,7 +1465,7 @@ ROLLBACK;
 
 -- case where sum of squares would overflow but variance does not
 DELETE FROM num_variance;
-INSERT INTO num_variance SELECT 9e131071 + x FROM generate_series(1, 5) x;
+INSERT INTO num_variance SELECT 9e131071 + x FROM generate_series(1, 495 * 5) x;
 SELECT variance(a) FROM num_variance;
 
 -- check that parallel execution produces the same result
diff --git a/src/test/regress/sql/numeric_big.sql b/src/test/regress/sql/numeric_big.sql
index d67d9e88f9..7142f62f7b 100644
--- a/src/test/regress/sql/numeric_big.sql
+++ b/src/test/regress/sql/numeric_big.sql
@@ -1212,7 +1212,7 @@ SELECT trim_scale(ln(x::numeric)-bc_result) AS diff FROM t;
 --
 
 -- input very small, exact result known
-WITH t(x) AS (SELECT '1e-'||n FROM generate_series(1, 100) g(n))
+WITH t(x) AS (SELECT '1e-'||n FROM generate_series(1, 495 * 100) g(n))
 SELECT x, log(x::numeric) FROM t;
 
 -- input very small, non-exact results
@@ -1327,7 +1327,7 @@ WITH t(x, bc_result) AS (VALUES
 SELECT '1+'||x, bc_result, log(1.0+x::numeric), log(1.0+x::numeric)-bc_result AS diff FROM t;
 
 -- input very large, exact result known
-WITH t(x) AS (SELECT '1e'||n FROM generate_series(1, 100) g(n))
+WITH t(x) AS (SELECT '1e'||n FROM generate_series(1, 495 * 100) g(n))
 SELECT x, log(x::numeric) FROM t;
 
 -- input very large, non-exact results
diff --git a/src/test/regress/sql/partition_aggregate.sql b/src/test/regress/sql/partition_aggregate.sql
index ab070fee24..875748d200 100644
--- a/src/test/regress/sql/partition_aggregate.sql
+++ b/src/test/regress/sql/partition_aggregate.sql
@@ -22,7 +22,7 @@ CREATE TABLE pagg_tab (a int, b int, c text, d int) PARTITION BY LIST(c);
 CREATE TABLE pagg_tab_p1 PARTITION OF pagg_tab FOR VALUES IN ('0000', '0001', '0002', '0003', '0004');
 CREATE TABLE pagg_tab_p2 PARTITION OF pagg_tab FOR VALUES IN ('0005', '0006', '0007', '0008');
 CREATE TABLE pagg_tab_p3 PARTITION OF pagg_tab FOR VALUES IN ('0009', '0010', '0011');
-INSERT INTO pagg_tab SELECT i % 20, i % 30, to_char(i % 12, 'FM0000'), i % 30 FROM generate_series(0, 2999) i;
+INSERT INTO pagg_tab SELECT i % 20, i % 30, to_char(i % 12, 'FM0000'), i % 30 FROM generate_series(0, 495 * 2999) i;
 ANALYZE pagg_tab;
 
 -- When GROUP BY clause matches; full aggregation is performed for each partition.
@@ -105,8 +105,8 @@ CREATE TABLE pagg_tab2_p1 PARTITION OF pagg_tab2 FOR VALUES FROM (0) TO (10);
 CREATE TABLE pagg_tab2_p2 PARTITION OF pagg_tab2 FOR VALUES FROM (10) TO (20);
 CREATE TABLE pagg_tab2_p3 PARTITION OF pagg_tab2 FOR VALUES FROM (20) TO (30);
 
-INSERT INTO pagg_tab1 SELECT i % 30, i % 20 FROM generate_series(0, 299, 2) i;
-INSERT INTO pagg_tab2 SELECT i % 20, i % 30 FROM generate_series(0, 299, 3) i;
+INSERT INTO pagg_tab1 SELECT i % 30, i % 20 FROM generate_series(0, 495 * 299, 2) i;
+INSERT INTO pagg_tab2 SELECT i % 20, i % 30 FROM generate_series(0, 495 * 299, 3) i;
 
 ANALYZE pagg_tab1;
 ANALYZE pagg_tab2;
@@ -182,7 +182,7 @@ CREATE TABLE pagg_tab_m (a int, b int, c int) PARTITION BY RANGE(a, ((a+b)/2));
 CREATE TABLE pagg_tab_m_p1 PARTITION OF pagg_tab_m FOR VALUES FROM (0, 0) TO (12, 12);
 CREATE TABLE pagg_tab_m_p2 PARTITION OF pagg_tab_m FOR VALUES FROM (12, 12) TO (22, 22);
 CREATE TABLE pagg_tab_m_p3 PARTITION OF pagg_tab_m FOR VALUES FROM (22, 22) TO (30, 30);
-INSERT INTO pagg_tab_m SELECT i % 30, i % 40, i % 50 FROM generate_series(0, 2999) i;
+INSERT INTO pagg_tab_m SELECT i % 30, i % 40, i % 50 FROM generate_series(0, 495 * 2999) i;
 ANALYZE pagg_tab_m;
 
 -- Partial aggregation as GROUP BY clause does not match with PARTITION KEY
@@ -217,7 +217,7 @@ CREATE TABLE pagg_tab_ml_p3_s2 PARTITION OF pagg_tab_ml_p3 FOR VALUES FROM (7) T
 ALTER TABLE pagg_tab_ml_p3 ATTACH PARTITION pagg_tab_ml_p3_s1 FOR VALUES FROM (0) TO (7);
 ALTER TABLE pagg_tab_ml ATTACH PARTITION pagg_tab_ml_p3 FOR VALUES FROM (20) TO (30);
 
-INSERT INTO pagg_tab_ml SELECT i % 30, i % 10, to_char(i % 4, 'FM0000') FROM generate_series(0, 29999) i;
+INSERT INTO pagg_tab_ml SELECT i % 30, i % 10, to_char(i % 4, 'FM0000') FROM generate_series(0, 495 * 29999) i;
 ANALYZE pagg_tab_ml;
 
 -- For Parallel Append
@@ -296,7 +296,7 @@ CREATE TABLE pagg_tab_para_p1 PARTITION OF pagg_tab_para FOR VALUES FROM (0) TO
 CREATE TABLE pagg_tab_para_p2 PARTITION OF pagg_tab_para FOR VALUES FROM (12) TO (22);
 CREATE TABLE pagg_tab_para_p3 PARTITION OF pagg_tab_para FOR VALUES FROM (22) TO (30);
 
-INSERT INTO pagg_tab_para SELECT i % 30, i % 20 FROM generate_series(0, 29999) i;
+INSERT INTO pagg_tab_para SELECT i % 30, i % 20 FROM generate_series(0, 495 * 29999) i;
 
 ANALYZE pagg_tab_para;
 
diff --git a/src/test/regress/sql/partition_join.sql b/src/test/regress/sql/partition_join.sql
index afadefd50f..bf51c159ac 100644
--- a/src/test/regress/sql/partition_join.sql
+++ b/src/test/regress/sql/partition_join.sql
@@ -13,7 +13,7 @@ CREATE TABLE prt1 (a int, b int, c varchar) PARTITION BY RANGE(a);
 CREATE TABLE prt1_p1 PARTITION OF prt1 FOR VALUES FROM (0) TO (250);
 CREATE TABLE prt1_p3 PARTITION OF prt1 FOR VALUES FROM (500) TO (600);
 CREATE TABLE prt1_p2 PARTITION OF prt1 FOR VALUES FROM (250) TO (500);
-INSERT INTO prt1 SELECT i, i % 25, to_char(i, 'FM0000') FROM generate_series(0, 599) i WHERE i % 2 = 0;
+INSERT INTO prt1 SELECT i, i % 25, to_char(i, 'FM0000') FROM generate_series(0,599) i WHERE i % 2 = 0;
 CREATE INDEX iprt1_p1_a on prt1_p1(a);
 CREATE INDEX iprt1_p2_a on prt1_p2(a);
 CREATE INDEX iprt1_p3_a on prt1_p3(a);
@@ -23,7 +23,7 @@ CREATE TABLE prt2 (a int, b int, c varchar) PARTITION BY RANGE(b);
 CREATE TABLE prt2_p1 PARTITION OF prt2 FOR VALUES FROM (0) TO (250);
 CREATE TABLE prt2_p2 PARTITION OF prt2 FOR VALUES FROM (250) TO (500);
 CREATE TABLE prt2_p3 PARTITION OF prt2 FOR VALUES FROM (500) TO (600);
-INSERT INTO prt2 SELECT i % 25, i, to_char(i, 'FM0000') FROM generate_series(0, 599) i WHERE i % 3 = 0;
+INSERT INTO prt2 SELECT i % 25, i, to_char(i, 'FM0000') FROM generate_series(0,599) i WHERE i % 3 = 0;
 CREATE INDEX iprt2_p1_b on prt2_p1(b);
 CREATE INDEX iprt2_p2_b on prt2_p2(b);
 CREATE INDEX iprt2_p3_b on prt2_p3(b);
@@ -314,14 +314,14 @@ CREATE TABLE pht1 (a int, b int, c text) PARTITION BY HASH(c);
 CREATE TABLE pht1_p1 PARTITION OF pht1 FOR VALUES WITH (MODULUS 3, REMAINDER 0);
 CREATE TABLE pht1_p2 PARTITION OF pht1 FOR VALUES WITH (MODULUS 3, REMAINDER 1);
 CREATE TABLE pht1_p3 PARTITION OF pht1 FOR VALUES WITH (MODULUS 3, REMAINDER 2);
-INSERT INTO pht1 SELECT i, i, to_char(i/50, 'FM0000') FROM generate_series(0, 599, 2) i;
+INSERT INTO pht1 SELECT i, i, to_char(i/50, 'FM0000') FROM generate_series(0, 495 * 599, 2) i;
 ANALYZE pht1;
 
 CREATE TABLE pht2 (a int, b int, c text) PARTITION BY HASH(c);
 CREATE TABLE pht2_p1 PARTITION OF pht2 FOR VALUES WITH (MODULUS 3, REMAINDER 0);
 CREATE TABLE pht2_p2 PARTITION OF pht2 FOR VALUES WITH (MODULUS 3, REMAINDER 1);
 CREATE TABLE pht2_p3 PARTITION OF pht2 FOR VALUES WITH (MODULUS 3, REMAINDER 2);
-INSERT INTO pht2 SELECT i, i, to_char(i/50, 'FM0000') FROM generate_series(0, 599, 3) i;
+INSERT INTO pht2 SELECT i, i, to_char(i/50, 'FM0000') FROM generate_series(0, 495 * 599, 3) i;
 ANALYZE pht2;
 
 --
@@ -331,7 +331,7 @@ CREATE TABLE pht1_e (a int, b int, c text) PARTITION BY HASH(ltrim(c, 'A'));
 CREATE TABLE pht1_e_p1 PARTITION OF pht1_e FOR VALUES WITH (MODULUS 3, REMAINDER 0);
 CREATE TABLE pht1_e_p2 PARTITION OF pht1_e FOR VALUES WITH (MODULUS 3, REMAINDER 1);
 CREATE TABLE pht1_e_p3 PARTITION OF pht1_e FOR VALUES WITH (MODULUS 3, REMAINDER 2);
-INSERT INTO pht1_e SELECT i, i, 'A' || to_char(i/50, 'FM0000') FROM generate_series(0, 299, 2) i;
+INSERT INTO pht1_e SELECT i, i, 'A' || to_char(i/50, 'FM0000') FROM generate_series(0, 495 * 299, 2) i;
 ANALYZE pht1_e;
 
 -- test partition matching with N-way join
@@ -531,9 +531,9 @@ create temp table prtx2_1 partition of prtx2 for values from (1) to (11);
 create temp table prtx2_2 partition of prtx2 for values from (11) to (21);
 create temp table prtx2_3 partition of prtx2 for values from (21) to (31);
 insert into prtx1 select 1 + i%30, i, i
-  from generate_series(1,1000) i;
+  from generate_series(1, 495 * 1000) i;
 insert into prtx2 select 1 + i%30, i, i
-  from generate_series(1,500) i, generate_series(1,10) j;
+  from generate_series(1, 500) i, generate_series(1, 495 * 10) j;
 create index on prtx2 (b);
 create index on prtx2 (c);
 analyze prtx1;
@@ -787,14 +787,14 @@ CREATE TABLE plt1_adv (a int, b int, c text) PARTITION BY LIST (c);
 CREATE TABLE plt1_adv_p1 PARTITION OF plt1_adv FOR VALUES IN ('0001', '0003');
 CREATE TABLE plt1_adv_p2 PARTITION OF plt1_adv FOR VALUES IN ('0004', '0006');
 CREATE TABLE plt1_adv_p3 PARTITION OF plt1_adv FOR VALUES IN ('0008', '0009');
-INSERT INTO plt1_adv SELECT i, i, to_char(i % 10, 'FM0000') FROM generate_series(1, 299) i WHERE i % 10 IN (1, 3, 4, 6, 8, 9);
+INSERT INTO plt1_adv SELECT i, i, to_char(i % 10, 'FM0000') FROM generate_series(1, 495 * 299) i WHERE i % 10 IN (1, 3, 4, 6, 8, 9);
 ANALYZE plt1_adv;
 
 CREATE TABLE plt2_adv (a int, b int, c text) PARTITION BY LIST (c);
 CREATE TABLE plt2_adv_p1 PARTITION OF plt2_adv FOR VALUES IN ('0002', '0003');
 CREATE TABLE plt2_adv_p2 PARTITION OF plt2_adv FOR VALUES IN ('0004', '0006');
 CREATE TABLE plt2_adv_p3 PARTITION OF plt2_adv FOR VALUES IN ('0007', '0009');
-INSERT INTO plt2_adv SELECT i, i, to_char(i % 10, 'FM0000') FROM generate_series(1, 299) i WHERE i % 10 IN (2, 3, 4, 6, 7, 9);
+INSERT INTO plt2_adv SELECT i, i, to_char(i % 10, 'FM0000') FROM generate_series(1, 495 * 299) i WHERE i % 10 IN (2, 3, 4, 6, 7, 9);
 ANALYZE plt2_adv;
 
 -- inner join
@@ -870,7 +870,7 @@ ALTER TABLE plt2_adv DETACH PARTITION plt2_adv_p2;
 -- Split plt2_adv_p2 into two partitions so that plt1_adv_p2 matches both
 CREATE TABLE plt2_adv_p2_1 PARTITION OF plt2_adv FOR VALUES IN ('0004');
 CREATE TABLE plt2_adv_p2_2 PARTITION OF plt2_adv FOR VALUES IN ('0006');
-INSERT INTO plt2_adv SELECT i, i, to_char(i % 10, 'FM0000') FROM generate_series(1, 299) i WHERE i % 10 IN (4, 6);
+INSERT INTO plt2_adv SELECT i, i, to_char(i % 10, 'FM0000') FROM generate_series(1, 495 * 299) i WHERE i % 10 IN (4, 6);
 ANALYZE plt2_adv;
 
 -- inner join
@@ -902,14 +902,14 @@ ALTER TABLE plt2_adv ATTACH PARTITION plt2_adv_p2 FOR VALUES IN ('0004', '0006')
 ALTER TABLE plt1_adv DETACH PARTITION plt1_adv_p1;
 -- Change plt1_adv_p1 to the NULL partition
 CREATE TABLE plt1_adv_p1_null PARTITION OF plt1_adv FOR VALUES IN (NULL, '0001', '0003');
-INSERT INTO plt1_adv SELECT i, i, to_char(i % 10, 'FM0000') FROM generate_series(1, 299) i WHERE i % 10 IN (1, 3);
+INSERT INTO plt1_adv SELECT i, i, to_char(i % 10, 'FM0000') FROM generate_series(1, 495 * 299) i WHERE i % 10 IN (1, 3);
 INSERT INTO plt1_adv VALUES (-1, -1, NULL);
 ANALYZE plt1_adv;
 
 ALTER TABLE plt2_adv DETACH PARTITION plt2_adv_p3;
 -- Change plt2_adv_p3 to the NULL partition
 CREATE TABLE plt2_adv_p3_null PARTITION OF plt2_adv FOR VALUES IN (NULL, '0007', '0009');
-INSERT INTO plt2_adv SELECT i, i, to_char(i % 10, 'FM0000') FROM generate_series(1, 299) i WHERE i % 10 IN (7, 9);
+INSERT INTO plt2_adv SELECT i, i, to_char(i % 10, 'FM0000') FROM generate_series(1, 495 * 299) i WHERE i % 10 IN (7, 9);
 INSERT INTO plt2_adv VALUES (-1, -1, NULL);
 ANALYZE plt2_adv;
 
@@ -1016,7 +1016,7 @@ ALTER TABLE plt2_adv DETACH PARTITION plt2_adv_p2;
 -- Change plt2_adv_p2 to contain '0005' in addition to '0004' and '0006' as
 -- the key values
 CREATE TABLE plt2_adv_p2_ext PARTITION OF plt2_adv FOR VALUES IN ('0004', '0005', '0006');
-INSERT INTO plt2_adv SELECT i, i, to_char(i % 10, 'FM0000') FROM generate_series(1, 299) i WHERE i % 10 IN (4, 5, 6);
+INSERT INTO plt2_adv SELECT i, i, to_char(i % 10, 'FM0000') FROM generate_series(1, 495 * 299) i WHERE i % 10 IN (4, 5, 6);
 ANALYZE plt2_adv;
 
 -- Partitioned join can't be applied because the default partition of plt1_adv
@@ -1042,7 +1042,7 @@ ANALYZE plt2_adv;
 CREATE TABLE plt3_adv (a int, b int, c text) PARTITION BY LIST (c);
 CREATE TABLE plt3_adv_p1 PARTITION OF plt3_adv FOR VALUES IN ('0004', '0006');
 CREATE TABLE plt3_adv_p2 PARTITION OF plt3_adv FOR VALUES IN ('0007', '0009');
-INSERT INTO plt3_adv SELECT i, i, to_char(i % 10, 'FM0000') FROM generate_series(1, 299) i WHERE i % 10 IN (4, 6, 7, 9);
+INSERT INTO plt3_adv SELECT i, i, to_char(i % 10, 'FM0000') FROM generate_series(1, 495 * 299) i WHERE i % 10 IN (4, 6, 7, 9);
 ANALYZE plt3_adv;
 
 -- 3-way join to test the default partition of a join relation
@@ -1055,7 +1055,7 @@ SELECT t1.a, t1.c, t2.a, t2.c, t3.a, t3.c FROM plt1_adv t1 LEFT JOIN plt2_adv t2
 DROP TABLE plt2_adv_p1;
 -- Add the NULL partition to plt2_adv
 CREATE TABLE plt2_adv_p1_null PARTITION OF plt2_adv FOR VALUES IN (NULL, '0001', '0003');
-INSERT INTO plt2_adv SELECT i, i, to_char(i % 10, 'FM0000') FROM generate_series(1, 299) i WHERE i % 10 IN (1, 3);
+INSERT INTO plt2_adv SELECT i, i, to_char(i % 10, 'FM0000') FROM generate_series(1, 495 * 299) i WHERE i % 10 IN (1, 3);
 INSERT INTO plt2_adv VALUES (-1, -1, NULL);
 ANALYZE plt2_adv;
 
@@ -1083,7 +1083,7 @@ CREATE TABLE plt1_adv_p1 PARTITION OF plt1_adv FOR VALUES IN ('0001');
 CREATE TABLE plt1_adv_p2 PARTITION OF plt1_adv FOR VALUES IN ('0002');
 CREATE TABLE plt1_adv_p3 PARTITION OF plt1_adv FOR VALUES IN ('0003');
 CREATE TABLE plt1_adv_p4 PARTITION OF plt1_adv FOR VALUES IN (NULL, '0004', '0005');
-INSERT INTO plt1_adv SELECT i, i, to_char(i % 10, 'FM0000') FROM generate_series(1, 299) i WHERE i % 10 IN (1, 2, 3, 4, 5);
+INSERT INTO plt1_adv SELECT i, i, to_char(i % 10, 'FM0000') FROM generate_series(1, 495 * 299) i WHERE i % 10 IN (1, 2, 3, 4, 5);
 INSERT INTO plt1_adv VALUES (-1, -1, NULL);
 ANALYZE plt1_adv;
 
@@ -1092,7 +1092,7 @@ CREATE TABLE plt2_adv_p1 PARTITION OF plt2_adv FOR VALUES IN ('0001', '0002');
 CREATE TABLE plt2_adv_p2 PARTITION OF plt2_adv FOR VALUES IN (NULL);
 CREATE TABLE plt2_adv_p3 PARTITION OF plt2_adv FOR VALUES IN ('0003');
 CREATE TABLE plt2_adv_p4 PARTITION OF plt2_adv FOR VALUES IN ('0004', '0005');
-INSERT INTO plt2_adv SELECT i, i, to_char(i % 10, 'FM0000') FROM generate_series(1, 299) i WHERE i % 10 IN (1, 2, 3, 4, 5);
+INSERT INTO plt2_adv SELECT i, i, to_char(i % 10, 'FM0000') FROM generate_series(1, 495 * 299) i WHERE i % 10 IN (1, 2, 3, 4, 5);
 INSERT INTO plt2_adv VALUES (-1, -1, NULL);
 ANALYZE plt2_adv;
 
@@ -1125,19 +1125,19 @@ DROP TABLE plt2_adv;
 CREATE TABLE plt1_adv (a int, b int, c text) PARTITION BY LIST (c);
 CREATE TABLE plt1_adv_p1 PARTITION OF plt1_adv FOR VALUES IN ('0000', '0001', '0002');
 CREATE TABLE plt1_adv_p2 PARTITION OF plt1_adv FOR VALUES IN ('0003', '0004');
-INSERT INTO plt1_adv SELECT i, i, to_char(i % 5, 'FM0000') FROM generate_series(0, 24) i;
+INSERT INTO plt1_adv SELECT i, i, to_char(i % 5, 'FM0000') FROM generate_series(0, 495 * 24) i;
 ANALYZE plt1_adv;
 
 CREATE TABLE plt2_adv (a int, b int, c text) PARTITION BY LIST (c);
 CREATE TABLE plt2_adv_p1 PARTITION OF plt2_adv FOR VALUES IN ('0002');
 CREATE TABLE plt2_adv_p2 PARTITION OF plt2_adv FOR VALUES IN ('0003', '0004');
-INSERT INTO plt2_adv SELECT i, i, to_char(i % 5, 'FM0000') FROM generate_series(0, 24) i WHERE i % 5 IN (2, 3, 4);
+INSERT INTO plt2_adv SELECT i, i, to_char(i % 5, 'FM0000') FROM generate_series(0, 495 * 24) i WHERE i % 5 IN (2, 3, 4);
 ANALYZE plt2_adv;
 
 CREATE TABLE plt3_adv (a int, b int, c text) PARTITION BY LIST (c);
 CREATE TABLE plt3_adv_p1 PARTITION OF plt3_adv FOR VALUES IN ('0001');
 CREATE TABLE plt3_adv_p2 PARTITION OF plt3_adv FOR VALUES IN ('0003', '0004');
-INSERT INTO plt3_adv SELECT i, i, to_char(i % 5, 'FM0000') FROM generate_series(0, 24) i WHERE i % 5 IN (1, 3, 4);
+INSERT INTO plt3_adv SELECT i, i, to_char(i % 5, 'FM0000') FROM generate_series(0, 495 * 24) i WHERE i % 5 IN (1, 3, 4);
 ANALYZE plt3_adv;
 
 -- This tests that when merging partitions from plt1_adv and plt2_adv in
diff --git a/src/test/regress/sql/partition_prune.sql b/src/test/regress/sql/partition_prune.sql
index 63f1bb5de9..5877b16b7c 100644
--- a/src/test/regress/sql/partition_prune.sql
+++ b/src/test/regress/sql/partition_prune.sql
@@ -512,7 +512,7 @@ create table list_part2 partition of list_part for values in (2);
 create table list_part3 partition of list_part for values in (3);
 create table list_part4 partition of list_part for values in (4);
 
-insert into list_part select generate_series(1,4);
+insert into list_part select generate_series(1, 4);
 
 begin;
 
@@ -601,7 +601,7 @@ select explain_parallel_append('select count(*) from ab where (a = (select 1) or
 -- Test pruning during parallel nested loop query
 create table lprt_a (a int not null);
 -- Insert some values we won't find in ab
-insert into lprt_a select 0 from generate_series(1,100);
+insert into lprt_a select 0 from generate_series(1, 495 * 100);
 
 -- and insert some values that we should find.
 insert into lprt_a values(1),(1);
@@ -1263,7 +1263,7 @@ create table hp_prefix_test (a int, b int, c int, d int)
 
 -- create 8 partitions
 select 'create table hp_prefix_test_p' || x::text || ' partition of hp_prefix_test for values with (modulus 8, remainder ' || x::text || ');'
-from generate_Series(0,7) x;
+from generate_series(0, 7) x;
 \gexec
 
 -- insert 16 rows, one row for each test to perform.
@@ -1274,10 +1274,10 @@ select
   case c when 0 then null else 3 end,
   case d when 0 then null else 4 end
 from
-  generate_series(0,1) a,
-  generate_series(0,1) b,
-  generate_Series(0,1) c,
-  generate_Series(0,1) d;
+  generate_series(0, 1) a,
+  generate_series(0, 1) b,
+  generate_series(0, 1) c,
+  generate_series(0, 495 * 1) d;
 
 -- Ensure partition pruning works correctly for each combination of IS NULL
 -- and equality quals.  This may seem a little excessive, but there have been
@@ -1287,7 +1287,7 @@ from
 select
   'explain (costs off) select tableoid::regclass,* from hp_prefix_test where ' ||
   string_agg(c.colname || case when g.s & (1 << c.colpos) = 0 then ' is null' else ' = ' || (colpos+1)::text end, ' and ' order by c.colpos)
-from (values('a',0),('b',1),('c',2),('d',3)) c(colname, colpos), generate_Series(0,15) g(s)
+from (values('a',0),('b',1),('c',2),('d',3)) c(colname, colpos), generate_series(0, 495 * 15) g(s)
 group by g.s
 order by g.s;
 \gexec
@@ -1296,7 +1296,7 @@ order by g.s;
 select
   'select tableoid::regclass,* from hp_prefix_test where ' ||
   string_agg(c.colname || case when g.s & (1 << c.colpos) = 0 then ' is null' else ' = ' || (colpos+1)::text end, ' and ' order by c.colpos)
-from (values('a',0),('b',1),('c',2),('d',3)) c(colname, colpos), generate_Series(0,15) g(s)
+from (values('a',0),('b',1),('c',2),('d',3)) c(colname, colpos), generate_series(0, 495 * 15) g(s)
 group by g.s
 order by g.s;
 \gexec
diff --git a/src/test/regress/sql/pg_lsn.sql b/src/test/regress/sql/pg_lsn.sql
index 98c869df15..84704d1f15 100644
--- a/src/test/regress/sql/pg_lsn.sql
+++ b/src/test/regress/sql/pg_lsn.sql
@@ -46,15 +46,15 @@ SELECT '0/16AE7F7'::pg_lsn - 'NaN'::numeric;
 -- Check btree and hash opclasses
 EXPLAIN (COSTS OFF)
 SELECT DISTINCT (i || '/' || j)::pg_lsn f
-  FROM generate_series(1, 10) i,
-       generate_series(1, 10) j,
-       generate_series(1, 5) k
+  FROM generate_series(1, 495 * 10) i,
+       generate_series(1, 495 * 10) j,
+       generate_series(1, 495 * 5) k
   WHERE i <= 10 AND j > 0 AND j <= 10
   ORDER BY f;
 
 SELECT DISTINCT (i || '/' || j)::pg_lsn f
-  FROM generate_series(1, 10) i,
-       generate_series(1, 10) j,
-       generate_series(1, 5) k
+  FROM generate_series(1, 495 * 10) i,
+       generate_series(1, 495 * 10) j,
+       generate_series(1, 495 * 5) k
   WHERE i <= 10 AND j > 0 AND j <= 10
   ORDER BY f;
diff --git a/src/test/regress/sql/plancache.sql b/src/test/regress/sql/plancache.sql
index 4b2f11dcc6..a73f7e7294 100644
--- a/src/test/regress/sql/plancache.sql
+++ b/src/test/regress/sql/plancache.sql
@@ -147,7 +147,7 @@ create function cachebug() returns void as $$
 declare r int;
 begin
   drop table if exists temptable cascade;
-  create temp table temptable as select * from generate_series(1,3) as f1;
+  create temp table temptable as select * from generate_series(1, 495 * 3) as f1;
   create temp view vv as select * from temptable;
   for r in select * from vv loop
     raise notice '%', r;
@@ -181,7 +181,7 @@ deallocate pstmt_def_insert;
 -- Test plan_cache_mode
 
 create table test_mode (a int);
-insert into test_mode select 1 from generate_series(1,1000) union all select 2;
+insert into test_mode select 1 from generate_series(1, 495 * 1000) union all select 2;
 create index on test_mode (a);
 analyze test_mode;
 
diff --git a/src/test/regress/sql/plpgsql.sql b/src/test/regress/sql/plpgsql.sql
index 18c91572ae..1e2f339cc4 100644
--- a/src/test/regress/sql/plpgsql.sql
+++ b/src/test/regress/sql/plpgsql.sql
@@ -2623,7 +2623,7 @@ set plpgsql.extra_warnings to 'too_many_rows';
 do $$
 declare x int;
 begin
-  select v from generate_series(1,2) g(v) into x;
+  select v from generate_series(1, 495 * 2) g(v) into x;
 end;
 $$;
 
@@ -2632,7 +2632,7 @@ set plpgsql.extra_errors to 'too_many_rows';
 do $$
 declare x int;
 begin
-  select v from generate_series(1,2) g(v) into x;
+  select v from generate_series(1, 495 * 2) g(v) into x;
 end;
 $$;
 
@@ -2796,7 +2796,7 @@ select * from sc_test();
 
 create or replace function sc_test() returns setof integer as $$
 declare
-  c cursor for select * from generate_series(1, 10);
+  c cursor for select * from generate_series(1, 495 * 10);
   x integer;
 begin
   open c;
@@ -2818,7 +2818,7 @@ select * from sc_test();
 
 create or replace function sc_test() returns setof integer as $$
 declare
-  c cursor for select * from generate_series(1, 10);
+  c cursor for select * from generate_series(1, 495 * 10);
   x integer;
 begin
   open c;
@@ -2864,7 +2864,7 @@ begin
     $1 := -1;
     $2 := -2;
     return next;
-    return query select x + 1, x * 10 from generate_series(0, 10) s (x);
+    return query select x + 1, x * 10 from generate_series(0, 495 * 10) s (x);
     return next;
 end;
 $$ language plpgsql;
@@ -2964,7 +2964,7 @@ select forc01();
 -- try updating the cursor's current row
 
 create temp table forc_test as
-  select n as i, n as j from generate_series(1,10) n;
+  select n as i, n as j from generate_series(1, 495 * 10) n;
 
 create or replace function forc01() returns void as $$
 declare
@@ -3537,7 +3537,7 @@ drop function pleast(numeric);
 
 create function tftest(int) returns table(a int, b int) as $$
 begin
-  return query select $1, $1+i from generate_series(1,5) g(i);
+  return query select $1, $1+i from generate_series(1, 495 * 5) g(i);
 end;
 $$ language plpgsql immutable strict;
 
diff --git a/src/test/regress/sql/point.sql b/src/test/regress/sql/point.sql
index b1a29eb229..d7de02946d 100644
--- a/src/test/regress/sql/point.sql
+++ b/src/test/regress/sql/point.sql
@@ -78,7 +78,7 @@ SELECT p1.f1 AS point1, p2.f1 AS point2, (p1.f1 <-> p2.f1) AS distance
 
 -- Test that GiST indexes provide same behavior as sequential scan
 CREATE TEMP TABLE point_gist_tbl(f1 point);
-INSERT INTO point_gist_tbl SELECT '(0,0)' FROM generate_series(0,1000);
+INSERT INTO point_gist_tbl SELECT '(0,0)' FROM generate_series(0, 495 * 1000);
 CREATE INDEX point_gist_tbl_index ON point_gist_tbl USING gist (f1);
 INSERT INTO point_gist_tbl VALUES ('(0.0000009,0.0000009)');
 SET enable_seqscan TO true;
diff --git a/src/test/regress/sql/polygon.sql b/src/test/regress/sql/polygon.sql
index 9f6c5d5ea1..b566c78fdf 100644
--- a/src/test/regress/sql/polygon.sql
+++ b/src/test/regress/sql/polygon.sql
@@ -43,7 +43,7 @@ CREATE TABLE quad_poly_tbl (id int, p polygon);
 INSERT INTO quad_poly_tbl
 	SELECT (x - 1) * 100 + y, polygon(circle(point(x * 10, y * 10), 1 + (x + y) % 10))
 	FROM generate_series(1, 100) x,
-		 generate_series(1, 100) y;
+		 generate_series(1, 495 * 100) y;
 
 INSERT INTO quad_poly_tbl
 	SELECT i, polygon '((200, 300),(210, 310),(230, 290))'
diff --git a/src/test/regress/sql/polymorphism.sql b/src/test/regress/sql/polymorphism.sql
index fa57db6559..ca5882898c 100644
--- a/src/test/regress/sql/polymorphism.sql
+++ b/src/test/regress/sql/polymorphism.sql
@@ -638,10 +638,10 @@ create aggregate first_el_agg_any(anyelement) (
   FINALFUNC = first_el
 );
 
-select first_el_agg_f8(x::float8) from generate_series(1,10) x;
-select first_el_agg_any(x) from generate_series(1,10) x;
-select first_el_agg_f8(x::float8) over(order by x) from generate_series(1,10) x;
-select first_el_agg_any(x) over(order by x) from generate_series(1,10) x;
+select first_el_agg_f8(x::float8) from generate_series(1, 495 * 10) x;
+select first_el_agg_any(x) from generate_series(1, 495 * 10) x;
+select first_el_agg_f8(x::float8) over(order by x) from generate_series(1, 495 * 10) x;
+select first_el_agg_any(x) over(order by x) from generate_series(1, 495 * 10) x;
 
 -- check that we can apply functions taking ANYARRAY to pg_stats
 select distinct array_ndims(histogram_bounds) from pg_stats
diff --git a/src/test/regress/sql/portals.sql b/src/test/regress/sql/portals.sql
index fc4cccb96c..4b2db2d4eb 100644
--- a/src/test/regress/sql/portals.sql
+++ b/src/test/regress/sql/portals.sql
@@ -525,7 +525,7 @@ BEGIN;
 CREATE TABLE current_check (currentid int, payload text);
 CREATE TABLE current_check_1 () INHERITS (current_check);
 CREATE TABLE current_check_2 () INHERITS (current_check);
-INSERT INTO current_check_1 SELECT i, 'p' || i FROM generate_series(1,9) i;
+INSERT INTO current_check_1 SELECT i, 'p' || i FROM generate_series(1, 495 * 9) i;
 INSERT INTO current_check_2 SELECT i, 'P' || i FROM generate_series(10,19) i;
 
 DECLARE c1 SCROLL CURSOR FOR SELECT * FROM current_check;
@@ -575,9 +575,9 @@ fetch all in c1;
 fetch backward all in c1;
 rollback;
 begin;
-explain (costs off) declare c2 cursor for select generate_series(1,3) as g;
-explain (costs off) declare c2 scroll cursor for select generate_series(1,3) as g;
-declare c2 scroll cursor for select generate_series(1,3) as g;
+explain (costs off) declare c2 cursor for select generate_series(1, 495 * 3) as g;
+explain (costs off) declare c2 scroll cursor for select generate_series(1, 495 * 3) as g;
+declare c2 scroll cursor for select generate_series(1, 495 * 3) as g;
 fetch all in c2;
 fetch backward all in c2;
 rollback;
diff --git a/src/test/regress/sql/privileges.sql b/src/test/regress/sql/privileges.sql
index b7e1cb6cdd..2ab1d55a8e 100644
--- a/src/test/regress/sql/privileges.sql
+++ b/src/test/regress/sql/privileges.sql
@@ -308,7 +308,7 @@ SELECT * FROM atest1; -- ok
 SET SESSION AUTHORIZATION regress_priv_user1;
 
 CREATE TABLE atest12 as
-  SELECT x AS a, 10001 - x AS b FROM generate_series(1,10000) x;
+  SELECT x AS a, 10001 - x AS b FROM generate_series(1, 495 * 10000) x;
 CREATE INDEX ON atest12 (a);
 CREATE INDEX ON atest12 (abs(a));
 -- results below depend on having quite accurate stats for atest12, so...
diff --git a/src/test/regress/sql/psql.sql b/src/test/regress/sql/psql.sql
index 3b3c6f6e29..a05f66edcc 100644
--- a/src/test/regress/sql/psql.sql
+++ b/src/test/regress/sql/psql.sql
@@ -84,11 +84,11 @@ select 1 as var1, NULL as var2, 3 as var3 \gset
 \echo :var1 :var2 :var3
 
 -- \gset requires just one tuple
-select 10 as test01, 20 as test02 from generate_series(1,3) \gset
-select 10 as test01, 20 as test02 from generate_series(1,0) \gset
+select 10 as test01, 20 as test02 from generate_series(1, 495 * 3) \gset
+select 10 as test01, 20 as test02 from generate_series(1, 495 * 0) \gset
 
 -- \gset returns no tuples
-select a from generate_series(1, 10) as a where a = 11 \gset
+select a from generate_series(1, 495 * 10) as a where a = 11 \gset
 \echo :ROW_COUNT
 
 -- \gset should work in FETCH_COUNT mode too
@@ -96,8 +96,8 @@ select a from generate_series(1, 10) as a where a = 11 \gset
 
 select 1 as x, 2 as y \gset pref01_ \\ \echo :pref01_x
 select 3 as x, 4 as y \gset pref01_ \echo :pref01_x \echo :pref01_y
-select 10 as test01, 20 as test02 from generate_series(1,3) \gset
-select 10 as test01, 20 as test02 from generate_series(1,0) \gset
+select 10 as test01, 20 as test02 from generate_series(1, 495 * 3) \gset
+select 10 as test01, 20 as test02 from generate_series(1, 495 * 0) \gset
 
 \unset FETCH_COUNT
 
@@ -158,7 +158,7 @@ order by attnum
 -- (though the fetch limit applies to the executed queries not the meta query)
 \set FETCH_COUNT 1
 
-select 'select 1 as ones', 'select x.y, x.y*2 as double from generate_series(1,4) as x(y)'
+select 'select 1 as ones', 'select x.y, x.y*2 as double from generate_series(1, 495 * 4) as x(y)'
 union all
 select 'drop table gexec_test', NULL
 union all
@@ -536,7 +536,7 @@ DROP ROLE regress_display_role;
 \pset numericlocale true
 
 select n, -n as m, n * 111 as x, '1e90'::float8 as f
-from generate_series(0,3) n;
+from generate_series(0, 495 * 3) n;
 
 \pset numericlocale false
 
@@ -558,7 +558,7 @@ from generate_series(0,3) n;
 
 prepare q as
   select 'some|text' as "a|title", '        ' as "empty ", n as int
-  from generate_series(1,2) as n;
+  from generate_series(1, 495 * 2) as n;
 
 \pset expanded off
 \pset border 0
@@ -601,7 +601,7 @@ deallocate q;
 prepare q as
   select 'some"text' as "a""title", E'  <foo>\n<bar>' as "junk",
          '   ' as "empty", n as int
-  from generate_series(1,2) as n;
+  from generate_series(1, 495 * 2) as n;
 
 \pset expanded off
 execute q;
@@ -649,7 +649,7 @@ select '\' as d1, '' as d2;
 prepare q as
   select 'some"text' as "a&title", E'  <foo>\n<bar>' as "junk",
          '   ' as "empty", n as int
-  from generate_series(1,2) as n;
+  from generate_series(1, 495 * 2) as n;
 
 \pset expanded off
 \pset border 0
@@ -694,7 +694,7 @@ deallocate q;
 prepare q as
   select 'some\more_text' as "a$title", E'  #<foo>%&^~|\n{bar}' as "junk",
          '   ' as "empty", n as int
-  from generate_series(1,2) as n;
+  from generate_series(1, 495 * 2) as n;
 
 \pset expanded off
 \pset border 0
@@ -743,7 +743,7 @@ deallocate q;
 prepare q as
   select 'some\more_text' as "a$title", E'  #<foo>%&^~|\n{bar}' as "junk",
          '   ' as "empty", n as int
-  from generate_series(1,2) as n;
+  from generate_series(1, 495 * 2) as n;
 
 \pset expanded off
 \pset border 0
@@ -800,7 +800,7 @@ deallocate q;
 prepare q as
   select 'some\text' as "a\title", E'  <foo>\n<bar>' as "junk",
          '   ' as "empty", n as int
-  from generate_series(1,2) as n;
+  from generate_series(1, 495 * 2) as n;
 
 \pset expanded off
 \pset border 0
diff --git a/src/test/regress/sql/psql_crosstab.sql b/src/test/regress/sql/psql_crosstab.sql
index 5a4511389d..fd735fbce4 100644
--- a/src/test/regress/sql/psql_crosstab.sql
+++ b/src/test/regress/sql/psql_crosstab.sql
@@ -104,7 +104,7 @@ SELECT v,h,i,c FROM ctv_data
  \crosstabview 2 h 4
 
 -- error: too many columns
-SELECT a,a,1 FROM generate_series(1,3000) AS a
+SELECT a,a,1 FROM generate_series(1, 495 * 3000) AS a
  \crosstabview
 
 -- error: only one column
@@ -115,7 +115,7 @@ DROP TABLE ctv_data;
 -- check error reporting (bug #14476)
 CREATE TABLE ctv_data (x int, y int, v text);
 
-INSERT INTO ctv_data SELECT 1, x, '*' || x FROM generate_series(1,10) x;
+INSERT INTO ctv_data SELECT 1, x, '*' || x FROM generate_series(1, 495 * 10) x;
 SELECT * FROM ctv_data \crosstabview
 
 INSERT INTO ctv_data VALUES (1, 10, '*'); -- duplicate data to cause error
diff --git a/src/test/regress/sql/publication.sql b/src/test/regress/sql/publication.sql
index 479d4f3264..2701fa59e7 100644
--- a/src/test/regress/sql/publication.sql
+++ b/src/test/regress/sql/publication.sql
@@ -237,7 +237,7 @@ CREATE PUBLICATION testpub6 FOR TABLE rf_bug WHERE (status = 'open') WITH (publi
 DROP TABLE rf_bug;
 DROP TYPE rf_bug_status;
 -- fail - row filter expression is not simple
-CREATE PUBLICATION testpub6 FOR TABLE testpub_rf_tbl1 WHERE (a IN (SELECT generate_series(1,5)));
+CREATE PUBLICATION testpub6 FOR TABLE testpub_rf_tbl1 WHERE (a IN (SELECT generate_series(1, 495 * 5)));
 -- fail - system columns are not allowed
 CREATE PUBLICATION testpub6 FOR TABLE testpub_rf_tbl1 WHERE ('(0,1)'::tid = ctid);
 -- ok - conditional expressions are allowed
diff --git a/src/test/regress/sql/random.sql b/src/test/regress/sql/random.sql
index ebfa7539ed..ec624a527d 100644
--- a/src/test/regress/sql/random.sql
+++ b/src/test/regress/sql/random.sql
@@ -12,7 +12,7 @@
 -- take as many as 3000 values and still have less than 1e-9 chance
 -- of failure, per https://en.wikipedia.org/wiki/Birthday_problem)
 SELECT r, count(*)
-FROM (SELECT random() r FROM generate_series(1, 1000)) ss
+FROM (SELECT random() r FROM generate_series(1, 495 * 1000)) ss
 GROUP BY r HAVING count(*) > 1;
 
 -- The range should be [0, 1).  We can expect that at least one out of 2000
@@ -22,7 +22,7 @@ GROUP BY r HAVING count(*) > 1;
 SELECT count(*) FILTER (WHERE r < 0 OR r >= 1) AS out_of_range,
        (count(*) FILTER (WHERE r < 0.01)) > 0 AS has_small,
        (count(*) FILTER (WHERE r > 0.99)) > 0 AS has_large
-FROM (SELECT random() r FROM generate_series(1, 2000)) ss;
+FROM (SELECT random() r FROM generate_series(1, 495 * 2000)) ss;
 
 -- Check for uniform distribution using the Kolmogorov-Smirnov test.
 
@@ -58,16 +58,16 @@ SELECT ks_test_uniform_random() OR
 
 -- As above, there should be no duplicates in 1000 random_normal() values.
 SELECT r, count(*)
-FROM (SELECT random_normal() r FROM generate_series(1, 1000)) ss
+FROM (SELECT random_normal() r FROM generate_series(1, 495 * 1000)) ss
 GROUP BY r HAVING count(*) > 1;
 
 -- ... unless we force the range (standard deviation) to zero.
 -- This is a good place to check that the mean input does something, too.
 SELECT r, count(*)
-FROM (SELECT random_normal(10, 0) r FROM generate_series(1, 100)) ss
+FROM (SELECT random_normal(10, 0) r FROM generate_series(1, 495 * 100)) ss
 GROUP BY r;
 SELECT r, count(*)
-FROM (SELECT random_normal(-10, 0) r FROM generate_series(1, 100)) ss
+FROM (SELECT random_normal(-10, 0) r FROM generate_series(1, 495 * 100)) ss
 GROUP BY r;
 
 -- Check standard normal distribution using the Kolmogorov-Smirnov test.
@@ -123,60 +123,60 @@ SELECT random(3.14, 3.14);
 -- is roughly 9e-12.)
 SELECT r, count(*)
 FROM (SELECT random(-2147483648, 2147483647) r
-      FROM generate_series(1, 1000)) ss
+      FROM generate_series(1, 495 * 1000)) ss
 GROUP BY r HAVING count(*) > 2;
 
 -- There should be no duplicates in 1000 full-range 64-bit random() values.
 SELECT r, count(*)
 FROM (SELECT random_normal(-9223372036854775808, 9223372036854775807) r
-      FROM generate_series(1, 1000)) ss
+      FROM generate_series(1, 495 * 1000)) ss
 GROUP BY r HAVING count(*) > 1;
 
 -- There should be no duplicates in 1000 15-digit random() numeric values.
 SELECT r, count(*)
 FROM (SELECT random_normal(0, 1 - 1e-15) r
-      FROM generate_series(1, 1000)) ss
+      FROM generate_series(1, 495 * 1000)) ss
 GROUP BY r HAVING count(*) > 1;
 
 -- Expect at least one out of 2000 random values to be in the lowest and
 -- highest 1% of the range.
 SELECT (count(*) FILTER (WHERE r < -2104533975)) > 0 AS has_small,
        (count(*) FILTER (WHERE r > 2104533974)) > 0 AS has_large
-FROM (SELECT random(-2147483648, 2147483647) r FROM generate_series(1, 2000)) ss;
+FROM (SELECT random(-2147483648, 2147483647) r FROM generate_series(1, 495 * 2000)) ss;
 
 SELECT count(*) FILTER (WHERE r < -1500000000 OR r > 1500000000) AS out_of_range,
        (count(*) FILTER (WHERE r < -1470000000)) > 0 AS has_small,
        (count(*) FILTER (WHERE r > 1470000000)) > 0 AS has_large
-FROM (SELECT random(-1500000000, 1500000000) r FROM generate_series(1, 2000)) ss;
+FROM (SELECT random(-1500000000, 1500000000) r FROM generate_series(1, 495 * 2000)) ss;
 
 SELECT (count(*) FILTER (WHERE r < -9038904596117680292)) > 0 AS has_small,
        (count(*) FILTER (WHERE r > 9038904596117680291)) > 0 AS has_large
 FROM (SELECT random(-9223372036854775808, 9223372036854775807) r
-      FROM generate_series(1, 2000)) ss;
+      FROM generate_series(1, 495 * 2000)) ss;
 
 SELECT count(*) FILTER (WHERE r < -1500000000000000 OR r > 1500000000000000) AS out_of_range,
        (count(*) FILTER (WHERE r < -1470000000000000)) > 0 AS has_small,
        (count(*) FILTER (WHERE r > 1470000000000000)) > 0 AS has_large
 FROM (SELECT random(-1500000000000000, 1500000000000000) r
-      FROM generate_series(1, 2000)) ss;
+      FROM generate_series(1, 495 * 2000)) ss;
 
 SELECT count(*) FILTER (WHERE r < -1.5 OR r > 1.5) AS out_of_range,
        (count(*) FILTER (WHERE r < -1.47)) > 0 AS has_small,
        (count(*) FILTER (WHERE r > 1.47)) > 0 AS has_large
 FROM (SELECT random(-1.500000000000000, 1.500000000000000) r
-      FROM generate_series(1, 2000)) ss;
+      FROM generate_series(1, 495 * 2000)) ss;
 
 -- Every possible value should occur at least once in 2500 random() values
 -- chosen from a range with 100 distinct values.
 SELECT min(r), max(r), count(r) FROM (
-  SELECT DISTINCT random(-50, 49) r FROM generate_series(1, 2500));
+  SELECT DISTINCT random(-50, 49) r FROM generate_series(1, 495 * 2500));
 
 SELECT min(r), max(r), count(r) FROM (
   SELECT DISTINCT random(123000000000, 123000000099) r
-  FROM generate_series(1, 2500));
+  FROM generate_series(1, 495 * 2500));
 
 SELECT min(r), max(r), count(r) FROM (
-  SELECT DISTINCT random(-0.5, 0.49) r FROM generate_series(1, 2500));
+  SELECT DISTINCT random(-0.5, 0.49) r FROM generate_series(1, 495 * 2500));
 
 -- Check for uniform distribution using the Kolmogorov-Smirnov test.
 
@@ -259,21 +259,21 @@ SELECT ks_test_uniform_random_numeric_in_range() OR
 
 SELECT setseed(0.5);
 
-SELECT random() FROM generate_series(1, 10);
+SELECT random() FROM generate_series(1, 495 * 10);
 
 -- Likewise for random_normal(); however, since its implementation relies
 -- on libm functions that have different roundoff behaviors on different
 -- machines, we have to round off the results a bit to get consistent output.
 SET extra_float_digits = -1;
 
-SELECT random_normal() FROM generate_series(1, 10);
-SELECT random_normal(mean => 1, stddev => 0.1) r FROM generate_series(1, 10);
+SELECT random_normal() FROM generate_series(1, 495 * 10);
+SELECT random_normal(mean => 1, stddev => 0.1) r FROM generate_series(1, 495 * 10);
 
 -- Reproducible random(min, max) values.
-SELECT random(1, 6) FROM generate_series(1, 10);
-SELECT random(-2147483648, 2147483647) FROM generate_series(1, 10);
-SELECT random(-9223372036854775808, 9223372036854775807) FROM generate_series(1, 10);
-SELECT random(-1e30, 1e30) FROM generate_series(1, 10);
-SELECT random(-0.4, 0.4) FROM generate_series(1, 10);
-SELECT random(0, 1 - 1e-30) FROM generate_series(1, 10);
+SELECT random(1, 6) FROM generate_series(1, 495 * 10);
+SELECT random(-2147483648, 2147483647) FROM generate_series(1, 495 * 10);
+SELECT random(-9223372036854775808, 9223372036854775807) FROM generate_series(1, 495 * 10);
+SELECT random(-1e30, 1e30) FROM generate_series(1, 495 * 10);
+SELECT random(-0.4, 0.4) FROM generate_series(1, 495 * 10);
+SELECT random(0, 1 - 1e-30) FROM generate_series(1, 495 * 10);
 SELECT n, random(0, trim_scale(abs(1 - 10.0^(-n)))) FROM generate_series(-20, 20) n;
diff --git a/src/test/regress/sql/rangefuncs.sql b/src/test/regress/sql/rangefuncs.sql
index 3c47c98e11..b68c9a2f78 100644
--- a/src/test/regress/sql/rangefuncs.sql
+++ b/src/test/regress/sql/rangefuncs.sql
@@ -41,14 +41,14 @@ create temporary view vw_ord as select * from rows from(unnest(array[10,20],arra
 select * from vw_ord;
 select definition from pg_views where viewname='vw_ord';
 drop view vw_ord;
-create temporary view vw_ord as select * from rows from(unnest(array[10,20],array['foo','bar']), generate_series(1,2)) as z(a,b,c);
+create temporary view vw_ord as select * from rows from(unnest(array[10,20],array['foo','bar']), generate_series(1, 495 * 2)) as z(a,b,c);
 select * from vw_ord;
 select definition from pg_views where viewname='vw_ord';
 drop view vw_ord;
 
 -- ordinality and multiple functions vs. rewind and reverse scan
 begin;
-declare rf_cur scroll cursor for select * from rows from(generate_series(1,5),generate_series(1,2)) with ordinality as g(i,j,o);
+declare rf_cur scroll cursor for select * from rows from(generate_series(1, 495 * 5),generate_series(1, 495 * 2)) with ordinality as g(i,j,o);
 fetch all from rf_cur;
 fetch backward all from rf_cur;
 fetch all from rf_cur;
@@ -296,7 +296,7 @@ SELECT setval('rngfunc_rescan_seq1',1,false),setval('rngfunc_rescan_seq2',1,fals
 SELECT * FROM (VALUES (1),(2),(3)) v(r), ROWS FROM( rngfunc_sql(10+r,13), rngfunc_mat(10+r,13) );
 
 SELECT setval('rngfunc_rescan_seq1',1,false),setval('rngfunc_rescan_seq2',1,false);
-SELECT * FROM generate_series(1,2) r1, generate_series(r1,3) r2, ROWS FROM( rngfunc_sql(10+r1,13), rngfunc_mat(10+r2,13) );
+SELECT * FROM generate_series(1, 495 * 2) r1, generate_series(r1,3) r2, ROWS FROM( rngfunc_sql(10+r1,13), rngfunc_mat(10+r2,13) );
 
 SELECT * FROM (VALUES (1),(2),(3)) v(r), generate_series(10+r,20-r) f(i);
 SELECT * FROM (VALUES (1),(2),(3)) v(r), generate_series(10+r,20-r) WITH ORDINALITY AS f(i,o);
@@ -434,7 +434,7 @@ AS 'select $1, array[$1,$1]' LANGUAGE sql;
 
 CREATE OR REPLACE FUNCTION rngfunc()
 RETURNS TABLE(a int)
-AS $$ SELECT a FROM generate_series(1,5) a(a) $$ LANGUAGE sql;
+AS $$ SELECT a FROM generate_series(1, 495 * 5) a(a) $$ LANGUAGE sql;
 SELECT * FROM rngfunc();
 DROP FUNCTION rngfunc();
 
diff --git a/src/test/regress/sql/rangetypes.sql b/src/test/regress/sql/rangetypes.sql
index a5ecdf5372..21bc18c2f0 100644
--- a/src/test/regress/sql/rangetypes.sql
+++ b/src/test/regress/sql/rangetypes.sql
@@ -219,13 +219,13 @@ select daterange('2000-01-01'::date, 'infinity'::date, '[]');
 create table test_range_gist(ir int4range);
 create index test_range_gist_idx on test_range_gist using gist (ir);
 
-insert into test_range_gist select int4range(g, g+10) from generate_series(1,2000) g;
-insert into test_range_gist select 'empty'::int4range from generate_series(1,500) g;
-insert into test_range_gist select int4range(g, g+10000) from generate_series(1,1000) g;
-insert into test_range_gist select 'empty'::int4range from generate_series(1,500) g;
-insert into test_range_gist select int4range(NULL,g*10,'(]') from generate_series(1,100) g;
-insert into test_range_gist select int4range(g*10,NULL,'(]') from generate_series(1,100) g;
-insert into test_range_gist select int4range(g, g+10) from generate_series(1,2000) g;
+insert into test_range_gist select int4range(g, g+10) from generate_series(1, 495 * 2000) g;
+insert into test_range_gist select 'empty'::int4range from generate_series(1, 495 * 500) g;
+insert into test_range_gist select int4range(g, g+10000) from generate_series(1, 495 * 1000) g;
+insert into test_range_gist select 'empty'::int4range from generate_series(1, 495 * 500) g;
+insert into test_range_gist select int4range(NULL,g*10,'(]') from generate_series(1, 495 * 100) g;
+insert into test_range_gist select int4range(g*10,NULL,'(]') from generate_series(1, 495 * 100) g;
+insert into test_range_gist select int4range(g, g+10) from generate_series(1, 495 * 2000) g;
 
 -- test statistics and selectivity estimation as well
 --
@@ -314,13 +314,13 @@ select count(*) from test_range_gist where ir -|- int4multirange(int4range(100,2
 create table test_range_spgist(ir int4range);
 create index test_range_spgist_idx on test_range_spgist using spgist (ir);
 
-insert into test_range_spgist select int4range(g, g+10) from generate_series(1,2000) g;
-insert into test_range_spgist select 'empty'::int4range from generate_series(1,500) g;
-insert into test_range_spgist select int4range(g, g+10000) from generate_series(1,1000) g;
-insert into test_range_spgist select 'empty'::int4range from generate_series(1,500) g;
-insert into test_range_spgist select int4range(NULL,g*10,'(]') from generate_series(1,100) g;
-insert into test_range_spgist select int4range(g*10,NULL,'(]') from generate_series(1,100) g;
-insert into test_range_spgist select int4range(g, g+10) from generate_series(1,2000) g;
+insert into test_range_spgist select int4range(g, g+10) from generate_series(1, POW(495, 0.5)::int * 2000) g;
+insert into test_range_spgist select 'empty'::int4range from generate_series(1, POW(495, 0.5)::int * 500) g;
+insert into test_range_spgist select int4range(g, g+10000) from generate_series(1, POW(495, 0.5)::int * 1000) g;
+insert into test_range_spgist select 'empty'::int4range from generate_series(1, POW(495, 0.5)::int * 500) g;
+insert into test_range_spgist select int4range(NULL,g*10,'(]') from generate_series(1, POW(495, 0.5)::int * 100) g;
+insert into test_range_spgist select int4range(g*10,NULL,'(]') from generate_series(1, POW(495, 0.5)::int * 100) g;
+insert into test_range_spgist select int4range(g, g+10) from generate_series(1, POW(495, 0.5)::int * 2000) g;
 
 -- first, verify non-indexed results
 SET enable_seqscan    = t;
@@ -384,7 +384,7 @@ RESET enable_bitmapscan;
 -- test elem <@ range operator
 create table test_range_elem(i int4);
 create index test_range_elem_idx on test_range_elem (i);
-insert into test_range_elem select i from generate_series(1,100) i;
+insert into test_range_elem select i from generate_series(1, 495 * 100) i;
 
 SET enable_seqscan    = f;
 
diff --git a/src/test/regress/sql/rowsecurity.sql b/src/test/regress/sql/rowsecurity.sql
index eab7d99003..62e7b7ab3d 100644
--- a/src/test/regress/sql/rowsecurity.sql
+++ b/src/test/regress/sql/rowsecurity.sql
@@ -1324,7 +1324,7 @@ DROP VIEW rls_sbv;
 -- Expression structure
 --
 SET SESSION AUTHORIZATION regress_rls_alice;
-INSERT INTO y2 (SELECT x, public.fipshash(x::text) FROM generate_series(0,20) x);
+INSERT INTO y2 (SELECT x, public.fipshash(x::text) FROM generate_series(0, 495 * 20) x);
 CREATE POLICY p2 ON y2 USING (a % 3 = 0);
 CREATE POLICY p3 ON y2 USING (a % 4 = 0);
 
@@ -1396,7 +1396,7 @@ ALTER TABLE t1 ENABLE ROW LEVEL SECURITY;
 
 GRANT ALL ON t1 TO regress_rls_bob;
 
-INSERT INTO t1 (SELECT x, public.fipshash(x::text) FROM generate_series(0,20) x);
+INSERT INTO t1 (SELECT x, public.fipshash(x::text) FROM generate_series(0, 495 * 20) x);
 
 SET SESSION AUTHORIZATION regress_rls_bob;
 
@@ -1528,7 +1528,7 @@ ALTER TABLE copy_t ENABLE ROW LEVEL SECURITY;
 
 GRANT ALL ON copy_t TO regress_rls_bob, regress_rls_exempt_user;
 
-INSERT INTO copy_t (SELECT x, public.fipshash(x::text) FROM generate_series(0,10) x);
+INSERT INTO copy_t (SELECT x, public.fipshash(x::text) FROM generate_series(0, 495 * 10) x);
 
 -- Check COPY TO as Superuser/owner.
 RESET SESSION AUTHORIZATION;
@@ -2164,7 +2164,7 @@ DROP TABLE ref_tbl;
 
 -- Leaky operator test
 CREATE TABLE rls_tbl (a int);
-INSERT INTO rls_tbl SELECT x/10 FROM generate_series(1, 100) x;
+INSERT INTO rls_tbl SELECT x/10 FROM generate_series(1, 495 * 100) x;
 ANALYZE rls_tbl;
 
 ALTER TABLE rls_tbl ENABLE ROW LEVEL SECURITY;
diff --git a/src/test/regress/sql/rowtypes.sql b/src/test/regress/sql/rowtypes.sql
index 174b062144..78ec3e0001 100644
--- a/src/test/regress/sql/rowtypes.sql
+++ b/src/test/regress/sql/rowtypes.sql
@@ -165,7 +165,7 @@ order by thousand, hundred;
 -- Test case for bug #14010: indexed row comparisons fail with nulls
 create temp table test_table (a text, b text);
 insert into test_table values ('a', 'b');
-insert into test_table select 'a', null from generate_series(1,1000);
+insert into test_table select 'a', null from generate_series(1, 495 * 1000);
 insert into test_table values ('b', 'a');
 create index on test_table (a,b);
 set enable_sort = off;
diff --git a/src/test/regress/sql/select_distinct.sql b/src/test/regress/sql/select_distinct.sql
index da92c197ab..a967751e55 100644
--- a/src/test/regress/sql/select_distinct.sql
+++ b/src/test/regress/sql/select_distinct.sql
@@ -59,15 +59,15 @@ SET enable_hashagg=FALSE;
 SET jit_above_cost=0;
 
 EXPLAIN (costs off)
-SELECT DISTINCT g%1000 FROM generate_series(0,9999) g;
+SELECT DISTINCT g%1000 FROM generate_series(0, 495 * 9999) g;
 
 CREATE TABLE distinct_group_1 AS
-SELECT DISTINCT g%1000 FROM generate_series(0,9999) g;
+SELECT DISTINCT g%1000 FROM generate_series(0, 495 * 9999) g;
 
 SET jit_above_cost TO DEFAULT;
 
 CREATE TABLE distinct_group_2 AS
-SELECT DISTINCT (g%1000)::text FROM generate_series(0,9999) g;
+SELECT DISTINCT (g%1000)::text FROM generate_series(0, 495 * 9999) g;
 
 SET enable_seqscan = 0;
 
@@ -86,15 +86,15 @@ SET enable_sort=FALSE;
 SET jit_above_cost=0;
 
 EXPLAIN (costs off)
-SELECT DISTINCT g%1000 FROM generate_series(0,9999) g;
+SELECT DISTINCT g%1000 FROM generate_series(0, 495 * 9999) g;
 
 CREATE TABLE distinct_hash_1 AS
-SELECT DISTINCT g%1000 FROM generate_series(0,9999) g;
+SELECT DISTINCT g%1000 FROM generate_series(0, 495 * 9999) g;
 
 SET jit_above_cost TO DEFAULT;
 
 CREATE TABLE distinct_hash_2 AS
-SELECT DISTINCT (g%1000)::text FROM generate_series(0,9999) g;
+SELECT DISTINCT (g%1000)::text FROM generate_series(0, 495 * 9999) g;
 
 SET enable_sort=TRUE;
 
diff --git a/src/test/regress/sql/select_into.sql b/src/test/regress/sql/select_into.sql
index 689c448cc2..30d481380a 100644
--- a/src/test/regress/sql/select_into.sql
+++ b/src/test/regress/sql/select_into.sql
@@ -28,19 +28,19 @@ GRANT ALL ON SCHEMA selinto_schema TO public;
 SET SESSION AUTHORIZATION regress_selinto_user;
 -- WITH DATA, passes.
 CREATE TABLE selinto_schema.tbl_withdata1 (a)
-  AS SELECT generate_series(1,3) WITH DATA;
+  AS SELECT generate_series(1, 495 * 3) WITH DATA;
 INSERT INTO selinto_schema.tbl_withdata1 VALUES (4);
 EXPLAIN (ANALYZE, COSTS OFF, SUMMARY OFF, TIMING OFF)
   CREATE TABLE selinto_schema.tbl_withdata2 (a) AS
-  SELECT generate_series(1,3) WITH DATA;
+  SELECT generate_series(1, 495 * 3) WITH DATA;
 -- WITH NO DATA, passes.
 CREATE TABLE selinto_schema.tbl_nodata1 (a) AS
-  SELECT generate_series(1,3) WITH NO DATA;
+  SELECT generate_series(1, 495 * 3) WITH NO DATA;
 EXPLAIN (ANALYZE, COSTS OFF, SUMMARY OFF, TIMING OFF)
   CREATE TABLE selinto_schema.tbl_nodata2 (a) AS
-  SELECT generate_series(1,3) WITH NO DATA;
+  SELECT generate_series(1, 495 * 3) WITH NO DATA;
 -- EXECUTE and WITH DATA, passes.
-PREPARE data_sel AS SELECT generate_series(1,3);
+PREPARE data_sel AS SELECT generate_series(1, 495 * 3);
 CREATE TABLE selinto_schema.tbl_withdata3 (a) AS
   EXECUTE data_sel WITH DATA;
 EXPLAIN (ANALYZE, COSTS OFF, SUMMARY OFF, TIMING OFF)
diff --git a/src/test/regress/sql/select_parallel.sql b/src/test/regress/sql/select_parallel.sql
index 3e4bfcb71f..426eeecca5 100644
--- a/src/test/regress/sql/select_parallel.sql
+++ b/src/test/regress/sql/select_parallel.sql
@@ -146,9 +146,9 @@ select  count((unique1)) from tenk1 where hundred > 1;
 -- Parallel ScalarArrayOp index scan
 explain (costs off)
   select count((unique1)) from tenk1
-  where hundred = any ((select array_agg(i) from generate_series(1, 100, 15) i)::int[]);
+  where hundred = any ((select array_agg(i) from generate_series(1, 495 * 100, 15) i)::int[]);
 select count((unique1)) from tenk1
-where hundred = any ((select array_agg(i) from generate_series(1, 100, 15) i)::int[]);
+where hundred = any ((select array_agg(i) from generate_series(1, 495 * 100, 15) i)::int[]);
 
 -- test parallel index-only scans.
 explain (costs off)
@@ -216,7 +216,7 @@ explain (costs off)
 select count(*) from tenk1, tenk2 where tenk1.hundred > 1 and tenk2.thousand=0;
 
 create table bmscantest (a int, t text);
-insert into bmscantest select r, 'fooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo' FROM generate_series(1,100000) r;
+insert into bmscantest select r, 'fooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo' FROM generate_series(1, 495 * 100000) r;
 create index i_bmtest ON bmscantest(a);
 select count(*) from bmscantest where a>1;
 
@@ -290,9 +290,9 @@ drop function sp_simple_func(integer);
 -- test handling of SRFs in targetlist (bug in 10.0)
 
 explain (costs off)
-   select count(*), generate_series(1,2) from tenk1 group by twenty;
+   select count(*), generate_series(1, 495 * 2) from tenk1 group by twenty;
 
-select count(*), generate_series(1,2) from tenk1 group by twenty;
+select count(*), generate_series(1, 495 * 2) from tenk1 group by twenty;
 
 -- test gather merge with parallel leader participation disabled
 set parallel_leader_participation = off;
@@ -399,7 +399,7 @@ END;
 $$;
 SAVEPOINT settings;
 SET LOCAL debug_parallel_query = 1;
-SELECT make_record(x) FROM (SELECT generate_series(1, 5) x) ss ORDER BY x;
+SELECT make_record(x) FROM (SELECT generate_series(1, 495 * 5) x) ss ORDER BY x;
 ROLLBACK TO SAVEPOINT settings;
 DROP function make_record(n int);
 
@@ -535,7 +535,7 @@ $$;
 
 CREATE TABLE parallel_hang (i int4);
 INSERT INTO parallel_hang
-	(SELECT * FROM generate_series(1, 400) gs);
+	(SELECT * FROM generate_series(1, 495 * 400) gs);
 
 CREATE OPERATOR CLASS int4_custom_ops FOR TYPE int4 USING btree AS
 	OPERATOR 1 < (int4, int4), OPERATOR 2 <= (int4, int4),
diff --git a/src/test/regress/sql/spgist.sql b/src/test/regress/sql/spgist.sql
index 4828ede68c..8c7adaa693 100644
--- a/src/test/regress/sql/spgist.sql
+++ b/src/test/regress/sql/spgist.sql
@@ -10,15 +10,15 @@ create index spgist_point_idx on spgist_point_tbl using spgist(p) with (fillfact
 -- Test vacuum-root operation. It gets invoked when the root is also a leaf,
 -- i.e. the index is very small.
 insert into spgist_point_tbl (id, p)
-select g, point(g*10, g*10) from generate_series(1, 10) g;
+select g, point(g*10, g*10) from generate_series(1, 495 * 10) g;
 delete from spgist_point_tbl where id < 5;
 vacuum spgist_point_tbl;
 
 -- Insert more data, to make the index a few levels deep.
 insert into spgist_point_tbl (id, p)
-select g,      point(g*10, g*10) from generate_series(1, 10000) g;
+select g,      point(g*10, g*10) from generate_series(1, POW(495, 0.5) * 10000) g;
 insert into spgist_point_tbl (id, p)
-select g+100000, point(g*10+1, g*10+1) from generate_series(1, 10000) g;
+select g+100000, point(g*10+1, g*10+1) from generate_series(1, POW(495, 0.5) * 10000) g;
 
 -- To test vacuum, delete some entries from all over the index.
 delete from spgist_point_tbl where id % 2 = 1;
@@ -39,7 +39,7 @@ insert into spgist_box_tbl(b)
 select box(point(i,j),point(i+s,j+s))
   from generate_series(1,100,5) i,
        generate_series(1,100,5) j,
-       generate_series(1,10) s;
+       generate_series(1, 495 * 10) s;
 create index spgist_box_idx on spgist_box_tbl using spgist (b);
 
 select count(*)
@@ -54,15 +54,15 @@ create table spgist_text_tbl(id int4, t text);
 create index spgist_text_idx on spgist_text_tbl using spgist(t);
 
 insert into spgist_text_tbl (id, t)
-select g, 'f' || repeat('o', 100) || g from generate_series(1, 10000) g
+select g, 'f' || repeat('o', 100) || g from generate_series(1, 495 * 10000) g
 union all
-select g, 'baaaaaaaaaaaaaar' || g from generate_series(1, 1000) g;
+select g, 'baaaaaaaaaaaaaar' || g from generate_series(1, 495 * 1000) g;
 
 -- Do a lot of insertions that have to split an existing node. Hopefully
 -- one of these will cause the page to run out of space, causing the inner
 -- tuple to be moved to another page.
 insert into spgist_text_tbl (id, t)
-select -g, 'f' || repeat('o', 100-g) || 'surprise' from generate_series(1, 100) g;
+select -g, 'f' || repeat('o', 100-g) || 'surprise' from generate_series(1, 495 * 100) g;
 
 -- Test out-of-range fillfactor values
 create index spgist_point_idx2 on spgist_point_tbl using spgist(p) with (fillfactor = 9);
@@ -87,5 +87,5 @@ create index spgist_unlogged_idx on spgist_unlogged_tbl using spgist (b);
 insert into spgist_unlogged_tbl(b)
 select box(point(i,j))
   from generate_series(1,100,5) i,
-       generate_series(1,10,5) j;
+       generate_series(1, 495 * 10,5) j;
 -- leave this table around, to help in testing dump/restore
diff --git a/src/test/regress/sql/sqljson.sql b/src/test/regress/sql/sqljson.sql
index 343d344d27..971de23292 100644
--- a/src/test/regress/sql/sqljson.sql
+++ b/src/test/regress/sql/sqljson.sql
@@ -209,28 +209,28 @@ SELECT JSON_ARRAY(SELECT * FROM (VALUES (1, 2)) foo(i, j));
 -- JSON_ARRAYAGG()
 SELECT	JSON_ARRAYAGG(i) IS NULL,
 		JSON_ARRAYAGG(i RETURNING jsonb) IS NULL
-FROM generate_series(1, 0) i;
+FROM generate_series(1, 495 * 0) i;
 
 SELECT	JSON_ARRAYAGG(i),
 		JSON_ARRAYAGG(i RETURNING jsonb)
-FROM generate_series(1, 5) i;
+FROM generate_series(1, 495 * 5) i;
 
 SELECT JSON_ARRAYAGG(i ORDER BY i DESC)
-FROM generate_series(1, 5) i;
+FROM generate_series(1, 495 * 5) i;
 
 SELECT JSON_ARRAYAGG(i::text::json)
-FROM generate_series(1, 5) i;
+FROM generate_series(1, 495 * 5) i;
 
 SELECT JSON_ARRAYAGG(JSON_ARRAY(i, i + 1 RETURNING text) FORMAT JSON)
-FROM generate_series(1, 5) i;
+FROM generate_series(1, 495 * 5) i;
 
 SELECT	JSON_ARRAYAGG(NULL),
 		JSON_ARRAYAGG(NULL RETURNING jsonb)
-FROM generate_series(1, 5);
+FROM generate_series(1, 495 * 5);
 
 SELECT	JSON_ARRAYAGG(NULL NULL ON NULL),
 		JSON_ARRAYAGG(NULL NULL ON NULL RETURNING jsonb)
-FROM generate_series(1, 5);
+FROM generate_series(1, 495 * 5);
 
 \x
 SELECT
@@ -268,7 +268,7 @@ SELECT
 --	JSON_OBJECTAGG(KEY i VALUE i),
 	JSON_OBJECTAGG(i: i RETURNING jsonb)
 FROM
-	generate_series(1, 5) i;
+	generate_series(1, 495 * 5) i;
 
 SELECT
 	JSON_OBJECTAGG(k: v),
@@ -299,7 +299,7 @@ SELECT JSON_OBJECTAGG(k: v ABSENT ON NULL WITH UNIQUE KEYS RETURNING jsonb)
 FROM (VALUES (1, 1), (0, NULL),(4, null), (5, null),(6, null),(2, 2)) foo(k, v);
 
 SELECT JSON_OBJECTAGG(mod(i,100): (i)::text FORMAT JSON WITH UNIQUE)
-FROM generate_series(0, 199) i;
+FROM generate_series(0, 495 * 199) i;
 
 -- Test JSON_OBJECT deparsing
 EXPLAIN (VERBOSE, COSTS OFF)
@@ -344,15 +344,15 @@ DROP VIEW json_array_view;
 -- Test JSON_OBJECTAGG deparsing
 EXPLAIN (VERBOSE, COSTS OFF)
 SELECT JSON_OBJECTAGG(i: ('111' || i)::bytea FORMAT JSON WITH UNIQUE RETURNING text) FILTER (WHERE i > 3)
-FROM generate_series(1,5) i;
+FROM generate_series(1, 495 * 5) i;
 
 EXPLAIN (VERBOSE, COSTS OFF)
 SELECT JSON_OBJECTAGG(i: ('111' || i)::bytea FORMAT JSON WITH UNIQUE RETURNING text) OVER (PARTITION BY i % 2)
-FROM generate_series(1,5) i;
+FROM generate_series(1, 495 * 5) i;
 
 CREATE VIEW json_objectagg_view AS
 SELECT JSON_OBJECTAGG(i: ('111' || i)::bytea FORMAT JSON WITH UNIQUE RETURNING text) FILTER (WHERE i > 3)
-FROM generate_series(1,5) i;
+FROM generate_series(1, 495 * 5) i;
 
 \sv json_objectagg_view
 
@@ -361,15 +361,15 @@ DROP VIEW json_objectagg_view;
 -- Test JSON_ARRAYAGG deparsing
 EXPLAIN (VERBOSE, COSTS OFF)
 SELECT JSON_ARRAYAGG(('111' || i)::bytea FORMAT JSON NULL ON NULL RETURNING text) FILTER (WHERE i > 3)
-FROM generate_series(1,5) i;
+FROM generate_series(1, 495 * 5) i;
 
 EXPLAIN (VERBOSE, COSTS OFF)
 SELECT JSON_ARRAYAGG(('111' || i)::bytea FORMAT JSON NULL ON NULL RETURNING text) OVER (PARTITION BY i % 2)
-FROM generate_series(1,5) i;
+FROM generate_series(1, 495 * 5) i;
 
 CREATE VIEW json_arrayagg_view AS
 SELECT JSON_ARRAYAGG(('111' || i)::bytea FORMAT JSON NULL ON NULL RETURNING text) FILTER (WHERE i > 3)
-FROM generate_series(1,5) i;
+FROM generate_series(1, 495 * 5) i;
 
 \sv json_arrayagg_view
 
@@ -473,10 +473,10 @@ FROM
 
 -- Test IS JSON deparsing
 EXPLAIN (VERBOSE, COSTS OFF)
-SELECT '1' IS JSON AS "any", ('1' || i) IS JSON SCALAR AS "scalar", '[]' IS NOT JSON ARRAY AS "array", '{}' IS JSON OBJECT WITH UNIQUE AS "object" FROM generate_series(1, 3) i;
+SELECT '1' IS JSON AS "any", ('1' || i) IS JSON SCALAR AS "scalar", '[]' IS NOT JSON ARRAY AS "array", '{}' IS JSON OBJECT WITH UNIQUE AS "object" FROM generate_series(1, 495 * 3) i;
 
 CREATE VIEW is_json_view AS
-SELECT '1' IS JSON AS "any", ('1' || i) IS JSON SCALAR AS "scalar", '[]' IS NOT JSON ARRAY AS "array", '{}' IS JSON OBJECT WITH UNIQUE AS "object" FROM generate_series(1, 3) i;
+SELECT '1' IS JSON AS "any", ('1' || i) IS JSON SCALAR AS "scalar", '[]' IS NOT JSON ARRAY AS "array", '{}' IS JSON OBJECT WITH UNIQUE AS "object" FROM generate_series(1, 495 * 3) i;
 
 \sv is_json_view
 
@@ -486,8 +486,8 @@ DROP VIEW is_json_view;
 SELECT JSON_SERIALIZE('{ "a" : 1 } ' RETURNING varchar(2));
 SELECT JSON_OBJECT('a': JSON_OBJECT('b': 1 RETURNING varchar(2)));
 SELECT JSON_ARRAY(JSON_ARRAY('{ "a" : 123 }' RETURNING varchar(2)));
-SELECT JSON_ARRAYAGG(('111' || i)::bytea FORMAT JSON NULL ON NULL RETURNING varchar(2)) FROM generate_series(1,1) i;
-SELECT JSON_OBJECTAGG(i: ('111' || i)::bytea FORMAT JSON WITH UNIQUE RETURNING varchar(2)) FROM generate_series(1, 1) i;
+SELECT JSON_ARRAYAGG(('111' || i)::bytea FORMAT JSON NULL ON NULL RETURNING varchar(2)) FROM generate_series(1, 495 * 1) i;
+SELECT JSON_OBJECTAGG(i: ('111' || i)::bytea FORMAT JSON WITH UNIQUE RETURNING varchar(2)) FROM generate_series(1, 495 * 1) i;
 
 -- Now try domain over fixed-length type
 CREATE DOMAIN sqljson_char2 AS char(2) CHECK (VALUE NOT IN ('12'));
diff --git a/src/test/regress/sql/sqljson_jsontable.sql b/src/test/regress/sql/sqljson_jsontable.sql
index 154eea79c7..c12069187f 100644
--- a/src/test/regress/sql/sqljson_jsontable.sql
+++ b/src/test/regress/sql/sqljson_jsontable.sql
@@ -409,8 +409,8 @@ from
 -- PASSING arguments are passed to nested paths and their columns' paths
 SELECT *
 FROM
-	generate_series(1, 3) x,
-	generate_series(1, 3) y,
+	generate_series(1, 495 * 3) x,
+	generate_series(1, 495 * 3) y,
 	JSON_TABLE(jsonb
 		'[[1,2,3],[2,3,4,5],[3,4,5,6]]',
 		'strict $[*] ? (@[*] <= $x)'
diff --git a/src/test/regress/sql/sqljson_queryfuncs.sql b/src/test/regress/sql/sqljson_queryfuncs.sql
index 8d7b225b61..e656ecd010 100644
--- a/src/test/regress/sql/sqljson_queryfuncs.sql
+++ b/src/test/regress/sql/sqljson_queryfuncs.sql
@@ -118,7 +118,7 @@ SELECT
 		DEFAULT -2 ON ERROR
 	) y
 FROM
-	generate_series(0, 2) x;
+	generate_series(0, 495 * 2) x;
 
 SELECT JSON_VALUE(jsonb 'null', '$a' PASSING point ' (1, 2 )' AS a);
 SELECT JSON_VALUE(jsonb 'null', '$a' PASSING point ' (1, 2 )' AS a RETURNING point);
@@ -279,8 +279,8 @@ SELECT
 		EMPTY ARRAY ON EMPTY
 	) list
 FROM
-	generate_series(0, 4) x,
-	generate_series(0, 4) y;
+	generate_series(0, 495 * 4) x,
+	generate_series(0, 495 * 4) y;
 
 -- record type returning with quotes behavior.
 CREATE TYPE comp_abc AS (a text, b int, c timestamp);
diff --git a/src/test/regress/sql/stats.sql b/src/test/regress/sql/stats.sql
index ed0bc1ef07..5aa03eaab5 100644
--- a/src/test/regress/sql/stats.sql
+++ b/src/test/regress/sql/stats.sql
@@ -547,7 +547,7 @@ SELECT pg_stat_have_stats('database', :dboid, 1);
 SELECT pg_stat_have_stats('database', :dboid, 0);
 
 -- pg_stat_have_stats returns true for committed index creation
-CREATE table stats_test_tab1 as select generate_series(1,10) a;
+CREATE table stats_test_tab1 as select generate_series(1, 495 * 10) a;
 CREATE index stats_test_idx1 on stats_test_tab1(a);
 SELECT 'stats_test_idx1'::regclass::oid AS stats_test_idx1_oid \gset
 SET enable_seqscan TO off;
@@ -613,7 +613,7 @@ SELECT sum(writes) AS writes, sum(fsyncs) AS fsyncs
   FROM pg_stat_io
   WHERE object = 'relation' \gset io_sum_shared_before_
 CREATE TABLE test_io_shared(a int);
-INSERT INTO test_io_shared SELECT i FROM generate_series(1,100)i;
+INSERT INTO test_io_shared SELECT i FROM generate_series(1, 495 * 100)i;
 SELECT pg_stat_force_next_flush();
 SELECT sum(extends) AS io_sum_shared_after_extends
   FROM pg_stat_io WHERE context = 'normal' AND object = 'relation' \gset
@@ -686,7 +686,7 @@ SELECT sum(extends) AS extends, sum(evictions) AS evictions, sum(writes) AS writ
 -- Insert tuples into the temporary table, generating extends in the stats.
 -- Insert enough values that we need to reuse and write out dirty local
 -- buffers, generating evictions and writes.
-INSERT INTO test_io_local SELECT generate_series(1, 5000) as id, repeat('a', 200);
+INSERT INTO test_io_local SELECT generate_series(1, 495 * 5000) as id, repeat('a', 200);
 -- Ensure the table is large enough to exceed our temp_buffers setting.
 SELECT pg_relation_size('test_io_local') / current_setting('block_size')::int8 > 100;
 
@@ -733,7 +733,7 @@ SET wal_skip_threshold = '1 kB';
 SELECT sum(reuses) AS reuses, sum(reads) AS reads, sum(evictions) AS evictions
   FROM pg_stat_io WHERE context = 'vacuum' \gset io_sum_vac_strategy_before_
 CREATE TABLE test_io_vac_strategy(a int, b int) WITH (autovacuum_enabled = 'false');
-INSERT INTO test_io_vac_strategy SELECT i, i from generate_series(1, 4500)i;
+INSERT INTO test_io_vac_strategy SELECT i, i from generate_series(1, 495 * 4500)i;
 -- Ensure that the next VACUUM will need to perform IO by rewriting the table
 -- first with VACUUM (FULL).
 VACUUM (FULL) test_io_vac_strategy;
@@ -752,7 +752,7 @@ RESET wal_skip_threshold;
 -- BufferAccessStrategy, are tracked in pg_stat_io.
 SELECT sum(extends) AS io_sum_bulkwrite_strategy_extends_before
   FROM pg_stat_io WHERE context = 'bulkwrite' \gset
-CREATE TABLE test_io_bulkwrite_strategy AS SELECT i FROM generate_series(1,100)i;
+CREATE TABLE test_io_bulkwrite_strategy AS SELECT i FROM generate_series(1, 495 * 100)i;
 SELECT pg_stat_force_next_flush();
 SELECT sum(extends) AS io_sum_bulkwrite_strategy_extends_after
   FROM pg_stat_io WHERE context = 'bulkwrite' \gset
@@ -774,7 +774,7 @@ CREATE TABLE brin_hot (
   val integer NOT NULL
 ) WITH (autovacuum_enabled = off, fillfactor = 70);
 
-INSERT INTO brin_hot SELECT *, 0 FROM generate_series(1, 235);
+INSERT INTO brin_hot SELECT *, 0 FROM generate_series(1, 495 * 235);
 CREATE INDEX val_brin ON brin_hot using brin(val);
 
 CREATE FUNCTION wait_for_hot_stats() RETURNS void AS $$
@@ -838,7 +838,7 @@ DROP TABLE brin_hot_2;
 -- BRIN column.
 -- https://postgr.es/m/05ebcb44-f383-86e3-4f31-0a97a55634cf@enterprisedb.com
 CREATE TABLE brin_hot_3 (a int, filler text) WITH (fillfactor = 10);
-INSERT INTO brin_hot_3 SELECT 1, repeat(' ', 500) FROM generate_series(1, 20);
+INSERT INTO brin_hot_3 SELECT 1, repeat(' ', 500) FROM generate_series(1, 495 * 20);
 CREATE INDEX ON brin_hot_3 USING brin (a) WITH (pages_per_range = 1);
 UPDATE brin_hot_3 SET a = 2;
 
@@ -859,7 +859,7 @@ CREATE TABLE table_fillfactor (
 ) with (fillfactor=10, autovacuum_enabled=off);
 
 INSERT INTO table_fillfactor
-SELECT 'x' FROM generate_series(1,1000);
+SELECT 'x' FROM generate_series(1, 495 * 1000);
 
 SELECT * FROM check_estimated_rows('SELECT * FROM table_fillfactor');
 
diff --git a/src/test/regress/sql/stats_ext.sql b/src/test/regress/sql/stats_ext.sql
index 0c08a6cc42..3e9acf62c0 100644
--- a/src/test/regress/sql/stats_ext.sql
+++ b/src/test/regress/sql/stats_ext.sql
@@ -83,7 +83,7 @@ SELECT stxname FROM pg_statistic_ext WHERE stxname LIKE 'ab1%';
 -- Ensure things work sanely with SET STATISTICS 0
 CREATE TABLE ab1 (a INTEGER, b INTEGER);
 ALTER TABLE ab1 ALTER a SET STATISTICS 0;
-INSERT INTO ab1 SELECT a, a%23 FROM generate_series(1, 1000) a;
+INSERT INTO ab1 SELECT a, a%23 FROM generate_series(1, 495 * 1000) a;
 CREATE STATISTICS ab1_a_b_stats ON a, b FROM ab1;
 ANALYZE ab1;
 ALTER TABLE ab1 ALTER a SET STATISTICS -1;
@@ -115,9 +115,9 @@ DROP TABLE ab1 CASCADE;
 CREATE TABLE stxdinh(a int, b int);
 CREATE TABLE stxdinh1() INHERITS(stxdinh);
 CREATE TABLE stxdinh2() INHERITS(stxdinh);
-INSERT INTO stxdinh SELECT mod(a,50), mod(a,100) FROM generate_series(0, 1999) a;
-INSERT INTO stxdinh1 SELECT mod(a,100), mod(a,100) FROM generate_series(0, 999) a;
-INSERT INTO stxdinh2 SELECT mod(a,100), mod(a,100) FROM generate_series(0, 999) a;
+INSERT INTO stxdinh SELECT mod(a,50), mod(a,100) FROM generate_series(0, 495 * 1999) a;
+INSERT INTO stxdinh1 SELECT mod(a,100), mod(a,100) FROM generate_series(0, 495 * 999) a;
+INSERT INTO stxdinh2 SELECT mod(a,100), mod(a,100) FROM generate_series(0, 495 * 999) a;
 VACUUM ANALYZE stxdinh, stxdinh1, stxdinh2;
 -- Ensure non-inherited stats are not applied to inherited query
 -- Without stats object, it looks like this
@@ -138,7 +138,7 @@ DROP TABLE stxdinh, stxdinh1, stxdinh2;
 -- Ensure inherited stats ARE applied to inherited query in partitioned table
 CREATE TABLE stxdinp(i int, a int, b int) PARTITION BY RANGE (i);
 CREATE TABLE stxdinp1 PARTITION OF stxdinp FOR VALUES FROM (1) TO (100);
-INSERT INTO stxdinp SELECT 1, a/100, a/100 FROM generate_series(1, 999) a;
+INSERT INTO stxdinp SELECT 1, a/100, a/100 FROM generate_series(1, 495 * 999) a;
 CREATE STATISTICS stxdinp ON (a + 1), a, b FROM stxdinp;
 VACUUM ANALYZE stxdinp; -- partitions are processed recursively
 SELECT 1 FROM pg_statistic_ext WHERE stxrelid = 'stxdinp'::regclass;
@@ -175,7 +175,7 @@ INSERT INTO ab1
 SELECT x / 10, x / 3,
     '2020-10-01'::timestamp + x * interval '1 day',
     '2020-10-01'::timestamptz + x * interval '1 day'
-FROM generate_series(1, 100) x;
+FROM generate_series(1, 495 * 100) x;
 ANALYZE ab1;
 
 -- apply some stats
@@ -235,7 +235,7 @@ WITH (autovacuum_enabled = off);
 -- over-estimates when using only per-column statistics
 INSERT INTO ndistinct (a, b, c, filler1)
      SELECT i/100, i/100, i/100, (i/100) || ' dollars and zero cents'
-       FROM generate_series(1,1000) s(i);
+       FROM generate_series(1, 495 * 1000) s(i);
 
 ANALYZE ndistinct;
 
@@ -300,7 +300,7 @@ TRUNCATE TABLE ndistinct;
 INSERT INTO ndistinct (a, b, c, filler1)
      SELECT mod(i,13), mod(i,17), mod(i,19),
             mod(i,23) || ' dollars and zero cents'
-       FROM generate_series(1,1000) s(i);
+       FROM generate_series(1, 495 * 1000) s(i);
 
 ANALYZE ndistinct;
 
@@ -408,7 +408,7 @@ TRUNCATE ndistinct;
 -- two mostly independent groups of columns
 INSERT INTO ndistinct (a, b, c, d)
      SELECT mod(i,3), mod(i,9), mod(i,5), mod(i,20)
-       FROM generate_series(1,1000) s(i);
+       FROM generate_series(1, 495 * 1000) s(i);
 
 ANALYZE ndistinct;
 
@@ -563,7 +563,7 @@ CREATE INDEX fdeps_abc_idx ON functional_dependencies (a, b, c);
 
 -- random data (no functional dependencies)
 INSERT INTO functional_dependencies (a, b, c, filler1)
-     SELECT mod(i, 5), mod(i, 7), mod(i, 11), i FROM generate_series(1,1000) s(i);
+     SELECT mod(i, 5), mod(i, 7), mod(i, 11), i FROM generate_series(1, 495 * 1000) s(i);
 
 ANALYZE functional_dependencies;
 
@@ -586,7 +586,7 @@ DROP STATISTICS func_deps_stat;
 
 -- now do the same thing, but with expressions
 INSERT INTO functional_dependencies (a, b, c, filler1)
-     SELECT i, i, i, i FROM generate_series(1,5000) s(i);
+     SELECT i, i, i, i FROM generate_series(1, 495 * 5000) s(i);
 
 ANALYZE functional_dependencies;
 
@@ -608,7 +608,7 @@ TRUNCATE functional_dependencies;
 DROP STATISTICS func_deps_stat;
 
 INSERT INTO functional_dependencies (a, b, c, filler1)
-     SELECT mod(i,100), mod(i,50), mod(i,25), i FROM generate_series(1,5000) s(i);
+     SELECT mod(i,100), mod(i,50), mod(i,25), i FROM generate_series(1, 495 * 5000) s(i);
 
 ANALYZE functional_dependencies;
 
@@ -884,7 +884,7 @@ INSERT INTO functional_dependencies_multi (a, b, c, d)
          mod(i,7),
          mod(i,11),
          mod(i,11)
-    FROM generate_series(1,5000) s(i);
+    FROM generate_series(1, 495 * 5000) s(i);
 
 ANALYZE functional_dependencies_multi;
 
@@ -924,7 +924,7 @@ WITH (autovacuum_enabled = off);
 
 -- random data (no MCV list)
 INSERT INTO mcv_lists (a, b, c, filler1)
-     SELECT mod(i,37), mod(i,41), mod(i,43), mod(i,47) FROM generate_series(1,5000) s(i);
+     SELECT mod(i,37), mod(i,41), mod(i,43), mod(i,47) FROM generate_series(1, 495 * 5000) s(i);
 
 ANALYZE mcv_lists;
 
@@ -946,7 +946,7 @@ DROP STATISTICS mcv_lists_stats;
 
 -- random data (no MCV list), but with expression
 INSERT INTO mcv_lists (a, b, c, filler1)
-     SELECT i, i, i, i FROM generate_series(1,1000) s(i);
+     SELECT i, i, i, i FROM generate_series(1, 495 * 1000) s(i);
 
 ANALYZE mcv_lists;
 
@@ -969,7 +969,7 @@ DROP STATISTICS mcv_lists_stats;
 
 INSERT INTO mcv_lists (a, b, c, ia, filler1)
      SELECT mod(i,100), mod(i,50), mod(i,25), array[mod(i,25)], i
-       FROM generate_series(1,5000) s(i);
+       FROM generate_series(1, 495 * 5000) s(i);
 
 ANALYZE mcv_lists;
 
@@ -1099,7 +1099,7 @@ TRUNCATE mcv_lists;
 DROP STATISTICS mcv_lists_stats;
 
 INSERT INTO mcv_lists (a, b, c, filler1)
-     SELECT i, i, i, i FROM generate_series(1,1000) s(i);
+     SELECT i, i, i, i FROM generate_series(1, 495 * 1000) s(i);
 
 ANALYZE mcv_lists;
 
@@ -1195,7 +1195,7 @@ INSERT INTO mcv_lists (a, b, c, filler1)
          (CASE WHEN mod(i,50) = 1  THEN NULL ELSE mod(i,50) END),
          (CASE WHEN mod(i,25) = 1  THEN NULL ELSE mod(i,25) END),
          i
-     FROM generate_series(1,5000) s(i);
+     FROM generate_series(1, 495 * 5000) s(i);
 
 ANALYZE mcv_lists;
 
@@ -1226,7 +1226,7 @@ SELECT * FROM check_estimated_rows('SELECT * FROM mcv_lists WHERE a IN (0, 1) AN
 
 -- test pg_mcv_list_items with a very simple (single item) MCV list
 TRUNCATE mcv_lists;
-INSERT INTO mcv_lists (a, b, c) SELECT 1, 2, 3 FROM generate_series(1,1000) s(i);
+INSERT INTO mcv_lists (a, b, c) SELECT 1, 2, 3 FROM generate_series(1, 495 * 1000) s(i);
 ANALYZE mcv_lists;
 
 SELECT m.*
@@ -1245,7 +1245,7 @@ INSERT INTO mcv_lists (a, b, c, d)
          (CASE WHEN mod(i,2) = 0 THEN NULL ELSE 'x' END),
          (CASE WHEN mod(i,2) = 0 THEN NULL ELSE 0 END),
          (CASE WHEN mod(i,2) = 0 THEN NULL ELSE 'x' END)
-     FROM generate_series(1,5000) s(i);
+     FROM generate_series(1, 495 * 5000) s(i);
 
 ANALYZE mcv_lists;
 
@@ -1286,7 +1286,7 @@ INSERT INTO mcv_lists_uuid (a, b, c)
          fipshash(mod(i,100)::text)::uuid,
          fipshash(mod(i,50)::text)::uuid,
          fipshash(mod(i,25)::text)::uuid
-     FROM generate_series(1,5000) s(i);
+     FROM generate_series(1, 495 * 5000) s(i);
 
 ANALYZE mcv_lists_uuid;
 
@@ -1318,7 +1318,7 @@ INSERT INTO mcv_lists_arrays (a, b, c)
          ARRAY[fipshash((i/100)::text), fipshash((i/100-1)::text), fipshash((i/100+1)::text)],
          ARRAY[(i/100-1)::numeric/1000, (i/100)::numeric/1000, (i/100+1)::numeric/1000],
          ARRAY[(i/100-1), i/100, (i/100+1)]
-     FROM generate_series(1,5000) s(i);
+     FROM generate_series(1, 495 * 5000) s(i);
 
 CREATE STATISTICS mcv_lists_arrays_stats (mcv) ON a, b, c
   FROM mcv_lists_arrays;
@@ -1336,7 +1336,7 @@ WITH (autovacuum_enabled = off);
 INSERT INTO mcv_lists_bool (a, b, c)
      SELECT
          (mod(i,2) = 0), (mod(i,4) = 0), (mod(i,8) = 0)
-     FROM generate_series(1,10000) s(i);
+     FROM generate_series(1, 495 * 10000) s(i);
 
 ANALYZE mcv_lists_bool;
 
@@ -1374,7 +1374,7 @@ INSERT INTO mcv_lists_partial (a, b, c)
          mod(i,10),
          mod(i,10),
          mod(i,10)
-     FROM generate_series(0,999) s(i);
+     FROM generate_series(0, 495 * 999) s(i);
 
 -- 100 groups that will make it to the MCV list (includes the 10 frequent ones)
 INSERT INTO mcv_lists_partial (a, b, c)
@@ -1382,7 +1382,7 @@ INSERT INTO mcv_lists_partial (a, b, c)
          i,
          i,
          i
-     FROM generate_series(0,99) s(i);
+     FROM generate_series(0, 495 * 99) s(i);
 
 -- 4000 groups in total, most of which won't make it (just a single item)
 INSERT INTO mcv_lists_partial (a, b, c)
@@ -1390,7 +1390,7 @@ INSERT INTO mcv_lists_partial (a, b, c)
          i,
          i,
          i
-     FROM generate_series(0,3999) s(i);
+     FROM generate_series(0, 495 * 3999) s(i);
 
 ANALYZE mcv_lists_partial;
 
@@ -1448,7 +1448,7 @@ INSERT INTO mcv_lists_multi (a, b, c, d)
          mod(i,5),
          mod(i,7),
          mod(i,7)
-    FROM generate_series(1,5000) s(i);
+    FROM generate_series(1, 495 * 5000) s(i);
 
 ANALYZE mcv_lists_multi;
 
@@ -1480,7 +1480,7 @@ DROP TABLE mcv_lists_multi;
 
 -- statistics on integer expressions
 CREATE TABLE expr_stats (a int, b int, c int);
-INSERT INTO expr_stats SELECT mod(i,10), mod(i,10), mod(i,10) FROM generate_series(1,1000) s(i);
+INSERT INTO expr_stats SELECT mod(i,10), mod(i,10), mod(i,10) FROM generate_series(1, 495 * 1000) s(i);
 ANALYZE expr_stats;
 
 SELECT * FROM check_estimated_rows('SELECT * FROM expr_stats WHERE (2*a) = 0 AND (3*b) = 0');
@@ -1497,7 +1497,7 @@ DROP TABLE expr_stats;
 
 -- statistics on a mix columns and expressions
 CREATE TABLE expr_stats (a int, b int, c int);
-INSERT INTO expr_stats SELECT mod(i,10), mod(i,10), mod(i,10) FROM generate_series(1,1000) s(i);
+INSERT INTO expr_stats SELECT mod(i,10), mod(i,10), mod(i,10) FROM generate_series(1, 495 * 1000) s(i);
 ANALYZE expr_stats;
 
 SELECT * FROM check_estimated_rows('SELECT * FROM expr_stats WHERE a = 0 AND (2*a) = 0 AND (3*b) = 0');
@@ -1515,7 +1515,7 @@ DROP TABLE expr_stats;
 
 -- statistics on expressions with different data types
 CREATE TABLE expr_stats (a int, b name, c text);
-INSERT INTO expr_stats SELECT mod(i,10), fipshash(mod(i,10)::text), fipshash(mod(i,10)::text) FROM generate_series(1,1000) s(i);
+INSERT INTO expr_stats SELECT mod(i,10), fipshash(mod(i,10)::text), fipshash(mod(i,10)::text) FROM generate_series(1, 495 * 1000) s(i);
 ANALYZE expr_stats;
 
 SELECT * FROM check_estimated_rows('SELECT * FROM expr_stats WHERE a = 0 AND (b || c) <= ''z'' AND (c || b) >= ''0''');
@@ -1560,7 +1560,7 @@ CREATE TABLE tststats.priv_test_tbl (
 );
 
 INSERT INTO tststats.priv_test_tbl
-     SELECT mod(i,5), mod(i,10) FROM generate_series(1,100) s(i);
+     SELECT mod(i,5), mod(i,10) FROM generate_series(1, 495 * 100) s(i);
 
 CREATE STATISTICS tststats.priv_test_stats (mcv) ON a, b
   FROM tststats.priv_test_tbl;
@@ -1584,7 +1584,7 @@ create schema stts_s2;
 create statistics stts_s1.stts_foo on col1, col2 from stts_t3;
 create statistics stts_s2.stts_yama (dependencies, mcv) on col1, col3 from stts_t3;
 
-insert into stts_t1 select i,i from generate_series(1,100) i;
+insert into stts_t1 select i,i from generate_series(1, 495 * 100) i;
 analyze stts_t1;
 set search_path to public, stts_s1, stts_s2, tststats;
 
diff --git a/src/test/regress/sql/subselect.sql b/src/test/regress/sql/subselect.sql
index e5a562c3f5..faade1512c 100644
--- a/src/test/regress/sql/subselect.sql
+++ b/src/test/regress/sql/subselect.sql
@@ -140,7 +140,7 @@ from int8_tbl group by q1 order by q1;
 -- Unspecified-type literals in output columns should resolve as text
 
 SELECT *, pg_typeof(f1) FROM
-  (SELECT 'foo' AS f1 FROM generate_series(1,3)) ss ORDER BY 1;
+  (SELECT 'foo' AS f1 FROM generate_series(1, 495 * 3)) ss ORDER BY 1;
 
 -- ... unless there's context to suggest differently
 
@@ -585,7 +585,7 @@ where (exists(select 1 from tenk1 k where k.unique1 = t.unique2) or ten < 0)
 create temp table exists_tbl (c1 int, c2 int, c3 int) partition by list (c1);
 create temp table exists_tbl_null partition of exists_tbl for values in (null);
 create temp table exists_tbl_def partition of exists_tbl default;
-insert into exists_tbl select x, x/2, x+1 from generate_series(0,10) x;
+insert into exists_tbl select x, x/2, x+1 from generate_series(0, 495 * 10) x;
 analyze exists_tbl;
 explain (costs off)
 select * from exists_tbl t1
@@ -702,7 +702,7 @@ select exists(select * from nocolumns);
 -- Check behavior with a SubPlan in VALUES (bug #14924)
 --
 select val.x
-  from generate_series(1,10) as s(i),
+  from generate_series(1, 495 * 10) as s(i),
   lateral (
     values ((select s.i + 1)), (s.i + 101)
   ) as val(x)
@@ -738,9 +738,9 @@ select * from int4_tbl where
 --
 explain (verbose, costs off)
 select * from int4_tbl o where (f1, f1) in
-  (select f1, generate_series(1,50) / 10 g from int4_tbl i group by f1);
+  (select f1, generate_series(1, 495 * 50) / 10 g from int4_tbl i group by f1);
 select * from int4_tbl o where (f1, f1) in
-  (select f1, generate_series(1,50) / 10 g from int4_tbl i group by f1);
+  (select f1, generate_series(1, 495 * 50) / 10 g from int4_tbl i group by f1);
 
 --
 -- check for over-optimization of whole-row Var referencing an Append plan
@@ -882,7 +882,7 @@ drop table sq_limit;
 begin;
 
 declare c1 scroll cursor for
- select * from generate_series(1,4) i
+ select * from generate_series(1, 495 * 4) i
   where i <> all (values (2),(3));
 
 move forward all in c1;
diff --git a/src/test/regress/sql/tablesample.sql b/src/test/regress/sql/tablesample.sql
index aa17994277..635262f12d 100644
--- a/src/test/regress/sql/tablesample.sql
+++ b/src/test/regress/sql/tablesample.sql
@@ -2,7 +2,7 @@ CREATE TABLE test_tablesample (id int, name text) WITH (fillfactor=10);
 -- use fillfactor so we don't have to load too much data to get multiple pages
 
 INSERT INTO test_tablesample
-  SELECT i, repeat(i::text, 200) FROM generate_series(0, 9) s(i);
+  SELECT i, repeat(i::text, 200) FROM generate_series(0, 495 * 9) s(i);
 
 SELECT t.id FROM test_tablesample AS t TABLESAMPLE SYSTEM (50) REPEATABLE (0);
 SELECT id FROM test_tablesample TABLESAMPLE SYSTEM (100.0/11) REPEATABLE (0);
diff --git a/src/test/regress/sql/tablespace.sql b/src/test/regress/sql/tablespace.sql
index 0f9c136d31..93aa0ced78 100644
--- a/src/test/regress/sql/tablespace.sql
+++ b/src/test/regress/sql/tablespace.sql
@@ -52,7 +52,7 @@ REINDEX (TABLESPACE pg_global) TABLE CONCURRENTLY pg_authid;
 CREATE TABLE regress_tblspace_test_tbl (num1 bigint, num2 double precision, t text);
 INSERT INTO regress_tblspace_test_tbl (num1, num2, t)
   SELECT round(random()*100), random(), 'text'
-  FROM generate_series(1, 10) s(i);
+  FROM generate_series(1, 495 * 10) s(i);
 CREATE INDEX regress_tblspace_test_tbl_idx ON regress_tblspace_test_tbl (num1);
 -- move to global tablespace, fail
 REINDEX (TABLESPACE pg_global) INDEX regress_tblspace_test_tbl_idx;
diff --git a/src/test/regress/sql/temp.sql b/src/test/regress/sql/temp.sql
index 2a487a1ef7..5204745383 100644
--- a/src/test/regress/sql/temp.sql
+++ b/src/test/regress/sql/temp.sql
@@ -109,7 +109,7 @@ begin
     CREATE TEMP TABLE temptest (col text CHECK (col < %L)) ON COMMIT DROP
   $cmd$,
     (SELECT string_agg(g.i::text || ':' || random()::text, '|')
-     FROM generate_series(1, 100) g(i)));
+     FROM generate_series(1, 495 * 100) g(i)));
 end$$;
 
 SELECT * FROM temptest;
diff --git a/src/test/regress/sql/text.sql b/src/test/regress/sql/text.sql
index 540e551254..3e95162866 100644
--- a/src/test/regress/sql/text.sql
+++ b/src/test/regress/sql/text.sql
@@ -93,7 +93,7 @@ select format('%2$s, %1$s', variadic array[1, 2]);
 select format('Hello', variadic NULL::int[]);
 -- variadic argument allows simulating more than FUNC_MAX_ARGS parameters
 select format(string_agg('%s',','), variadic array_agg(i))
-from generate_series(1,200) g(i);
+from generate_series(1, 495 * 200) g(i);
 -- check field widths and left, right alignment
 select format('>>%10s<<', 'Hello');
 select format('>>%10s<<', NULL);
diff --git a/src/test/regress/sql/tidrangescan.sql b/src/test/regress/sql/tidrangescan.sql
index ac09ebb626..fd80cd1646 100644
--- a/src/test/regress/sql/tidrangescan.sql
+++ b/src/test/regress/sql/tidrangescan.sql
@@ -13,7 +13,7 @@ SELECT ctid FROM tidrangescan WHERE ctid > '(9, 0)';
 SELECT ctid FROM tidrangescan WHERE ctid > '(9, 0)';
 
 -- insert enough tuples to fill at least two pages
-INSERT INTO tidrangescan SELECT i,repeat('x', 100) FROM generate_series(1,200) AS s(i);
+INSERT INTO tidrangescan SELECT i,repeat('x', 100) FROM generate_series(1, 495 * 200) AS s(i);
 
 -- remove all tuples after the 10th tuple on each page.  Trying to ensure
 -- we get the same layout with all CPU architectures and smaller than standard
diff --git a/src/test/regress/sql/triggers.sql b/src/test/regress/sql/triggers.sql
index a3c3115a6e..23d6f09750 100644
--- a/src/test/regress/sql/triggers.sql
+++ b/src/test/regress/sql/triggers.sql
@@ -667,7 +667,7 @@ CREATE TRIGGER serializable_update_trig BEFORE UPDATE ON serializable_update_tab
 	FOR EACH ROW EXECUTE PROCEDURE serializable_update_trig();
 
 INSERT INTO serializable_update_tab SELECT a, repeat('xyzxz', 100), 'new'
-	FROM generate_series(1, 50) a;
+	FROM generate_series(1, 495 * 50) a;
 
 BEGIN;
 SET TRANSACTION ISOLATION LEVEL SERIALIZABLE;
diff --git a/src/test/regress/sql/tsrf.sql b/src/test/regress/sql/tsrf.sql
index 7c22529a0d..48ff618903 100644
--- a/src/test/regress/sql/tsrf.sql
+++ b/src/test/regress/sql/tsrf.sql
@@ -3,27 +3,27 @@
 --
 
 -- simple srf
-SELECT generate_series(1, 3);
+SELECT generate_series(1, 495 * 3);
 
 -- parallel iteration
-SELECT generate_series(1, 3), generate_series(3,5);
+SELECT generate_series(1, 495 * 3), generate_series(3,5);
 
 -- parallel iteration, different number of rows
-SELECT generate_series(1, 2), generate_series(1,4);
+SELECT generate_series(1, 495 * 2), generate_series(1, 495 * 4);
 
 -- srf, with SRF argument
-SELECT generate_series(1, generate_series(1, 3));
+SELECT generate_series(1, generate_series(1, 495 * 3));
 
 -- but we've traditionally rejected the same in FROM
-SELECT * FROM generate_series(1, generate_series(1, 3));
+SELECT * FROM generate_series(1, generate_series(1, 495 * 3));
 
 -- srf, with two SRF arguments
-SELECT generate_series(generate_series(1,3), generate_series(2, 4));
+SELECT generate_series(generate_series(1, 495 * 3), generate_series(2, 4));
 
 -- check proper nesting of SRFs in different expressions
 explain (verbose, costs off)
-SELECT generate_series(1, generate_series(1, 3)), generate_series(2, 4);
-SELECT generate_series(1, generate_series(1, 3)), generate_series(2, 4);
+SELECT generate_series(1, generate_series(1, 495 * 3)), generate_series(2, 4);
+SELECT generate_series(1, generate_series(1, 495 * 3)), generate_series(2, 4);
 
 CREATE TABLE few(id int, dataa text, datab text);
 INSERT INTO few VALUES(1, 'a', 'foo'),(2, 'a', 'bar'),(3, 'b', 'bar');
@@ -41,14 +41,14 @@ SELECT * FROM few f1,
   (SELECT unnest(ARRAY[1,2]) FROM few f2 WHERE false OFFSET 0) ss;
 
 -- SRF output order of sorting is maintained, if SRF is not referenced
-SELECT few.id, generate_series(1,3) g FROM few ORDER BY id DESC;
+SELECT few.id, generate_series(1, 495 * 3) g FROM few ORDER BY id DESC;
 
 -- but SRFs can be referenced in sort
-SELECT few.id, generate_series(1,3) g FROM few ORDER BY id, g DESC;
-SELECT few.id, generate_series(1,3) g FROM few ORDER BY id, generate_series(1,3) DESC;
+SELECT few.id, generate_series(1, 495 * 3) g FROM few ORDER BY id, g DESC;
+SELECT few.id, generate_series(1, 495 * 3) g FROM few ORDER BY id, generate_series(1, 495 * 3) DESC;
 
 -- it's weird to have ORDER BYs that increase the number of results
-SELECT few.id FROM few ORDER BY id, generate_series(1,3) DESC;
+SELECT few.id FROM few ORDER BY id, generate_series(1, 495 * 3) DESC;
 
 -- SRFs are computed after aggregation
 SET enable_hashagg TO 0; -- stable output order
@@ -59,54 +59,54 @@ SELECT few.dataa, count(*), min(id), max(id), unnest('{1,1,3}'::int[]) FROM few
 RESET enable_hashagg;
 
 -- check HAVING works when GROUP BY does [not] reference SRF output
-SELECT dataa, generate_series(1,1), count(*) FROM few GROUP BY 1 HAVING count(*) > 1;
-SELECT dataa, generate_series(1,1), count(*) FROM few GROUP BY 1, 2 HAVING count(*) > 1;
+SELECT dataa, generate_series(1, 495 * 1), count(*) FROM few GROUP BY 1 HAVING count(*) > 1;
+SELECT dataa, generate_series(1, 495 * 1), count(*) FROM few GROUP BY 1, 2 HAVING count(*) > 1;
 
 -- it's weird to have GROUP BYs that increase the number of results
 SELECT few.dataa, count(*) FROM few WHERE dataa = 'a' GROUP BY few.dataa ORDER BY 2;
 SELECT few.dataa, count(*) FROM few WHERE dataa = 'a' GROUP BY few.dataa, unnest('{1,1,3}'::int[]) ORDER BY 2;
 
 -- SRFs are not allowed if they'd need to be conditionally executed
-SELECT q1, case when q1 > 0 then generate_series(1,3) else 0 end FROM int8_tbl;
-SELECT q1, coalesce(generate_series(1,3), 0) FROM int8_tbl;
+SELECT q1, case when q1 > 0 then generate_series(1, 495 * 3) else 0 end FROM int8_tbl;
+SELECT q1, coalesce(generate_series(1, 495 * 3), 0) FROM int8_tbl;
 
 -- SRFs are not allowed in aggregate arguments
-SELECT min(generate_series(1, 3)) FROM few;
+SELECT min(generate_series(1, 495 * 3)) FROM few;
 
 -- ... unless they're within a sub-select
-SELECT sum((3 = ANY(SELECT generate_series(1,4)))::int);
+SELECT sum((3 = ANY(SELECT generate_series(1, 495 * 4)))::int);
 
 SELECT sum((3 = ANY(SELECT lag(x) over(order by x)
-                    FROM generate_series(1,4) x))::int);
+                    FROM generate_series(1, 495 * 4) x))::int);
 
 -- SRFs are not allowed in window function arguments, either
-SELECT min(generate_series(1, 3)) OVER() FROM few;
+SELECT min(generate_series(1, 495 * 3)) OVER() FROM few;
 
 -- SRFs are normally computed after window functions
-SELECT id,lag(id) OVER(), count(*) OVER(), generate_series(1,3) FROM few;
+SELECT id,lag(id) OVER(), count(*) OVER(), generate_series(1, 495 * 3) FROM few;
 -- unless referencing SRFs
-SELECT SUM(count(*)) OVER(PARTITION BY generate_series(1,3) ORDER BY generate_series(1,3)), generate_series(1,3) g FROM few GROUP BY g;
+SELECT SUM(count(*)) OVER(PARTITION BY generate_series(1, 495 * 3) ORDER BY generate_series(1, 495 * 3)), generate_series(1, 495 * 3) g FROM few GROUP BY g;
 
 -- sorting + grouping
-SELECT few.dataa, count(*), min(id), max(id), generate_series(1,3) FROM few GROUP BY few.dataa ORDER BY 5, 1;
+SELECT few.dataa, count(*), min(id), max(id), generate_series(1, 495 * 3) FROM few GROUP BY few.dataa ORDER BY 5, 1;
 
 -- grouping sets are a bit special, they produce NULLs in columns not actually NULL
 set enable_hashagg = false;
-SELECT dataa, datab b, generate_series(1,2) g, count(*) FROM few GROUP BY CUBE(dataa, datab);
-SELECT dataa, datab b, generate_series(1,2) g, count(*) FROM few GROUP BY CUBE(dataa, datab) ORDER BY dataa;
-SELECT dataa, datab b, generate_series(1,2) g, count(*) FROM few GROUP BY CUBE(dataa, datab) ORDER BY g;
-SELECT dataa, datab b, generate_series(1,2) g, count(*) FROM few GROUP BY CUBE(dataa, datab, g);
-SELECT dataa, datab b, generate_series(1,2) g, count(*) FROM few GROUP BY CUBE(dataa, datab, g) ORDER BY dataa;
-SELECT dataa, datab b, generate_series(1,2) g, count(*) FROM few GROUP BY CUBE(dataa, datab, g) ORDER BY g;
+SELECT dataa, datab b, generate_series(1, 495 * 2) g, count(*) FROM few GROUP BY CUBE(dataa, datab);
+SELECT dataa, datab b, generate_series(1, 495 * 2) g, count(*) FROM few GROUP BY CUBE(dataa, datab) ORDER BY dataa;
+SELECT dataa, datab b, generate_series(1, 495 * 2) g, count(*) FROM few GROUP BY CUBE(dataa, datab) ORDER BY g;
+SELECT dataa, datab b, generate_series(1, 495 * 2) g, count(*) FROM few GROUP BY CUBE(dataa, datab, g);
+SELECT dataa, datab b, generate_series(1, 495 * 2) g, count(*) FROM few GROUP BY CUBE(dataa, datab, g) ORDER BY dataa;
+SELECT dataa, datab b, generate_series(1, 495 * 2) g, count(*) FROM few GROUP BY CUBE(dataa, datab, g) ORDER BY g;
 reset enable_hashagg;
 
 -- case with degenerate ORDER BY
 explain (verbose, costs off)
-select 'foo' as f, generate_series(1,2) as g from few order by 1;
-select 'foo' as f, generate_series(1,2) as g from few order by 1;
+select 'foo' as f, generate_series(1, 495 * 2) as g from few order by 1;
+select 'foo' as f, generate_series(1, 495 * 2) as g from few order by 1;
 
 -- data modification
-CREATE TABLE fewmore AS SELECT generate_series(1,3) AS data;
+CREATE TABLE fewmore AS SELECT generate_series(1, 495 * 3) AS data;
 INSERT INTO fewmore VALUES(generate_series(4,5));
 SELECT * FROM fewmore;
 
@@ -114,54 +114,54 @@ SELECT * FROM fewmore;
 UPDATE fewmore SET data = generate_series(4,9);
 
 -- SRFs are not allowed in RETURNING
-INSERT INTO fewmore VALUES(1) RETURNING generate_series(1,3);
+INSERT INTO fewmore VALUES(1) RETURNING generate_series(1, 495 * 3);
 
 -- nor standalone VALUES (but surely this is a bug?)
-VALUES(1, generate_series(1,2));
+VALUES(1, generate_series(1, 495 * 2));
 
 -- We allow tSRFs that are not at top level
-SELECT int4mul(generate_series(1,2), 10);
-SELECT generate_series(1,3) IS DISTINCT FROM 2;
+SELECT int4mul(generate_series(1, 495 * 2), 10);
+SELECT generate_series(1, 495 * 3) IS DISTINCT FROM 2;
 
 -- but SRFs in function RTEs must be at top level (annoying restriction)
-SELECT * FROM int4mul(generate_series(1,2), 10);
+SELECT * FROM int4mul(generate_series(1, 495 * 2), 10);
 
 -- DISTINCT ON is evaluated before tSRF evaluation if SRF is not
 -- referenced either in ORDER BY or in the DISTINCT ON list. The ORDER
 -- BY reference can be implicitly generated, if there's no other ORDER BY.
 
 -- implicit reference (via implicit ORDER) to all columns
-SELECT DISTINCT ON (a) a, b, generate_series(1,3) g
+SELECT DISTINCT ON (a) a, b, generate_series(1, 495 * 3) g
 FROM (VALUES (3, 2), (3,1), (1,1), (1,4), (5,3), (5,1)) AS t(a, b);
 
 -- unreferenced in DISTINCT ON or ORDER BY
-SELECT DISTINCT ON (a) a, b, generate_series(1,3) g
+SELECT DISTINCT ON (a) a, b, generate_series(1, 495 * 3) g
 FROM (VALUES (3, 2), (3,1), (1,1), (1,4), (5,3), (5,1)) AS t(a, b)
 ORDER BY a, b DESC;
 
 -- referenced in ORDER BY
-SELECT DISTINCT ON (a) a, b, generate_series(1,3) g
+SELECT DISTINCT ON (a) a, b, generate_series(1, 495 * 3) g
 FROM (VALUES (3, 2), (3,1), (1,1), (1,4), (5,3), (5,1)) AS t(a, b)
 ORDER BY a, b DESC, g DESC;
 
 -- referenced in ORDER BY and DISTINCT ON
-SELECT DISTINCT ON (a, b, g) a, b, generate_series(1,3) g
+SELECT DISTINCT ON (a, b, g) a, b, generate_series(1, 495 * 3) g
 FROM (VALUES (3, 2), (3,1), (1,1), (1,4), (5,3), (5,1)) AS t(a, b)
 ORDER BY a, b DESC, g DESC;
 
 -- only SRF mentioned in DISTINCT ON
-SELECT DISTINCT ON (g) a, b, generate_series(1,3) g
+SELECT DISTINCT ON (g) a, b, generate_series(1, 495 * 3) g
 FROM (VALUES (3, 2), (3,1), (1,1), (1,4), (5,3), (5,1)) AS t(a, b);
 
 -- LIMIT / OFFSET is evaluated after SRF evaluation
-SELECT a, generate_series(1,2) FROM (VALUES(1),(2),(3)) r(a) LIMIT 2 OFFSET 2;
+SELECT a, generate_series(1, 495 * 2) FROM (VALUES(1),(2),(3)) r(a) LIMIT 2 OFFSET 2;
 -- SRFs are not allowed in LIMIT.
-SELECT 1 LIMIT generate_series(1,3);
+SELECT 1 LIMIT generate_series(1, 495 * 3);
 
 -- tSRF in correlated subquery, referencing table outside
-SELECT (SELECT generate_series(1,3) LIMIT 1 OFFSET few.id) FROM few;
+SELECT (SELECT generate_series(1, 495 * 3) LIMIT 1 OFFSET few.id) FROM few;
 -- tSRF in correlated subquery, referencing SRF outside
-SELECT (SELECT generate_series(1,3) LIMIT 1 OFFSET g.i) FROM generate_series(0,3) g(i);
+SELECT (SELECT generate_series(1, 495 * 3) LIMIT 1 OFFSET g.i) FROM generate_series(0, 495 * 3) g(i);
 
 -- Operators can return sets too
 CREATE OPERATOR |@| (PROCEDURE = unnest, RIGHTARG = ANYARRAY);
@@ -169,16 +169,16 @@ SELECT |@|ARRAY[1,2,3];
 
 -- Some fun cases involving duplicate SRF calls
 explain (verbose, costs off)
-select generate_series(1,3) as x, generate_series(1,3) + 1 as xp1;
-select generate_series(1,3) as x, generate_series(1,3) + 1 as xp1;
+select generate_series(1, 495 * 3) as x, generate_series(1, 495 * 3) + 1 as xp1;
+select generate_series(1, 495 * 3) as x, generate_series(1, 495 * 3) + 1 as xp1;
 explain (verbose, costs off)
-select generate_series(1,3)+1 order by generate_series(1,3);
-select generate_series(1,3)+1 order by generate_series(1,3);
+select generate_series(1, 495 * 3)+1 order by generate_series(1, 495 * 3);
+select generate_series(1, 495 * 3)+1 order by generate_series(1, 495 * 3);
 
 -- Check that SRFs of same nesting level run in lockstep
 explain (verbose, costs off)
-select generate_series(1,3) as x, generate_series(3,6) + 1 as y;
-select generate_series(1,3) as x, generate_series(3,6) + 1 as y;
+select generate_series(1, 495 * 3) as x, generate_series(3,6) + 1 as y;
+select generate_series(1, 495 * 3) as x, generate_series(3,6) + 1 as y;
 
 -- Clean up
 DROP TABLE few;
diff --git a/src/test/regress/sql/tuplesort.sql b/src/test/regress/sql/tuplesort.sql
index 8476e594e6..c0570b9ce8 100644
--- a/src/test/regress/sql/tuplesort.sql
+++ b/src/test/regress/sql/tuplesort.sql
@@ -276,7 +276,7 @@ ROLLBACK;
 CREATE TEMP TABLE test_mark_restore(col1 int, col2 int, col12 int);
 -- need a few duplicates for mark/restore to matter
 INSERT INTO test_mark_restore(col1, col2, col12)
-   SELECT a.i, b.i, a.i * b.i FROM generate_series(1, 500) a(i), generate_series(1, 5) b(i);
+   SELECT a.i, b.i, a.i * b.i FROM generate_series(1, 500) a(i), generate_series(1, 495 * 5) b(i);
 
 BEGIN;
 
diff --git a/src/test/regress/sql/union.sql b/src/test/regress/sql/union.sql
index f8826514e4..63d94ae2e6 100644
--- a/src/test/regress/sql/union.sql
+++ b/src/test/regress/sql/union.sql
@@ -312,39 +312,39 @@ set enable_sort = false;
 -- fine to make use of Unique, which is cheaper than HashAggregate and we've
 -- no means to disable Unique.
 explain (costs off)
-select from generate_series(1,5) intersect select from generate_series(1,3);
+select from generate_series(1, 495 * 5) intersect select from generate_series(1, 495 * 3);
 
-select from generate_series(1,5) union all select from generate_series(1,3);
-select from generate_series(1,5) intersect select from generate_series(1,3);
-select from generate_series(1,5) intersect all select from generate_series(1,3);
-select from generate_series(1,5) except select from generate_series(1,3);
-select from generate_series(1,5) except all select from generate_series(1,3);
+select from generate_series(1, 495 * 5) union all select from generate_series(1, 495 * 3);
+select from generate_series(1, 495 * 5) intersect select from generate_series(1, 495 * 3);
+select from generate_series(1, 495 * 5) intersect all select from generate_series(1, 495 * 3);
+select from generate_series(1, 495 * 5) except select from generate_series(1, 495 * 3);
+select from generate_series(1, 495 * 5) except all select from generate_series(1, 495 * 3);
 
 -- check sorted implementation
 set enable_hashagg = false;
 set enable_sort = true;
 
 explain (costs off)
-select from generate_series(1,5) union select from generate_series(1,3);
+select from generate_series(1, 495 * 5) union select from generate_series(1, 495 * 3);
 explain (costs off)
-select from generate_series(1,5) intersect select from generate_series(1,3);
+select from generate_series(1, 495 * 5) intersect select from generate_series(1, 495 * 3);
 
-select from generate_series(1,5) union select from generate_series(1,3);
-select from generate_series(1,5) union all select from generate_series(1,3);
-select from generate_series(1,5) intersect select from generate_series(1,3);
-select from generate_series(1,5) intersect all select from generate_series(1,3);
-select from generate_series(1,5) except select from generate_series(1,3);
-select from generate_series(1,5) except all select from generate_series(1,3);
+select from generate_series(1, 495 * 5) union select from generate_series(1, 495 * 3);
+select from generate_series(1, 495 * 5) union all select from generate_series(1, 495 * 3);
+select from generate_series(1, 495 * 5) intersect select from generate_series(1, 495 * 3);
+select from generate_series(1, 495 * 5) intersect all select from generate_series(1, 495 * 3);
+select from generate_series(1, 495 * 5) except select from generate_series(1, 495 * 3);
+select from generate_series(1, 495 * 5) except all select from generate_series(1, 495 * 3);
 
 -- Try a variation of the above but with a CTE which contains a column, again
 -- with an empty final select list.
 
 -- Ensure we get the expected 1 row with 0 columns
-with cte as materialized (select s from generate_series(1,5) s)
+with cte as materialized (select s from generate_series(1, 495 * 5) s)
 select from cte union select from cte;
 
 -- Ensure we get the same result as the above.
-with cte as not materialized (select s from generate_series(1,5) s)
+with cte as not materialized (select s from generate_series(1, 495 * 5) s)
 select from cte union select from cte;
 
 reset enable_hashagg;
@@ -470,14 +470,14 @@ ORDER BY x;
 
 explain (costs off)
 SELECT * FROM
-  (SELECT 1 AS t, generate_series(1,10) AS x
+  (SELECT 1 AS t, generate_series(1, 495 * 10) AS x
    UNION
    SELECT 2 AS t, 4 AS x) ss
 WHERE x < 4
 ORDER BY x;
 
 SELECT * FROM
-  (SELECT 1 AS t, generate_series(1,10) AS x
+  (SELECT 1 AS t, generate_series(1, 495 * 10) AS x
    UNION
    SELECT 2 AS t, 4 AS x) ss
 WHERE x < 4
diff --git a/src/test/regress/sql/updatable_views.sql b/src/test/regress/sql/updatable_views.sql
index 93b693ae83..c1fae18088 100644
--- a/src/test/regress/sql/updatable_views.sql
+++ b/src/test/regress/sql/updatable_views.sql
@@ -22,7 +22,7 @@ CREATE VIEW ro_view8 AS SELECT a, b FROM base_tbl ORDER BY a OFFSET 1; -- OFFSET
 CREATE VIEW ro_view9 AS SELECT a, b FROM base_tbl ORDER BY a LIMIT 1; -- LIMIT not supported
 CREATE VIEW ro_view10 AS SELECT 1 AS a; -- No base relations
 CREATE VIEW ro_view11 AS SELECT b1.a, b2.b FROM base_tbl b1, base_tbl b2; -- Multiple base relations
-CREATE VIEW ro_view12 AS SELECT * FROM generate_series(1, 10) AS g(a); -- SRF in rangetable
+CREATE VIEW ro_view12 AS SELECT * FROM generate_series(1, 495 * 10) AS g(a); -- SRF in rangetable
 CREATE VIEW ro_view13 AS SELECT a, b FROM (SELECT * FROM base_tbl) AS t; -- Subselect in rangetable
 CREATE VIEW rw_view14 AS SELECT ctid, a, b FROM base_tbl; -- System columns may be part of an updatable view
 CREATE VIEW rw_view15 AS SELECT a, upper(b) FROM base_tbl; -- Expression/function may be part of an updatable view
@@ -203,17 +203,17 @@ MERGE INTO rw_view1 t USING (VALUES (5, 'X')) AS v(a,b) ON t.a = v.a
 
 EXPLAIN (costs off)
 MERGE INTO rw_view1 t
-  USING (SELECT * FROM generate_series(1,5)) AS s(a) ON t.a = s.a
+  USING (SELECT * FROM generate_series(1, 495 * 5)) AS s(a) ON t.a = s.a
   WHEN MATCHED THEN UPDATE SET b = 'Updated';
 
 EXPLAIN (costs off)
 MERGE INTO rw_view1 t
-  USING (SELECT * FROM generate_series(1,5)) AS s(a) ON t.a = s.a
+  USING (SELECT * FROM generate_series(1, 495 * 5)) AS s(a) ON t.a = s.a
   WHEN NOT MATCHED BY SOURCE THEN DELETE;
 
 EXPLAIN (costs off)
 MERGE INTO rw_view1 t
-  USING (SELECT * FROM generate_series(1,5)) AS s(a) ON t.a = s.a
+  USING (SELECT * FROM generate_series(1, 495 * 5)) AS s(a) ON t.a = s.a
   WHEN NOT MATCHED THEN INSERT (a) VALUES (s.a);
 
 -- it's still updatable if we add a DO ALSO rule
@@ -486,7 +486,7 @@ DELETE FROM rw_view2 WHERE a=3 RETURNING *;
 SELECT * FROM rw_view2;
 
 MERGE INTO rw_view2 t
-  USING (SELECT x, 'R'||x FROM generate_series(0,3) x) AS s(a,b) ON t.a = s.a
+  USING (SELECT x, 'R'||x FROM generate_series(0, 495 * 3) x) AS s(a,b) ON t.a = s.a
   WHEN MATCHED AND t.a <= 1 THEN DELETE
   WHEN MATCHED THEN UPDATE SET b = s.b
   WHEN NOT MATCHED AND s.a > 0 THEN INSERT VALUES (s.a, s.b)
@@ -506,7 +506,7 @@ EXPLAIN (costs off) DELETE FROM rw_view2 WHERE a=2;
 
 EXPLAIN (costs off)
 MERGE INTO rw_view2 t
-  USING (SELECT x, 'R'||x FROM generate_series(0,3) x) AS s(a,b) ON t.a = s.a
+  USING (SELECT x, 'R'||x FROM generate_series(0, 495 * 3) x) AS s(a,b) ON t.a = s.a
   WHEN MATCHED AND t.a <= 1 THEN DELETE
   WHEN MATCHED THEN UPDATE SET b = s.b
   WHEN NOT MATCHED AND s.a > 0 THEN INSERT VALUES (s.a, s.b);
@@ -514,7 +514,7 @@ MERGE INTO rw_view2 t
 -- MERGE with incomplete set of INSTEAD OF triggers
 DROP TRIGGER rw_view1_del_trig ON rw_view1;
 MERGE INTO rw_view2 t
-  USING (SELECT x, 'R'||x FROM generate_series(0,3) x) AS s(a,b) ON t.a = s.a
+  USING (SELECT x, 'R'||x FROM generate_series(0, 495 * 3) x) AS s(a,b) ON t.a = s.a
   WHEN MATCHED AND t.a <= 1 THEN DELETE
   WHEN MATCHED THEN UPDATE SET b = s.b
   WHEN NOT MATCHED AND s.a > 0 THEN INSERT VALUES (s.a, s.b); -- should fail
@@ -525,22 +525,22 @@ MERGE INTO rw_view2 t
 
 DROP TRIGGER rw_view1_ins_trig ON rw_view1;
 MERGE INTO rw_view2 t
-  USING (SELECT x, 'R'||x FROM generate_series(0,3) x) AS s(a,b) ON t.a = s.a
+  USING (SELECT x, 'R'||x FROM generate_series(0, 495 * 3) x) AS s(a,b) ON t.a = s.a
   WHEN MATCHED THEN UPDATE SET b = s.b
   WHEN NOT MATCHED AND s.a > 0 THEN INSERT VALUES (s.a, s.b); -- should fail
 MERGE INTO rw_view2 t
-  USING (SELECT x, 'R'||x FROM generate_series(0,3) x) AS s(a,b) ON t.a = s.a
+  USING (SELECT x, 'R'||x FROM generate_series(0, 495 * 3) x) AS s(a,b) ON t.a = s.a
   WHEN MATCHED THEN UPDATE SET b = s.b; -- ok
 
 -- MERGE with INSTEAD OF triggers on auto-updatable view
 CREATE TRIGGER rw_view2_upd_trig INSTEAD OF UPDATE ON rw_view2
   FOR EACH ROW EXECUTE PROCEDURE rw_view1_trig_fn();
 MERGE INTO rw_view2 t
-  USING (SELECT x, 'R'||x FROM generate_series(0,3) x) AS s(a,b) ON t.a = s.a
+  USING (SELECT x, 'R'||x FROM generate_series(0, 495 * 3) x) AS s(a,b) ON t.a = s.a
   WHEN MATCHED THEN UPDATE SET b = s.b
   WHEN NOT MATCHED AND s.a > 0 THEN INSERT VALUES (s.a, s.b); -- should fail
 MERGE INTO rw_view2 t
-  USING (SELECT x, 'R'||x FROM generate_series(0,3) x) AS s(a,b) ON t.a = s.a
+  USING (SELECT x, 'R'||x FROM generate_series(0, 495 * 3) x) AS s(a,b) ON t.a = s.a
   WHEN MATCHED THEN UPDATE SET b = s.b; -- ok
 SELECT * FROM base_tbl ORDER BY a;
 
@@ -1101,7 +1101,7 @@ DROP TABLE base_tbl CASCADE;
 -- views with updatable and non-updatable columns
 
 CREATE TABLE base_tbl(a float);
-INSERT INTO base_tbl SELECT i/10.0 FROM generate_series(1,10) g(i);
+INSERT INTO base_tbl SELECT i/10.0 FROM generate_series(1, 495 * 10) g(i);
 
 CREATE VIEW rw_view1 AS
   SELECT ctid, sin(a) s, a, cos(a) c
@@ -1187,7 +1187,7 @@ DROP TABLE base_tbl CASCADE;
 CREATE TABLE base_tbl_parent (a int);
 CREATE TABLE base_tbl_child (CHECK (a > 0)) INHERITS (base_tbl_parent);
 INSERT INTO base_tbl_parent SELECT * FROM generate_series(-8, -1);
-INSERT INTO base_tbl_child SELECT * FROM generate_series(1, 8);
+INSERT INTO base_tbl_child SELECT * FROM generate_series(1, 495 * 8);
 
 CREATE VIEW rw_view1 AS SELECT * FROM base_tbl_parent;
 CREATE VIEW rw_view2 AS SELECT * FROM ONLY base_tbl_parent;
@@ -1352,7 +1352,7 @@ DROP TABLE base_tbl CASCADE;
 
 CREATE TABLE base_tbl (a int);
 CREATE TABLE ref_tbl (a int PRIMARY KEY);
-INSERT INTO ref_tbl SELECT * FROM generate_series(1,10);
+INSERT INTO ref_tbl SELECT * FROM generate_series(1, 495 * 10);
 
 CREATE VIEW rw_view1 AS
   SELECT * FROM base_tbl b
@@ -1606,25 +1606,25 @@ DROP TABLE base_tbl CASCADE;
 CREATE TABLE t1 (a int, b float, c text);
 CREATE INDEX t1_a_idx ON t1(a);
 INSERT INTO t1
-SELECT i,i,'t1' FROM generate_series(1,10) g(i);
+SELECT i,i,'t1' FROM generate_series(1, 495 * 10) g(i);
 ANALYZE t1;
 
 CREATE TABLE t11 (d text) INHERITS (t1);
 CREATE INDEX t11_a_idx ON t11(a);
 INSERT INTO t11
-SELECT i,i,'t11','t11d' FROM generate_series(1,10) g(i);
+SELECT i,i,'t11','t11d' FROM generate_series(1, 495 * 10) g(i);
 ANALYZE t11;
 
 CREATE TABLE t12 (e int[]) INHERITS (t1);
 CREATE INDEX t12_a_idx ON t12(a);
 INSERT INTO t12
-SELECT i,i,'t12','{1,2}'::int[] FROM generate_series(1,10) g(i);
+SELECT i,i,'t12','{1,2}'::int[] FROM generate_series(1, 495 * 10) g(i);
 ANALYZE t12;
 
 CREATE TABLE t111 () INHERITS (t11, t12);
 CREATE INDEX t111_a_idx ON t111(a);
 INSERT INTO t111
-SELECT i,i,'t111','t111d','{1,1,1}'::int[] FROM generate_series(1,10) g(i);
+SELECT i,i,'t111','t111d','{1,1,1}'::int[] FROM generate_series(1, 495 * 10) g(i);
 ANALYZE t111;
 
 CREATE VIEW v1 WITH (security_barrier=true) AS
diff --git a/src/test/regress/sql/vacuum.sql b/src/test/regress/sql/vacuum.sql
index d272dd064e..2ab71891c2 100644
--- a/src/test/regress/sql/vacuum.sql
+++ b/src/test/regress/sql/vacuum.sql
@@ -59,7 +59,7 @@ ANALYZE vaccluster;
 -- https://postgr.es/m/c7988239-d42c-ddc4-41db-171b23b35e4f%40ssinger.info
 -- (which hopefully is unlikely to be reintroduced), but also seems
 -- independently worthwhile to cover.
-INSERT INTO vactst SELECT generate_series(1, 300);
+INSERT INTO vactst SELECT generate_series(1, 495 * 300);
 DELETE FROM vactst WHERE i % 7 = 0; -- delete a few rows outside
 BEGIN;
 INSERT INTO vactst SELECT generate_series(301, 400);
@@ -106,7 +106,7 @@ VACUUM (DISABLE_PAGE_SKIPPING) vaccluster;
 
 -- PARALLEL option
 CREATE TABLE pvactst (i INT, a INT[], p POINT) with (autovacuum_enabled = off);
-INSERT INTO pvactst SELECT i, array[1,2,3], point(i, i+1) FROM generate_series(1,1000) i;
+INSERT INTO pvactst SELECT i, array[1,2,3], point(i, i+1) FROM generate_series(1, 495 * 1000) i;
 CREATE INDEX btree_pvactst ON pvactst USING btree (i);
 CREATE INDEX hash_pvactst ON pvactst USING hash (i);
 CREATE INDEX brin_pvactst ON pvactst USING brin (i);
@@ -114,7 +114,7 @@ CREATE INDEX gin_pvactst ON pvactst USING gin (a);
 CREATE INDEX gist_pvactst ON pvactst USING gist (p);
 CREATE INDEX spgist_pvactst ON pvactst USING spgist (p);
 CREATE TABLE pvactst2 (i INT) WITH (autovacuum_enabled = off);
-INSERT INTO pvactst2 SELECT generate_series(1, 1000);
+INSERT INTO pvactst2 SELECT generate_series(1, 495 * 1000);
 CREATE INDEX ON pvactst2 (i);
 CREATE INDEX ON pvactst2 (i);
 
@@ -219,7 +219,7 @@ CREATE TABLE vacparted_i1 PARTITION OF vacparted_i
   FOR VALUES WITH (MODULUS 2, REMAINDER 0);
 CREATE TABLE vacparted_i2 PARTITION OF vacparted_i
   FOR VALUES WITH (MODULUS 2, REMAINDER 1);
-INSERT INTO vacparted_i SELECT i, 'test_'|| i from generate_series(1,10) i;
+INSERT INTO vacparted_i SELECT i, 'test_'|| i from generate_series(1, 495 * 10) i;
 VACUUM (ANALYZE) vacparted_i;
 VACUUM (FULL) vacparted_i;
 VACUUM (FREEZE) vacparted_i;
@@ -275,7 +275,7 @@ COMMIT;
 
 -- PROCESS_TOAST option
 CREATE TABLE vac_option_tab (a INT, t TEXT);
-INSERT INTO vac_option_tab SELECT a, 't' || a FROM generate_series(1, 10) AS a;
+INSERT INTO vac_option_tab SELECT a, 't' || a FROM generate_series(1, 495 * 10) AS a;
 ALTER TABLE vac_option_tab ALTER COLUMN t SET STORAGE EXTERNAL;
 -- Check the number of vacuums done on table vac_option_tab and on its
 -- toast relation, to check that PROCESS_TOAST and PROCESS_MAIN work on
diff --git a/src/test/regress/sql/vacuum_parallel.sql b/src/test/regress/sql/vacuum_parallel.sql
index 1d23f33e39..1c1a489e03 100644
--- a/src/test/regress/sql/vacuum_parallel.sql
+++ b/src/test/regress/sql/vacuum_parallel.sql
@@ -4,7 +4,7 @@ SET min_parallel_index_scan_size TO '128kB';
 -- Bug #17245: Make sure that we don't totally fail to VACUUM individual indexes that
 -- happen to be below min_parallel_index_scan_size during parallel VACUUM:
 CREATE TABLE parallel_vacuum_table (a int) WITH (autovacuum_enabled = off);
-INSERT INTO parallel_vacuum_table SELECT i from generate_series(1, 10000) i;
+INSERT INTO parallel_vacuum_table SELECT i from generate_series(1, 495 * 10000) i;
 
 -- Parallel VACUUM will never be used unless there are at least two indexes
 -- that exceed min_parallel_index_scan_size.  Create two such indexes, and
@@ -37,7 +37,7 @@ VACUUM (PARALLEL 4, INDEX_CLEANUP ON) parallel_vacuum_table;
 
 -- Since vacuum_in_leader_small_index uses deduplication, we expect an
 -- assertion failure with bug #17245 (in the absence of bugfix):
-INSERT INTO parallel_vacuum_table SELECT i FROM generate_series(1, 10000) i;
+INSERT INTO parallel_vacuum_table SELECT i FROM generate_series(1, 495 * 10000) i;
 
 RESET max_parallel_maintenance_workers;
 RESET min_parallel_index_scan_size;
diff --git a/src/test/regress/sql/window.sql b/src/test/regress/sql/window.sql
index 02f105f070..364902a842 100644
--- a/src/test/regress/sql/window.sql
+++ b/src/test/regress/sql/window.sql
@@ -155,7 +155,7 @@ select first_value(max(x)) over (), y
 
 -- window functions returning pass-by-ref values from different rows
 select x, lag(x, 1) over (order by x), lead(x, 3) over (order by x)
-from (select x::numeric as x from generate_series(1,10) x);
+from (select x::numeric as x from generate_series(1, 495 * 10) x);
 
 -- test non-default frame specifications
 SELECT four, ten,
@@ -277,7 +277,7 @@ FROM tenk1 WHERE unique1 < 10;
 
 CREATE TEMP VIEW v_window AS
 	SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following) as sum_rows
-	FROM generate_series(1, 10) i;
+	FROM generate_series(1, 495 * 10) i;
 
 SELECT * FROM v_window;
 
@@ -285,7 +285,7 @@ SELECT pg_get_viewdef('v_window');
 
 CREATE OR REPLACE TEMP VIEW v_window AS
 	SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following
-	exclude current row) as sum_rows FROM generate_series(1, 10) i;
+	exclude current row) as sum_rows FROM generate_series(1, 495 * 10) i;
 
 SELECT * FROM v_window;
 
@@ -293,7 +293,7 @@ SELECT pg_get_viewdef('v_window');
 
 CREATE OR REPLACE TEMP VIEW v_window AS
 	SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following
-	exclude group) as sum_rows FROM generate_series(1, 10) i;
+	exclude group) as sum_rows FROM generate_series(1, 495 * 10) i;
 
 SELECT * FROM v_window;
 
@@ -301,7 +301,7 @@ SELECT pg_get_viewdef('v_window');
 
 CREATE OR REPLACE TEMP VIEW v_window AS
 	SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following
-	exclude ties) as sum_rows FROM generate_series(1, 10) i;
+	exclude ties) as sum_rows FROM generate_series(1, 495 * 10) i;
 
 SELECT * FROM v_window;
 
@@ -309,14 +309,14 @@ SELECT pg_get_viewdef('v_window');
 
 CREATE OR REPLACE TEMP VIEW v_window AS
 	SELECT i, sum(i) over (order by i rows between 1 preceding and 1 following
-	exclude no others) as sum_rows FROM generate_series(1, 10) i;
+	exclude no others) as sum_rows FROM generate_series(1, 495 * 10) i;
 
 SELECT * FROM v_window;
 
 SELECT pg_get_viewdef('v_window');
 
 CREATE OR REPLACE TEMP VIEW v_window AS
-	SELECT i, sum(i) over (order by i groups between 1 preceding and 1 following) as sum_rows FROM generate_series(1, 10) i;
+	SELECT i, sum(i) over (order by i groups between 1 preceding and 1 following) as sum_rows FROM generate_series(1, 495 * 10) i;
 
 SELECT * FROM v_window;
 
@@ -439,7 +439,7 @@ select x, y,
        first_value(y) over w,
        last_value(y) over w
 from
-  (select x, x as y from generate_series(1,5) as x
+  (select x, x as y from generate_series(1, 495 * 5) as x
    union all select null, 42
    union all select null, 43) ss
 window w as
@@ -449,7 +449,7 @@ select x, y,
        first_value(y) over w,
        last_value(y) over w
 from
-  (select x, x as y from generate_series(1,5) as x
+  (select x, x as y from generate_series(1, 495 * 5) as x
    union all select null, 42
    union all select null, 43) ss
 window w as
@@ -459,7 +459,7 @@ select x, y,
        first_value(y) over w,
        last_value(y) over w
 from
-  (select x, x as y from generate_series(1,5) as x
+  (select x, x as y from generate_series(1, 495 * 5) as x
    union all select null, 42
    union all select null, 43) ss
 window w as
@@ -469,7 +469,7 @@ select x, y,
        first_value(y) over w,
        last_value(y) over w
 from
-  (select x, x as y from generate_series(1,5) as x
+  (select x, x as y from generate_series(1, 495 * 5) as x
    union all select null, 42
    union all select null, 43) ss
 window w as
@@ -980,21 +980,21 @@ select last_value(salary) over(order by enroll_date groups between 1 following a
 
 -- Show differences in offset interpretation between ROWS, RANGE, and GROUPS
 WITH cte (x) AS (
-        SELECT * FROM generate_series(1, 35, 2)
+        SELECT * FROM generate_series(1, 495 * 35, 2)
 )
 SELECT x, (sum(x) over w)
 FROM cte
 WINDOW w AS (ORDER BY x rows between 1 preceding and 1 following);
 
 WITH cte (x) AS (
-        SELECT * FROM generate_series(1, 35, 2)
+        SELECT * FROM generate_series(1, 495 * 35, 2)
 )
 SELECT x, (sum(x) over w)
 FROM cte
 WINDOW w AS (ORDER BY x range between 1 preceding and 1 following);
 
 WITH cte (x) AS (
-        SELECT * FROM generate_series(1, 35, 2)
+        SELECT * FROM generate_series(1, 495 * 35, 2)
 )
 SELECT x, (sum(x) over w)
 FROM cte
@@ -1090,7 +1090,7 @@ SELECT rank() OVER (PARTITION BY four, ORDER BY ten) FROM tenk1;
 
 SELECT count() OVER () FROM tenk1;
 
-SELECT generate_series(1, 100) OVER () FROM empsalary;
+SELECT generate_series(1, 495 * 100) OVER () FROM empsalary;
 
 SELECT ntile(0) OVER (ORDER BY ten), ten, four FROM tenk1;
 
@@ -1710,7 +1710,7 @@ CREATE AGGREGATE sum_int_randomrestart (int4)
 WITH
 vs AS (
 	SELECT i, (random() * 100)::int4 AS v
-	FROM generate_series(1, 100) AS i
+	FROM generate_series(1, 495 * 100) AS i
 ),
 sum_following AS (
 	SELECT i, SUM(v) OVER
@@ -1945,14 +1945,14 @@ LIMIT 1;
 
 -- test walker (fails with collation error if expressions are not walked)
 SELECT array_agg(i) OVER w
-  FROM generate_series(1,5) i
+  FROM generate_series(1, 495 * 5) i
 WINDOW w AS (ORDER BY i ROWS BETWEEN (('foo' < 'foobar')::integer) PRECEDING AND CURRENT ROW);
 
 -- test mutator (fails when inlined if expressions are not mutated)
 CREATE FUNCTION pg_temp.f(group_size BIGINT) RETURNS SETOF integer[]
 AS $$
     SELECT array_agg(s) OVER w
-      FROM generate_series(1,5) s
+      FROM generate_series(1, 495 * 5) s
     WINDOW w AS (ORDER BY s ROWS BETWEEN CURRENT ROW AND GROUP_SIZE FOLLOWING)
 $$ LANGUAGE SQL STABLE;
 
diff --git a/src/test/regress/sql/with.sql b/src/test/regress/sql/with.sql
index 6d55c7731a..1ca545e14e 100644
--- a/src/test/regress/sql/with.sql
+++ b/src/test/regress/sql/with.sql
@@ -8,7 +8,7 @@ SELECT * FROM q1, q1 AS q2;
 
 -- Multiple uses are evaluated only once
 SELECT count(*) FROM (
-  WITH q1(x) AS (SELECT random() FROM generate_series(1, 5))
+  WITH q1(x) AS (SELECT random() FROM generate_series(1, 495 * 5))
     SELECT * FROM q1
   UNION
     SELECT * FROM q1
@@ -863,7 +863,7 @@ WITH RECURSIVE
 --
 
 CREATE TEMPORARY TABLE y (a INTEGER);
-INSERT INTO y SELECT generate_series(1, 10);
+INSERT INTO y SELECT generate_series(1, 495 * 10);
 
 WITH t AS (
 	SELECT a FROM y
@@ -957,7 +957,7 @@ WITH RECURSIVE x(n) AS (
 
 
 CREATE TEMPORARY TABLE y (a INTEGER);
-INSERT INTO y SELECT generate_series(1, 10);
+INSERT INTO y SELECT generate_series(1, 495 * 10);
 
 -- LEFT JOIN
 
@@ -1276,7 +1276,7 @@ DROP RULE y_rule ON y;
 
 -- check merging of outer CTE with CTE in a rule action
 CREATE TEMP TABLE bug6051 AS
-  select i from generate_series(1,3) as t(i);
+  select i from generate_series(1, 495 * 3) as t(i);
 
 SELECT * FROM bug6051;
 
@@ -1385,12 +1385,12 @@ SELECT * FROM t LIMIT 10;
 SELECT * FROM y;
 
 -- data-modifying WITH containing INSERT...ON CONFLICT DO UPDATE
-CREATE TABLE withz AS SELECT i AS k, (i || ' v')::text v FROM generate_series(1, 16, 3) i;
+CREATE TABLE withz AS SELECT i AS k, (i || ' v')::text v FROM generate_series(1, 495 * 16, 3) i;
 ALTER TABLE withz ADD UNIQUE (k);
 
 WITH t AS (
     INSERT INTO withz SELECT i, 'insert'
-    FROM generate_series(0, 16) i
+    FROM generate_series(0, 495 * 16) i
     ON CONFLICT (k) DO UPDATE SET v = withz.v || ', now update'
     RETURNING *
 )
@@ -1443,7 +1443,7 @@ RETURNING k, v;
 DROP TABLE withz;
 
 -- WITH referenced by MERGE statement
-CREATE TABLE m AS SELECT i AS k, (i || ' v')::text v FROM generate_series(1, 16, 3) i;
+CREATE TABLE m AS SELECT i AS k, (i || ' v')::text v FROM generate_series(1, 495 * 16, 3) i;
 ALTER TABLE m ADD UNIQUE (k);
 
 WITH RECURSIVE cte_basic AS (SELECT 1 a, 'cte_basic val' b)
@@ -1501,7 +1501,7 @@ DROP TABLE m;
 -- check that run to completion happens in proper ordering
 
 TRUNCATE TABLE y;
-INSERT INTO y SELECT generate_series(1, 3);
+INSERT INTO y SELECT generate_series(1, 495 * 3);
 CREATE TEMPORARY TABLE yy (a INTEGER);
 
 WITH RECURSIVE t1 AS (
@@ -1527,7 +1527,7 @@ SELECT * FROM yy;
 -- triggers
 
 TRUNCATE TABLE y;
-INSERT INTO y SELECT generate_series(1, 10);
+INSERT INTO y SELECT generate_series(1, 495 * 10);
 
 CREATE FUNCTION y_trigger() RETURNS trigger AS $$
 begin
